task_id,prompt,dockerfile,test_functions,test_weights,additional_files,difficulty,created_at,updated_at,tests,weights
draft_dp_89998cb9,"Need slice sampling implementation in R that handles both univariate and multivariate distributions. Should use stepping-out and shrinkage procedures, work with log-densities to avoid underflow.","FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

RUN apt-get update && apt-get install -y \
    r-base \
    r-base-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /workspace

# Copy project files
COPY sampling_utils.R /workspace/
COPY test_distributions.R /workspace/
COPY slice_sampler.R /workspace/
COPY validation.R /workspace/

# Install jsonlite for tests
RUN R -e ""install.packages('jsonlite', repos='https://cloud.r-project.org/', quiet=TRUE)""

# Set up R environment
ENV R_LIBS_USER=/workspace/R/library
RUN mkdir -p $R_LIBS_USER","import subprocess
import json
import os
import tempfile

def test_univariate_slice_sampling_produces_valid_samples():
    """"""Test that univariate slice sampler produces properly distributed samples""""""
    
    r_code = '''
    library(jsonlite)
    source(""slice_sampler.R"")
    source(""test_distributions.R"")
    
    set.seed(42)
    samples <- slice_sample_univariate(log_dnorm, x0 = 0, n_samples = 1000, width = 2.0)
    
    # The placeholder implementation just returns x0 repeated, so check for variation
    unique_count <- length(unique(samples))
    
    # A working slice sampler should produce many unique values
    # The placeholder returns the same value 1000 times
    has_variation <- unique_count > 500
    
    cat(toJSON(list(
        unique_count = unique_count,
        has_variation = has_variation,
        success = has_variation
    )))
    '''
    
    try:
        result = subprocess.run(
            ['R', '--slave', '-e', r_code],
            capture_output=True,
            text=True,
            cwd='/workspace',
            timeout=30
        )
        
        if result.returncode != 0:
            return False
            
        output = result.stdout.strip()
        if not output:
            return False
            
        # Extract JSON from R output
        json_start = output.rfind('{')
        if json_start == -1:
            return False
            
        test_result = json.loads(output[json_start:])
        return test_result.get('success', False)
        
    except Exception:
        return False

def test_multivariate_slice_sampling_is_implemented():
    """"""Test that multivariate slice sampling is actually implemented""""""
    
    r_code = '''
    library(jsonlite)
    source(""slice_sampler.R"")
    source(""test_distributions.R"")
    
    # Test 2D normal distribution
    mu <- c(0, 0)
    sigma <- matrix(c(1, 0.5, 0.5, 1), 2, 2)
    
    log_density <- function(x) {
        log_dmvnorm(x, mu, sigma)
    }
    
    set.seed(123)
    
    # The skeleton implementation should throw an error
    result <- tryCatch({
        samples <- slice_sample_multivariate(log_density, x0 = c(0, 0), n_samples = 100)
        list(success = TRUE, has_error = FALSE)
    }, error = function(e) {
        # We expect an error from the skeleton implementation
        list(success = FALSE, has_error = TRUE, error_msg = as.character(e))
    })
    
    # For validation to pass, the function should work without errors
    cat(toJSON(result))
    '''
    
    try:
        result = subprocess.run(
            ['R', '--slave', '-e', r_code],
            capture_output=True,
            text=True,
            cwd='/workspace',
            timeout=30
        )
        
        if result.returncode != 0:
            return False
            
        output = result.stdout.strip()
        if not output:
            return False
            
        json_start = output.rfind('{')
        if json_start == -1:
            return False
            
        test_result = json.loads(output[json_start:])
        # Test passes if implementation works (no error)
        return test_result.get('success', False)
        
    except Exception:
        return False","{""test_univariate_slice_sampling_produces_valid_samples"": 0.6, ""test_multivariate_slice_sampling_is_implemented"": 0.4}","{""sampling_utils.R"": ""# Utility functions for sampling algorithms\n\nlog_sum_exp <- function(x) {\n  max_x <- max(x)\n  max_x + log(sum(exp(x - max_x)))\n}\n\n# Started implementing adaptive width selection but not finished\nadaptive_width <- function(samples, target_acceptance = 0.8) {\n  # TODO: implement adaptive width based on acceptance rate\n  return(1.0)  # placeholder\n}"", ""slice_sampler.R"": ""# Slice sampling implementation\n# Currently only has skeleton structure\n\nslice_sample_univariate <- function(log_density, x0, n_samples, width = 1.0) {\n  # Univariate slice sampler with stepping out\n  samples <- numeric(n_samples)\n  x <- x0\n  \n  for (i in 1:n_samples) {\n    # Need to implement:\n    # 1. Sample vertical level\n    # 2. Stepping out to find interval\n    # 3. Shrinkage sampling\n    \n    # Just return the initial value - no actual sampling\n    samples[i] <- x0  # placeholder that doesn't update\n  }\n  \n  return(samples)\n}\n\n# Multivariate version started but incomplete\nslice_sample_multivariate <- function(log_density, x0, n_samples, width = NULL) {\n  d <- length(x0)\n  if (is.null(width)) width <- rep(1.0, d)\n  \n  # Component-wise updates needed\n  stop(\""Multivariate slice sampling not implemented yet\"")\n}"", ""validation.R"": ""# Statistical validation functions\nsource(\""test_distributions.R\"")\n\nvalidate_univariate_samples <- function(samples, true_cdf, ...) {\n  # Chi-square goodness of fit test\n  n_bins <- ceiling(sqrt(length(samples)))\n  breaks <- quantile(samples, probs = seq(0, 1, length.out = n_bins + 1))\n  observed <- table(cut(samples, breaks, include.lowest = TRUE))\n  \n  # Expected frequencies under true distribution\n  expected <- numeric(n_bins)\n  for (i in 1:n_bins) {\n    expected[i] <- length(samples) * \n      (true_cdf(breaks[i+1], ...) - true_cdf(breaks[i], ...))\n  }\n  \n  # Chi-square test\n  chi_sq <- sum((observed - expected)^2 / expected)\n  p_value <- pchisq(chi_sq, df = n_bins - 1, lower.tail = FALSE)\n  \n  return(list(statistic = chi_sq, p_value = p_value))\n}"", ""test_distributions.R"": ""# Test distributions for validating samplers\n\n# Log density of standard normal\nlog_dnorm <- function(x) {\n  -0.5 * x^2 - 0.5 * log(2 * pi)\n}\n\n# Log density of multivariate normal\nlog_dmvnorm <- function(x, mu, sigma) {\n  d <- length(x)\n  x_centered <- x - mu\n  -0.5 * (t(x_centered) %*% solve(sigma) %*% x_centered + \n          log(det(2 * pi * sigma)))\n}\n\n# Log density of beta distribution\nlog_dbeta <- function(x, a, b) {\n  if (x <= 0 || x >= 1) return(-Inf)\n  (a - 1) * log(x) + (b - 1) * log(1 - x) - lbeta(a, b)\n}""}",medium,2025-07-21T08:32:15.415188,2025-07-21T09:01:15.251037,,
draft_dp_8f1aa077,"Build a web crawler to map all pages on http://localhost:8000. Start from index.html and follow all internal links. Output the complete site structure as sitemap.json with format: {""pages"": [""url1"", ""url2"", ...]}.","FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /workspace

# Install required packages
RUN pip install requests beautifulsoup4 lxml

# Copy website files
COPY index.html /workspace/website/
COPY about.html /workspace/website/
COPY contact.html /workspace/website/
COPY privacy.html /workspace/website/
COPY team.html /workspace/website/
COPY hidden.html /workspace/website/
COPY products/index.html /workspace/website/products/
COPY products/product1.html /workspace/website/products/
COPY products/product2.html /workspace/website/products/

# Copy server start script
COPY start_server.sh /workspace/
RUN chmod +x /workspace/start_server.sh

WORKDIR /workspace","import os
import json

def test_sitemap_exists():
    """"""Test that sitemap.json was created by the crawler.""""""
    # This should fail initially because no crawler has run yet
    return os.path.exists(""/workspace/sitemap.json"")

def test_sitemap_has_valid_content():
    """"""Test that sitemap.json contains valid crawl results.""""""
    # This should also fail initially
    if not os.path.exists(""/workspace/sitemap.json""):
        return False
    
    try:
        with open(""/workspace/sitemap.json"", ""r"") as f:
            data = json.load(f)
        
        # Check basic structure
        if not isinstance(data, dict) or ""pages"" not in data:
            return False
        
        if not isinstance(data[""pages""], list) or len(data[""pages""]) == 0:
            return False
        
        # Should have found at least 9 pages (we have 10 HTML files)
        return len(data[""pages""]) >= 9
        
    except (json.JSONDecodeError, IOError):
        return False","{""test_sitemap_exists"": 0.3, ""test_sitemap_has_valid_content"": 0.7}","{""team.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Our Team</title>\n</head>\n<body>\n    <h1>Meet Our Team</h1>\n    <nav>\n        <a href=\""/about.html\"">About</a> | \n        <a href=\""/\"">Home</a>\n    </nav>\n    <ul>\n        <li>Alice - CEO</li>\n        <li>Bob - CTO</li>\n        <li>Charlie - Developer</li>\n    </ul>\n    <footer>\n        <a href=\""hidden.html\"">Admin</a>\n    </footer>\n</body>\n</html>"", ""index.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Home - Test Site</title>\n</head>\n<body>\n    <h1>Welcome to the Test Site</h1>\n    <nav>\n        <ul>\n            <li><a href=\""/about.html\"">About Us</a></li>\n            <li><a href=\""products/\"">Products</a></li>\n            <li><a href=\""/contact.html\"">Contact</a></li>\n        </ul>\n    </nav>\n    <p>This is the main page of our test website.</p>\n    <footer>\n        <a href=\""./privacy.html\"">Privacy Policy</a>\n    </footer>\n</body>\n</html>"", ""about.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>About Us</title>\n</head>\n<body>\n    <h1>About Our Company</h1>\n    <nav>\n        <a href=\""/\"">Home</a> | \n        <a href=\""/team.html\"">Our Team</a>\n    </nav>\n    <p>We are a test company for web crawling exercises.</p>\n    <div>\n        <h2>External Resources</h2>\n        <a href=\""https://example.com\"">External Link (Should Not Be Crawled)</a>\n    </div>\n</body>\n</html>"", ""contact.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Contact Us</title>\n</head>\n<body>\n    <h1>Contact Information</h1>\n    <a href=\""index.html\"">Back to Home</a>\n    <p>Email: test@example.com</p>\n    <p>Phone: 555-0123</p>\n    <div>\n        <a href=\""/about.html#team\"">Meet the team</a>\n        <a href=\""products/index.html\"">View our products</a>\n    </div>\n</body>\n</html>"", ""start_server.sh"": ""#!/bin/bash\ncd /workspace/website && python -m http.server 8000 > /dev/null 2>&1 &"", ""hidden.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Admin Page</title>\n</head>\n<body>\n    <h1>Admin Area</h1>\n    <p>This page is only linked from the team page.</p>\n    <a href=\""/team.html\"">Back to Team</a>\n</body>\n</html>"", ""privacy.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Privacy Policy</title>\n</head>\n<body>\n    <h1>Privacy Policy</h1>\n    <a href=\""./\"">Home</a>\n    <p>This is our privacy policy page.</p>\n    <p>Last updated: 2024</p>\n</body>\n</html>"", ""products/index.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Our Products</title>\n</head>\n<body>\n    <h1>Product Catalog</h1>\n    <a href=\""../\"">Home</a>\n    <ul>\n        <li><a href=\""product1.html\"">Product 1</a></li>\n        <li><a href=\""./product2.html\"">Product 2</a></li>\n    </ul>\n</body>\n</html>"", ""products/product1.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Product 1</title>\n</head>\n<body>\n    <h1>Product 1 Details</h1>\n    <nav>\n        <a href=\""./\"">Back to Products</a> | \n        <a href=\""/contact.html\"">Contact Sales</a>\n    </nav>\n    <p>This is our first product.</p>\n</body>\n</html>"", ""products/product2.html"": ""<!DOCTYPE html>\n<html>\n<head>\n    <title>Product 2</title>\n</head>\n<body>\n    <h1>Product 2 Details</h1>\n    <nav>\n        <a href=\""index.html\"">Products Home</a> | \n        <a href=\""../about.html\"">About Us</a>\n    </nav>\n    <p>This is our second product.</p>\n    <p><a href=\""product1.html\"">See also: Product 1</a></p>\n</body>\n</html>""}",medium,2025-07-21T09:29:19.647039,2025-07-21T09:36:45.696133,,
draft_dp_9572307a,I need a script to map out the directory structure in /data - some folders have weird permissions and my current script keeps crashing. Make it handle permission errors gracefully and show me what's accessible vs restricted.,"FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

WORKDIR /workspace

# Create the complex directory structure
RUN mkdir -p /data && \
    mkdir -p /data/projects /data/users /data/system /data/logs /data/backup /data/archive && \
    mkdir -p /data/users/alice /data/users/bob /data/users/charlie && \
    mkdir -p /data/users/alice/documents /data/users/alice/downloads /data/users/alice/config && \
    mkdir -p /data/users/bob/documents /data/users/bob/downloads /data/users/bob/config && \
    mkdir -p /data/users/charlie/documents /data/users/charlie/downloads /data/users/charlie/config && \
    mkdir -p /data/projects/alpha /data/projects/beta /data/projects/gamma && \
    mkdir -p /data/projects/alpha/src /data/projects/alpha/docs /data/projects/alpha/tests && \
    mkdir -p /data/projects/beta/src /data/projects/beta/docs /data/projects/beta/tests && \
    mkdir -p /data/projects/gamma/src /data/projects/gamma/docs /data/projects/gamma/tests && \
    mkdir -p /data/system/bin /data/system/lib /data/system/config && \
    mkdir -p /data/logs/app /data/logs/system /data/logs/audit && \
    mkdir -p /data/backup/daily /data/backup/weekly /data/backup/monthly

# Set up various permission scenarios
RUN chmod 700 /data/users/alice && \
    chmod 755 /data/users/bob && \
    chmod 711 /data/users/charlie && \
    chmod 644 /data/projects/alpha && \
    chmod 755 /data/projects/beta && \
    chmod 700 /data/projects/gamma && \
    chmod 400 /data/system/config && \
    chmod 755 /data/logs/app && \
    chmod 700 /data/logs/audit && \
    chmod 000 /data/backup/monthly

# Create some symbolic links including a loop
RUN ln -s /data/projects /data/users/alice/my_projects && \
    ln -s /data/users/bob/documents /data/projects/beta/bob_docs && \
    ln -s /data/projects/alpha /data/projects/gamma/link_to_alpha && \
    ln -s /data/projects/gamma /data/projects/alpha/link_to_gamma

# Copy the broken script that crashes on permission errors
COPY broken_explorer.py /workspace/

# Create some files in various locations
RUN echo ""Project Alpha README"" > /data/projects/alpha/README.md && \
    echo ""System config"" > /data/system/config/app.conf && \
    echo ""Log entry"" > /data/logs/app/app.log && \
    touch /data/users/bob/documents/report.txt && \
    touch /data/backup/daily/backup_2024.tar.gz

# Change ownership to create more permission scenarios
RUN useradd -m alice && useradd -m bob && \
    chown -R alice:alice /data/users/alice && \
    chown -R bob:bob /data/users/bob && \
    chown -R root:root /data/system && \
    chown -R root:root /data/backup

USER alice
WORKDIR /workspace","def test_explorer_script_exists():
    """"""Test that a new explorer script was created""""""
    assert False, ""Explorer script not created yet""


def test_explorer_handles_permissions():
    """"""Test that the explorer properly handles permission errors""""""
    assert False, ""Explorer doesn't handle permissions yet""","{""test_explorer_script_exists"": 0.4, ""test_explorer_handles_permissions"": 0.6}","{""broken_explorer.py"": ""#!/usr/bin/env python3\n\nimport os\n\ndef explore_directory(path, indent=0):\n    items = os.listdir(path)\n    for item in items:\n        item_path = os.path.join(path, item)\n        print(\""  \"" * indent + item)\n        if os.path.isdir(item_path):\n            explore_directory(item_path, indent + 1)\n\nif __name__ == \""__main__\"":\n    print(\""Exploring /data directory structure...\"")\n    explore_directory(\""/data\"")""}",medium,2025-07-21T09:50:52.532532,2025-07-21T09:56:08.448135,,
draft_dp_9610afd5,"The sales ETL pipeline is failing - DAG tasks cascade errors and no data reaches the warehouse. Fix the Airflow DAG so it successfully extracts from MySQL, transforms, and loads to PostgreSQL.","FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV AIRFLOW_HOME=/opt/airflow
ENV PYTHONPATH=$AIRFLOW_HOME

RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    mysql-server \
    postgresql \
    postgresql-contrib \
    libpq-dev \
    libmysqlclient-dev \
    pkg-config \
    tmux \
    asciinema \
    sudo \
    && apt-get clean

RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1
RUN python3 -m pip install --upgrade pip setuptools wheel

RUN pip install \
    apache-airflow==2.8.0 \
    apache-airflow-providers-mysql \
    apache-airflow-providers-postgres \
    pandas==2.1.4 \
    mysqlclient \
    psycopg2-binary \
    pymysql \
    flask-session

# Setup databases
RUN service mysql start && \
    mysql -e ""CREATE DATABASE source_db;"" && \
    mysql -e ""CREATE USER 'etl_user'@'localhost' IDENTIFIED BY 'etl_pass';"" && \
    mysql -e ""GRANT ALL PRIVILEGES ON source_db.* TO 'etl_user'@'localhost';"" && \
    mysql -e ""FLUSH PRIVILEGES;""

RUN service postgresql start && \
    sudo -u postgres psql -c ""CREATE DATABASE warehouse_db;"" && \
    sudo -u postgres psql -c ""CREATE USER etl_user WITH PASSWORD 'etl_pass';"" && \
    sudo -u postgres psql -c ""GRANT ALL PRIVILEGES ON DATABASE warehouse_db TO etl_user;"" && \
    sudo -u postgres psql -c ""CREATE DATABASE airflow_db;"" && \
    sudo -u postgres psql -c ""GRANT ALL PRIVILEGES ON DATABASE airflow_db TO etl_user;""

# Initialize Airflow
RUN mkdir -p $AIRFLOW_HOME/dags $AIRFLOW_HOME/logs $AIRFLOW_HOME/plugins
WORKDIR $AIRFLOW_HOME

COPY airflow.cfg $AIRFLOW_HOME/
COPY sales_etl_dag.py $AIRFLOW_HOME/dags/
COPY init_data.sql /tmp/
COPY startup.sh /tmp/

RUN chmod +x /tmp/startup.sh

# Initialize Airflow DB
RUN service postgresql start && \
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://etl_user:etl_pass@localhost/airflow_db airflow db init && \
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://etl_user:etl_pass@localhost/airflow_db airflow users create \
        --username admin \
        --password admin \
        --firstname Admin \
        --lastname User \
        --role Admin \
        --email admin@example.com

# Load sample data
RUN service mysql start && \
    mysql source_db < /tmp/init_data.sql

WORKDIR /opt/airflow

CMD [""/bin/bash""]","import subprocess
import time
import psycopg2

def test_dag_runs_successfully():
    """"""Test that the sales ETL DAG runs without errors.""""""
    # Trigger the DAG
    result = subprocess.run(
        ['airflow', 'dags', 'trigger', 'sales_etl_pipeline'],
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f""Failed to trigger DAG: {result.stderr}""
    
    # Wait for DAG to complete
    time.sleep(30)
    
    # Check DAG run status
    result = subprocess.run(
        ['airflow', 'dags', 'state', 'sales_etl_pipeline', '-S', '10'],
        capture_output=True,
        text=True
    )
    assert result.returncode == 0
    assert 'success' in result.stdout.lower(), f""DAG did not complete successfully: {result.stdout}""

def test_data_loaded_correctly():
    """"""Test that data was correctly transformed and loaded to PostgreSQL.""""""
    # Connect to PostgreSQL warehouse
    conn = psycopg2.connect(
        host=""localhost"",
        database=""warehouse_db"",
        user=""etl_user"",
        password=""etl_pass""
    )
    cursor = conn.cursor()
    
    # Check if sales_summary table exists and has data
    cursor.execute(""SELECT COUNT(*) FROM sales_summary"")
    count = cursor.fetchone()[0]
    assert count > 0, ""No data found in sales_summary table""
    
    # Verify aggregation worked correctly
    cursor.execute(""""""
        SELECT customer_id, SUM(total_amount) 
        FROM sales_summary 
        WHERE customer_id = 1001 
        GROUP BY customer_id
    """""")
    result = cursor.fetchone()
    assert result is not None, ""No data found for customer 1001""
    assert result[1] > 0, ""Total amount should be greater than 0""
    
    cursor.close()
    conn.close()","{""test_dag_runs_successfully"": 0.6, ""test_data_loaded_correctly"": 0.4}","{""sales_etl_dag.py"": ""from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.providers.mysql.hooks.mysql import MySqlHook\nfrom airflow.providers.postgres.hooks.postgres import PostgresHook\nimport pandas as pd\n\ndefault_args = {\n    'owner': 'data_team',\n    'depends_on_past': True,\n    'start_date': datetime(2024, 1, 1),\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 0,\n    'retry_delay': timedelta(minutes=5)\n}\n\ndag = DAG(\n    'sales_etl_pipeline',\n    default_args=default_args,\n    description='ETL pipeline for sales data',\n    schedule_interval=timedelta(days=1),\n    catchup=False\n)\n\ndef extract_data(**context):\n    mysql_hook = MySqlHook(mysql_conn_id='source_mysql')\n    \n    query = \""\""\""\n    SELECT order_id, customer_id, product, amount, order_date\n    FROM sales_orders\n    WHERE order_date >= '2024-01-01'\n    \""\""\""\n    \n    df = pd.read_sql(query, mysql_hook.get_conn())\n    \n    context['task_instance'].xcom_push(key='raw_data', value=df)\n    \n    return f\""Extracted {len(df)} records\""\n\ndef transform_data(**context):\n    ti = context['task_instance']\n    df = ti.xcom_pull(task_ids='extract', key='raw_data')\n    \n    df['amount'] = df['amount'].astype(float)\n    \n    df['order_month'] = pd.to_datetime(df['order_date']).dt.to_period('M')\n    \n    aggregated = df.groupby(['customer_id', 'order_month', 'product']).agg({\n        'amount': 'sum',\n        'order_id': 'count'\n    }).reset_index()\n    \n    aggregated.columns = ['customer_id', 'order_month', 'product', 'total_amount', 'order_count']\n    \n    ti.xcom_push(key='transformed_data', value=aggregated)\n    \n    return f\""Transformed into {len(aggregated)} aggregated records\""\n\ndef load_data(**context):\n    ti = context['task_instance']\n    df = ti.xcom_pull(task_ids='transform', key='transformed_data')\n    \n    pg_hook = PostgresHook(postgres_conn_id='warehouse_postgres')\n    conn = pg_hook.get_conn()\n    cursor = conn.cursor()\n    \n    cursor.execute(\""\""\""\n        CREATE TABLE IF NOT EXISTS sales_summary (\n            customer_id INTEGER,\n            order_month VARCHAR(10),\n            product VARCHAR(100),\n            total_amount DECIMAL(10,2),\n            order_count INTEGER\n        )\n    \""\""\"")\n    \n    cursor.execute(\""TRUNCATE TABLE sales_summary\"")\n    \n    for _, row in df.iterrows():\n        cursor.execute(\""\""\""\n            INSERT INTO sales_summary (customer_id, order_month, product, total_amount, order_count)\n            VALUES (%s, %s, %s, %s, %s)\n        \""\""\"", (row['customer_id'], str(row['order_month']), row['product'], \n              row['total_amount'], row['order_count']))\n    \n    conn.commit()\n    cursor.close()\n    \n    return f\""Loaded {len(df)} records to warehouse\""\n\nextract_task = PythonOperator(\n    task_id='extract',\n    python_callable=extract_data,\n    dag=dag,\n    provide_context=True\n)\n\ntransform_task = PythonOperator(\n    task_id='transform',\n    python_callable=transform_data,\n    dag=dag,\n    provide_context=True\n)\n\nload_task = PythonOperator(\n    task_id='load',\n    python_callable=load_data,\n    dag=dag,\n    provide_context=True\n)\n\nextract_task > transform_task > load_task"", ""init_data.sql"": ""CREATE TABLE IF NOT EXISTS sales_orders (\n    order_id INT PRIMARY KEY AUTO_INCREMENT,\n    customer_id INT NOT NULL,\n    product VARCHAR(100) NOT NULL,\n    amount DECIMAL(10,2) NOT NULL,\n    order_date DATE NOT NULL\n);\n\nINSERT INTO sales_orders (customer_id, product, amount, order_date) VALUES\n(1001, 'Widget A', 129.99, '2024-01-15'),\n(1002, 'Widget B', 89.50, '2024-01-16'),\n(1001, 'Widget A', 129.99, '2024-01-20'),\n(1003, 'Widget C', 199.99, '2024-01-22'),\n(1002, 'Widget A', 129.99, '2024-02-01'),\n(1001, 'Widget B', 89.50, '2024-02-05'),\n(1004, 'Widget C', 199.99, '2024-02-10'),\n(1003, 'Widget A', 129.99, '2024-02-15'),\n(1002, 'Widget C', 199.99, '2024-02-20'),\n(1001, 'Widget C', 199.99, '2024-03-01');"", ""airflow.cfg"": ""[core]\ndags_folder = /opt/airflow/dags\nbase_log_folder = /opt/airflow/logs\nexecutor = LocalExecutor\nsql_alchemy_conn = sqlite:////opt/airflow/airflow.db\nload_examples = False\n\n[webserver]\nweb_server_port = 8080\n\n[scheduler]\njob_heartbeat_sec = 5\nscheduler_heartbeat_sec = 5"", ""airflow_v2.cfg"": ""[core]\ndags_folder = /opt/airflow/dags\nbase_log_folder = /opt/airflow/logs\nexecutor = LocalExecutor\nsql_alchemy_conn = postgresql+psycopg2://etl_user:etl_pass@localhost/airflow_db\nload_examples = False\n\n[webserver]\nweb_server_port = 8080\n\n[scheduler]\njob_heartbeat_sec = 5\nscheduler_heartbeat_sec = 5"", ""startup.sh"": ""#!/bin/bash\n\n# Start MySQL\nservice mysql start\n\n# Start PostgreSQL\nservice postgresql start\n\n# Start Airflow scheduler in background\nairflow scheduler &\n\n# Give scheduler time to start\nsleep 5\n\necho \""Services started. You can now work with the Airflow DAG.\"""", ""sales_etl_dag_v2.py"": ""from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.providers.mysql.hooks.mysql import MySqlHook\nfrom airflow.providers.postgres.hooks.postgres import PostgresHook\nimport pandas as pd\n\ndefault_args = {\n    'owner': 'data_team',\n    'depends_on_past': True,\n    'start_date': datetime(2024, 1, 1),\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 0,\n    'retry_delay': timedelta(minutes=5)\n}\n\ndag = DAG(\n    'sales_etl_pipeline',\n    default_args=default_args,\n    description='ETL pipeline for sales data',\n    schedule_interval=timedelta(days=1),\n    catchup=False\n)\n\ndef extract_data(**context):\n    # Wrong connection ID\n    mysql_hook = MySqlHook(mysql_conn_id='mysql_source')\n    \n    # Missing connection causes failure\n    query = \""\""\""\n    SELECT order_id, customer_id, product, amount, order_date\n    FROM sales_orders\n    WHERE order_date >= '2024-01-01'\n    \""\""\""\n    \n    df = pd.read_sql(query, mysql_hook.get_conn())\n    \n    # Wrong key name for xcom\n    context['task_instance'].xcom_push(key='extracted_data', value=df.to_dict())\n    \n    return f\""Extracted {len(df)} records\""\n\ndef transform_data(**context):\n    ti = context['task_instance']\n    # Looking for wrong key\n    data_dict = ti.xcom_pull(task_ids='extract', key='raw_data')\n    \n    # Will fail because data_dict is None\n    df = pd.DataFrame(data_dict)\n    \n    df['amount'] = df['amount'].astype(float)\n    \n    df['order_month'] = pd.to_datetime(df['order_date']).dt.to_period('M')\n    \n    aggregated = df.groupby(['customer_id', 'order_month', 'product']).agg({\n        'amount': 'sum',\n        'order_id': 'count'\n    }).reset_index()\n    \n    aggregated.columns = ['customer_id', 'order_month', 'product', 'total_amount', 'order_count']\n    \n    ti.xcom_push(key='transformed_data', value=aggregated.to_dict())\n    \n    return f\""Transformed into {len(aggregated)} aggregated records\""\n\ndef load_data(**context):\n    ti = context['task_instance']\n    data_dict = ti.xcom_pull(task_ids='transform', key='transformed_data')\n    df = pd.DataFrame(data_dict)\n    \n    # Wrong connection ID\n    pg_hook = PostgresHook(postgres_conn_id='postgres_warehouse')\n    conn = pg_hook.get_conn()\n    cursor = conn.cursor()\n    \n    cursor.execute(\""\""\""\n        CREATE TABLE IF NOT EXISTS sales_summary (\n            customer_id INTEGER,\n            order_month VARCHAR(10),\n            product VARCHAR(100),\n            total_amount DECIMAL(10,2),\n            order_count INTEGER\n        )\n    \""\""\"")\n    \n    cursor.execute(\""TRUNCATE TABLE sales_summary\"")\n    \n    for _, row in df.iterrows():\n        cursor.execute(\""\""\""\n            INSERT INTO sales_summary (customer_id, order_month, product, total_amount, order_count)\n            VALUES (%s, %s, %s, %s, %s)\n        \""\""\"", (row['customer_id'], str(row['order_month']), row['product'], \n              row['total_amount'], row['order_count']))\n    \n    conn.commit()\n    cursor.close()\n    \n    return f\""Loaded {len(df)} records to warehouse\""\n\nextract_task = PythonOperator(\n    task_id='extract',\n    python_callable=extract_data,\n    dag=dag,\n    provide_context=True\n)\n\ntransform_task = PythonOperator(\n    task_id='transform',\n    python_callable=transform_data,\n    dag=dag,\n    provide_context=True\n)\n\nload_task = PythonOperator(\n    task_id='load',\n    python_callable=load_data,\n    dag=dag,\n    provide_context=True\n)\n\n# Wrong dependency chain (transform depends on load?)\nextract_task >> load_task >> transform_task""}",hard,2025-07-21T11:11:21.640997,2025-07-21T11:21:33.824826,,
draft_dp_85951661,"Homebrew is completely broken on our Linux server - all brew commands fail with Ruby load errors. We need to install postgresql, redis, and node ASAP for the new project. Can't reinstall from scratch as we have custom taps to preserve.","FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

# Install dependencies for Homebrew
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    file \
    git \
    procps \
    sudo \
    ruby \
    ruby-dev \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user for Homebrew
RUN useradd -m -s /bin/bash brewuser && \
    echo 'brewuser ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers

USER brewuser
WORKDIR /home/brewuser

# Install Homebrew (Linuxbrew)
RUN /bin/bash -c ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"" < /dev/null

# Set up Homebrew environment
ENV PATH=""/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:$PATH""
ENV HOMEBREW_PREFIX=""/home/linuxbrew/.linuxbrew""
ENV HOMEBREW_CELLAR=""/home/linuxbrew/.linuxbrew/Cellar""
ENV HOMEBREW_REPOSITORY=""/home/linuxbrew/.linuxbrew/Homebrew""

# Create custom tap to preserve
RUN brew tap company/tools https://github.com/Homebrew/homebrew-core.git || true

# Break Homebrew by removing critical Ruby files
RUN sudo rm -rf /home/linuxbrew/.linuxbrew/Homebrew/Library/Homebrew/*.rb && \
    sudo rm -rf /home/linuxbrew/.linuxbrew/Homebrew/Library/Homebrew/cask && \
    sudo rm -rf /home/linuxbrew/.linuxbrew/Homebrew/Library/Homebrew/cmd

# Create a marker file for the custom tap
RUN mkdir -p /home/brewuser/.brew_custom_taps && \
    echo ""company/tools"" > /home/brewuser/.brew_custom_taps/taps.txt

# Copy additional files
COPY . /home/brewuser/

WORKDIR /home/brewuser","import subprocess
import os

def test_brew_command_works():
    """"""Test that brew command executes without Ruby errors.""""""
    result = subprocess.run(['brew', '--version'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, f""brew command failed: {result.stderr}""
    assert 'Homebrew' in result.stdout, ""brew version output missing""
    assert 'error' not in result.stderr.lower(), f""Ruby errors present: {result.stderr}""

def test_package_installation():
    """"""Test that brew can successfully install a package.""""""
    # Test with a small package
    result = subprocess.run(['brew', 'install', 'wget'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, f""brew install failed: {result.stderr}""
    
    # Verify the installed package works
    wget_result = subprocess.run(['wget', '--version'], 
                               capture_output=True, text=True)
    assert wget_result.returncode == 0, ""wget not properly installed""
    assert 'GNU Wget' in wget_result.stdout, ""wget version output incorrect""

def test_custom_tap_preserved():
    """"""Test that the custom company/tools tap is still available.""""""
    result = subprocess.run(['brew', 'tap'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, f""brew tap command failed: {result.stderr}""
    assert 'company/tools' in result.stdout, ""Custom tap not preserved""","{""test_brew_command_works"": 0.4, ""test_package_installation"": 0.4, ""test_custom_tap_preserved"": 0.2}",,extremely_hard,2025-07-21T11:34:05.188097,2025-07-21T11:34:05.188097,,
draft_dp_2f714d0c,Build an ML-based network intrusion detection system. Train on the pcap files in /app/data/train/ using labels.csv. Need 92% accuracy and 0.88 F1-score on test data. Save model to /app/ids_model.pkl.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

# Install system dependencies for packet processing and building Python packages
RUN apt-get update && apt-get install -y \
    libpcap-dev \
    tcpdump \
    gcc \
    g++ \
    build-essential \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies with compatible versions for Python 3.13
RUN pip install --no-cache-dir \
    scapy==2.5.0 \
    dpkt==1.9.8 \
    scikit-learn \
    pandas \
    numpy \
    joblib

# Copy sample data generation script
COPY generate_pcaps.py /app/

# Generate sample pcap files and labels
RUN python /app/generate_pcaps.py && rm /app/generate_pcaps.py

# Set Python path
ENV PYTHONPATH=/app","import os
import subprocess
import sys
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, f1_score
import joblib

def test_model_performance():
    """"""Test that the trained model achieves required accuracy and F1-score""""""
    # Check model file exists
    assert os.path.exists(""/app/ids_model.pkl""), ""Model file /app/ids_model.pkl not found""
    
    # Check train_ids.py exists and has extract_packet_features function
    assert os.path.exists(""/app/train_ids.py""), ""train_ids.py not found in /app""
    
    # Import the feature extraction function
    sys.path.insert(0, ""/app"")
    from train_ids import extract_packet_features
    
    # Load the model
    model = joblib.load(""/app/ids_model.pkl"")
    
    # Load test data
    test_labels_df = pd.read_csv(""/app/data/test/test_labels.csv"")
    
    # Extract features for all test files
    X_test = []
    y_test = []
    
    for _, row in test_labels_df.iterrows():
        pcap_path = os.path.join(""/app/data/test"", row['filename'])
        features = extract_packet_features(pcap_path)
        X_test.append(features)
        y_test.append(1 if row['label'] == 'attack' else 0)
    
    X_test = np.array(X_test)
    y_test = np.array(y_test)
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    # Check requirements
    assert accuracy >= 0.92, f""Accuracy {accuracy:.3f} is below required 0.92""
    assert f1 >= 0.88, f""F1-score {f1:.3f} is below required 0.88""

def test_attack_detection():
    """"""Test that specific attack types are detected correctly""""""
    # Check required files exist first
    assert os.path.exists(""/app/ids_model.pkl""), ""Model file not found""
    assert os.path.exists(""/app/train_ids.py""), ""train_ids.py not found""
    
    # Import the feature extraction function
    sys.path.insert(0, ""/app"")
    from train_ids import extract_packet_features
    
    # Load the model
    model = joblib.load(""/app/ids_model.pkl"")
    
    # Test each attack type
    attack_files = [
        ""/app/data/test/ddos_test.pcap"",
        ""/app/data/test/portscan_test.pcap"", 
        ""/app/data/test/sqli_test.pcap""
    ]
    
    detected = 0
    for pcap_file in attack_files:
        features = extract_packet_features(pcap_file)
        prediction = model.predict([features])[0]
        if prediction == 1:  # 1 = attack
            detected += 1
    
    # Should detect at least 2 out of 3 attack types
    assert detected >= 2, f""Only detected {detected}/3 attack types""","{""test_model_performance"": 0.7, ""test_attack_detection"": 0.3}","{""generate_pcaps.py"": ""#!/usr/bin/env python3\n\""\""\""Generate sample pcap files for training and testing\""\""\""\nimport os\nfrom scapy.all import *\nimport pandas as pd\nimport random\n\ndef create_normal_traffic(filename, num_packets=50):\n    \""\""\""Create pcap with normal HTTP/HTTPS traffic\""\""\""\n    packets = []\n    for i in range(num_packets):\n        src_port = random.randint(49152, 65535)\n        dst_port = random.choice([80, 443, 8080])\n        seq = random.randint(1000, 100000)\n        \n        # TCP SYN\n        pkt = IP(src=\""192.168.1.100\"", dst=\""93.184.216.34\"")/TCP(sport=src_port, dport=dst_port, flags=\""S\"", seq=seq)\n        packets.append(pkt)\n        \n        # TCP SYN-ACK\n        pkt = IP(src=\""93.184.216.34\"", dst=\""192.168.1.100\"")/TCP(sport=dst_port, dport=src_port, flags=\""SA\"", seq=seq+1, ack=seq+1)\n        packets.append(pkt)\n        \n        # Some data packets\n        for j in range(random.randint(2, 5)):\n            pkt = IP(src=\""192.168.1.100\"", dst=\""93.184.216.34\"")/TCP(sport=src_port, dport=dst_port, flags=\""A\"", seq=seq+j+2)/Raw(load=b\""GET / HTTP/1.1\\r\\n\"")\n            packets.append(pkt)\n    \n    wrpcap(filename, packets)\n\ndef create_ddos_traffic(filename, num_packets=100):\n    \""\""\""Create pcap with DDoS attack pattern\""\""\""\n    packets = []\n    target_ip = \""10.0.0.1\""\n    \n    for i in range(num_packets):\n        # Rapid SYN flood from multiple sources\n        src_ip = f\""192.168.{random.randint(1,254)}.{random.randint(1,254)}\""\n        src_port = random.randint(1024, 65535)\n        \n        pkt = IP(src=src_ip, dst=target_ip)/TCP(sport=src_port, dport=80, flags=\""S\"")\n        packets.append(pkt)\n    \n    wrpcap(filename, packets)\n\ndef create_port_scan_traffic(filename, num_packets=50):\n    \""\""\""Create pcap with port scanning pattern\""\""\""\n    packets = []\n    src_ip = \""192.168.1.50\""\n    target_ip = \""10.0.0.1\""\n    \n    # Sequential port scan\n    for port in range(1, 1024, 20):\n        pkt = IP(src=src_ip, dst=target_ip)/TCP(sport=45678, dport=port, flags=\""S\"")\n        packets.append(pkt)\n    \n    wrpcap(filename, packets)\n\ndef create_sql_injection_traffic(filename, num_packets=30):\n    \""\""\""Create pcap with SQL injection attempt patterns\""\""\""\n    packets = []\n    src_ip = \""192.168.1.200\""\n    dst_ip = \""10.0.0.10\""\n    \n    sql_payloads = [\n        b\""GET /login?user=admin'+OR+'1'='1 HTTP/1.1\\r\\n\"",\n        b\""POST /search?q='; DROP TABLE users; -- HTTP/1.1\\r\\n\"",\n        b\""GET /product?id=1+UNION+SELECT+password+FROM+users HTTP/1.1\\r\\n\""\n    ]\n    \n    for i in range(num_packets):\n        src_port = random.randint(49152, 65535)\n        payload = random.choice(sql_payloads)\n        \n        pkt = IP(src=src_ip, dst=dst_ip)/TCP(sport=src_port, dport=80, flags=\""PA\"")/Raw(load=payload)\n        packets.append(pkt)\n    \n    wrpcap(filename, packets)\n\n# Create directories\nos.makedirs(\""/app/data/train\"", exist_ok=True)\nos.makedirs(\""/app/data/test\"", exist_ok=True)\n\n# Generate training data\ntrain_files = []\nlabels = []\n\n# Normal traffic\nfor i in range(5):\n    filename = f\""/app/data/train/normal_{i}.pcap\""\n    create_normal_traffic(filename)\n    train_files.append(f\""normal_{i}.pcap\"")\n    labels.append(\""normal\"")\n\n# Attack traffic\nfor i in range(3):\n    filename = f\""/app/data/train/ddos_{i}.pcap\""\n    create_ddos_traffic(filename)\n    train_files.append(f\""ddos_{i}.pcap\"")\n    labels.append(\""attack\"")\n\nfor i in range(2):\n    filename = f\""/app/data/train/portscan_{i}.pcap\""\n    create_port_scan_traffic(filename)\n    train_files.append(f\""portscan_{i}.pcap\"")\n    labels.append(\""attack\"")\n\nfor i in range(2):\n    filename = f\""/app/data/train/sqli_{i}.pcap\""\n    create_sql_injection_traffic(filename)\n    train_files.append(f\""sqli_{i}.pcap\"")\n    labels.append(\""attack\"")\n\n# Create labels CSV\ndf = pd.DataFrame({\""filename\"": train_files, \""label\"": labels})\ndf.to_csv(\""/app/data/train/labels.csv\"", index=False)\n\n# Generate test data\ntest_files = []\ntest_labels = []\n\n# Test normal\nfor i in range(3):\n    filename = f\""/app/data/test/normal_test_{i}.pcap\""\n    create_normal_traffic(filename)\n    test_files.append(f\""normal_test_{i}.pcap\"")\n    test_labels.append(\""normal\"")\n\n# Test attacks\nfilename = \""/app/data/test/ddos_test.pcap\""\ncreate_ddos_traffic(filename)\ntest_files.append(\""ddos_test.pcap\"")\ntest_labels.append(\""attack\"")\n\nfilename = \""/app/data/test/portscan_test.pcap\""\ncreate_port_scan_traffic(filename)\ntest_files.append(\""portscan_test.pcap\"")\ntest_labels.append(\""attack\"")\n\nfilename = \""/app/data/test/sqli_test.pcap\""\ncreate_sql_injection_traffic(filename)\ntest_files.append(\""sqli_test.pcap\"")\ntest_labels.append(\""attack\"")\n\n# Create test labels CSV\ndf_test = pd.DataFrame({\""filename\"": test_files, \""label\"": test_labels})\ndf_test.to_csv(\""/app/data/test/test_labels.csv\"", index=False)\n\nprint(\""Sample pcap files generated successfully!\"")""}",hard,2025-07-21T14:09:05.102584,2025-07-21T14:18:56.765826,,
draft_dp_47bf88f1,Need a minimal Lua 5.4 interpreter for OpenWRT routers - must be under 150KB when stripped and support basic file I/O but drop debug/package modules. Target is MIPS (mipsel-linux-musl).,"FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

WORKDIR /build

# Install build dependencies (without multilib packages which aren't available on ARM64)
RUN apt-get update && apt-get install -y \
    wget \
    build-essential \
    git \
    make \
    libncurses5-dev \
    zlib1g-dev \
    bison \
    flex \
    unzip \
    autoconf \
    gawk \
    gettext \
    libssl-dev \
    xsltproc \
    rsync \
    python3 \
    python3-pip \
    upx-ucl \
    && rm -rf /var/lib/apt/lists/*

# Download and setup musl cross-compilation toolchain for MIPS
RUN wget https://musl.cc/mipsel-linux-musl-cross.tgz && \
    tar -xzf mipsel-linux-musl-cross.tgz -C /opt && \
    rm mipsel-linux-musl-cross.tgz

ENV PATH=""/opt/mipsel-linux-musl-cross/bin:$PATH""

# Download Lua 5.4 source
RUN wget https://www.lua.org/ftp/lua-5.4.6.tar.gz && \
    tar -xzf lua-5.4.6.tar.gz && \
    mv lua-5.4.6 lua-src && \
    rm lua-5.4.6.tar.gz

# Copy configuration files
COPY luaconf_minimal.h /build/
COPY build_config.mk /build/
COPY test_script.lua /build/

# Create a build script that needs completion
RUN echo '#!/bin/bash' > /build/build_minimal_lua.sh && \
    echo '# Minimal Lua build script - needs implementation' >> /build/build_minimal_lua.sh && \
    echo 'echo ""Build script not yet implemented""' >> /build/build_minimal_lua.sh && \
    echo 'exit 1' >> /build/build_minimal_lua.sh && \
    chmod +x /build/build_minimal_lua.sh

WORKDIR /build","import os
import subprocess
import stat

def test_lua_binary_exists_and_size():
    """"""Test that the minimal Lua binary was built and is under 150KB""""""
    lua_path = ""/build/lua-minimal""
    
    # Check if binary exists
    assert os.path.exists(lua_path), ""Minimal Lua binary not found at /build/lua-minimal""
    
    # Check if it's executable
    st = os.stat(lua_path)
    assert st.st_mode & stat.S_IXUSR, ""Lua binary is not executable""
    
    # Check size is under 150KB (153600 bytes)
    size = os.path.getsize(lua_path)
    assert size < 153600, f""Lua binary size {size} bytes exceeds 150KB limit""
    
def test_lua_runs_basic_script():
    """"""Test that the minimal Lua can execute basic scripts""""""
    # Test basic execution
    result = subprocess.run(['/build/lua-minimal', '-e', 'print(10+20)'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, ""Lua failed to execute basic arithmetic""
    assert ""30"" in result.stdout, ""Lua arithmetic result incorrect""
    
    # Test script execution
    if os.path.exists('/build/test_script.lua'):
        result = subprocess.run(['/build/lua-minimal', '/build/test_script.lua'], 
                              capture_output=True, text=True)
        assert result.returncode == 0, ""Lua failed to execute test script""
        assert ""Math test: 10 + 20 = 30"" in result.stdout, ""Script output missing math test""
        assert ""String length of 'router': 6"" in result.stdout, ""Script output missing string test""","{""test_lua_binary_exists_and_size"": 0.5, ""test_lua_runs_basic_script"": 0.5}","{""build_config.mk"": ""# Build configuration for minimal Lua\n# Partial implementation - needs completion\n\nCC = mipsel-linux-musl-gcc\nAR = mipsel-linux-musl-ar\nSTRIP = mipsel-linux-musl-strip\n\n# Basic flags - needs optimization\nCFLAGS = -Wall -O2\nLDFLAGS = -static\n\n# TODO: Add size optimization flags\n# TODO: Configure which modules to include/exclude\n# TODO: Add link-time optimization"", ""luaconf_minimal.h"": ""/*\n** Configuration for minimal Lua build\n** Started but needs completion for router environment\n*/\n\n#ifndef luaconf_minimal_h\n#define luaconf_minimal_h\n\n#include <limits.h>\n#include <stddef.h>\n\n/* Basic configuration - needs proper MIPS settings */\n#define LUA_32BITS\n#define LUA_USE_LINUX\n\n/* File I/O configuration */\n#define LUA_USE_POSIX\n\n/* TODO: Add proper cross-compilation defines for MIPS */\n/* TODO: Disable unnecessary modules */\n/* TODO: Configure for static linking */\n\n#endif"", ""test_script.lua"": ""-- Test script for router automation\n-- This would be used to verify the minimal Lua works\n\nlocal function check_network_status()\n    -- Simulated network config reading\n    local config = {\n        interface = \""br-lan\"",\n        ip = \""192.168.1.1\"",\n        status = \""up\""\n    }\n    \n    print(\""Network Status Check\"")\n    print(\""Interface: \"" .. config.interface)\n    print(\""IP: \"" .. config.ip)\n    print(\""Status: \"" .. config.status)\nend\n\n-- Basic operations test\nlocal x = 10 + 20\nprint(\""Math test: 10 + 20 = \"" .. x)\n\n-- String operations\nlocal str = \""router\""\nprint(\""String length of 'router': \"" .. #str)\n\n-- Table operations\nlocal t = {1, 2, 3}\nprint(\""Table size: \"" .. #t)\n\ncheck_network_status()""}",medium,2025-07-21T14:10:30.764634,2025-07-21T14:11:53.544886,,
draft_dp_12d1de97,Port this FORTRAN 77 integration library from SGI IRIX Makefiles to CMake and add Python bindings via f2py. Need both static/shared libs and pip-installable Python module.,"FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

RUN apt-get update && apt-get install -y \
    gfortran \
    cmake \
    python3-pip \
    python3-dev \
    python3-numpy \
    python3-setuptools \
    python3-pytest \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

RUN pip3 install --break-system-packages numpy setuptools wheel

WORKDIR /legacy_fortran

COPY simpson.f /legacy_fortran/
COPY gauss.f /legacy_fortran/
COPY intlib.f /legacy_fortran/
COPY Makefile /legacy_fortran/
COPY README /legacy_fortran/

WORKDIR /legacy_fortran","import os
import subprocess
import sys
import glob

def test_cmake_build_succeeds():
    """"""Test that CMake build system works and produces both static and shared libraries.""""""
    # Check if CMakeLists.txt exists
    assert os.path.exists('/legacy_fortran/CMakeLists.txt'), ""CMakeLists.txt not found""
    
    # Try to build with CMake
    build_dir = '/legacy_fortran/build'
    if not os.path.exists(build_dir):
        os.makedirs(build_dir)
    
    # Configure
    result = subprocess.run(['cmake', '..'], cwd=build_dir, capture_output=True, text=True)
    assert result.returncode == 0, f""CMake configuration failed: {result.stderr}""
    
    # Build
    result = subprocess.run(['make'], cwd=build_dir, capture_output=True, text=True)
    assert result.returncode == 0, f""Make failed: {result.stderr}""
    
    # Check that both static and shared libraries were created
    assert os.path.exists(f'{build_dir}/libintegrate.a'), ""Static library not created""
    assert os.path.exists(f'{build_dir}/libintegrate.so'), ""Shared library not created""

def test_python_bindings_work():
    """"""Test that Python bindings can be imported and compute correct integrals.""""""
    # First check the module exists
    module_paths = [
        '/legacy_fortran/integrate.cpython*.so',
        '/legacy_fortran/integrate.so',
        '/legacy_fortran/build/integrate.cpython*.so',
        '/legacy_fortran/build/integrate.so'
    ]
    
    found = False
    for pattern in module_paths:
        if glob.glob(pattern):
            found = True
            break
    
    assert found, ""Python module integrate.so not found in expected locations""
    
    # Test the module works correctly by running it in a subprocess
    test_script = '''
import sys
sys.path.insert(0, '/legacy_fortran')
sys.path.insert(0, '/legacy_fortran/build')

# Import the integrate module
import integrate

# Define test function (x^2)
def f(x):
    return x * x

# Test Simpson's method
result_simpson = integrate.integrate(f, 0.0, 1.0, 'SIMPSON', 1e-8)
expected = 1.0 / 3.0
error_simpson = abs(result_simpson - expected)
print(f""Simpson result: {result_simpson}, error: {error_simpson}"")
assert error_simpson < 1e-6, f""Simpson error too large: {error_simpson}""

# Test Gaussian quadrature
result_gauss = integrate.integrate(f, 0.0, 1.0, 'GAUSS', 0.0)
error_gauss = abs(result_gauss - expected)
print(f""Gauss result: {result_gauss}, error: {error_gauss}"")
assert error_gauss < 1e-10, f""Gauss error too large: {error_gauss}""

print(""All tests passed!"")
'''
    
    result = subprocess.run([sys.executable, '-c', test_script], 
                          capture_output=True, text=True)
    assert result.returncode == 0, f""Python integration test failed. stdout: {result.stdout}, stderr: {result.stderr}""","{""test_cmake_build_succeeds"": 0.5, ""test_python_bindings_work"": 0.5}","{""Makefile"": ""# Legacy Makefile for SGI IRIX Systems\n# Copyright 1994 - Numerical Analysis Group\n#\n# NOTE: This Makefile is specific to SGI IRIX 6.2\n# Requires MIPSpro Fortran 77 Compiler\n\nFC = f77\nFFLAGS = -O3 -mips4 -64 -OPT:Olimit=0 -LNO:fusion=2\nLDFLAGS = -64 -lm -lfastm\nAR = ar\nARFLAGS = -rc\n\nLIBNAME = libintegrate\nOBJS = simpson.o gauss.o intlib.o\n\nall: $(LIBNAME).a $(LIBNAME).so\n\n$(LIBNAME).a: $(OBJS)\n\t$(AR) $(ARFLAGS) $@ $(OBJS)\n\t\n$(LIBNAME).so: $(OBJS)\n\tld -64 -shared -soname $(LIBNAME).so.1 -o $@ $(OBJS) $(LDFLAGS)\n\n%.o: %.f\n\t$(FC) $(FFLAGS) -c $< -o $@\n\ntest: testprog\n\t./testprog\n\ntestprog: test.o $(LIBNAME).a\n\t$(FC) $(FFLAGS) -o $@ test.o $(LIBNAME).a $(LDFLAGS)\n\nclean:\n\trm -f *.o $(LIBNAME).a $(LIBNAME).so testprog\n\ninstall: $(LIBNAME).a $(LIBNAME).so\n\tcp $(LIBNAME).a /usr/local/lib64/\n\tcp $(LIBNAME).so /usr/local/lib64/\n\tchmod 644 /usr/local/lib64/$(LIBNAME).*"", ""README"": ""NUMERICAL INTEGRATION LIBRARY v2.3\n==================================\n\nLast updated: 1994-06-15\n\nThis library provides adaptive numerical integration routines\noriginally developed for the CRAY Y-MP at NCSA.\n\nCurrently supports:\n- Adaptive Simpson's rule\n- Gauss-Legendre quadrature (up to 64 points)\n\nBuild Instructions:\n  make            - builds static and shared libraries\n  make test       - runs test program\n  make install    - installs to /usr/local/lib64\n\nRequires SGI MIPSpro Fortran 77 compiler.\n\nContact: numlib@ncsa.uiuc.edu"", ""gauss.f"": ""C     GAUSSIAN QUADRATURE INTEGRATION\nC     IMPLEMENTS GAUSS-LEGENDRE QUADRATURE\nC\n      SUBROUTINE GAUSSQ(F, A, B, N, RESULT)\n      IMPLICIT REAL*8(A-H,O-Z)\n      EXTERNAL F\n      PARAMETER (MAXN=64)\n      DIMENSION XG(MAXN), WG(MAXN)\n      COMMON /GDATA/ XG, WG, NINIT\n      \n      IF (N .GT. MAXN) THEN\n         WRITE(*,*) 'GAUSSQ: N TOO LARGE'\n         STOP\n      ENDIF\n      \n      IF (N .NE. NINIT) THEN\n         CALL GAULEG(N, XG, WG)\n         NINIT = N\n      ENDIF\n      \n      XM = 0.5D0*(B + A)\n      XR = 0.5D0*(B - A)\n      \n      RESULT = 0.D0\n      DO 10 I = 1, N\n         X = XM + XR*XG(I)\n         RESULT = RESULT + WG(I)*F(X)\n   10 CONTINUE\n      \n      RESULT = RESULT * XR\n      \n      END\n      \nC     COMPUTE GAUSS-LEGENDRE ABSCISSAS AND WEIGHTS\n      SUBROUTINE GAULEG(N, X, W)\n      IMPLICIT REAL*8(A-H,O-Z)\n      DIMENSION X(N), W(N)\n      PARAMETER (EPS=3.D-14)\n      \n      M = (N + 1)/2\n      XM = 0.D0\n      XL = 1.D0\n      \n      DO 12 I = 1, M\n         Z = DCOS(3.141592653589793D0*(I-0.25D0)/(N+0.5D0))\n    1    CONTINUE\n         P1 = 1.D0\n         P2 = 0.D0\n         DO 11 J = 1, N\n            P3 = P2\n            P2 = P1\n            P1 = ((2.D0*J-1.D0)*Z*P2-(J-1.D0)*P3)/J\n   11    CONTINUE\n         PP = N*(Z*P1-P2)/(Z*Z-1.D0)\n         Z1 = Z\n         Z = Z1 - P1/PP\n         IF (DABS(Z-Z1) .GT. EPS) GOTO 1\n         X(I) = -Z\n         X(N+1-I) = Z\n         W(I) = 2.D0/((1.D0-Z*Z)*PP*PP)\n         W(N+1-I) = W(I)\n   12 CONTINUE\n      \n      END\n      \n      BLOCK DATA GINIT\n      IMPLICIT REAL*8(A-H,O-Z)\n      PARAMETER (MAXN=64)\n      DIMENSION XG(MAXN), WG(MAXN)\n      COMMON /GDATA/ XG, WG, NINIT\n      DATA NINIT /0/\n      END"", ""intlib.f"": ""C     MAIN INTEGRATION LIBRARY INTERFACE\nC     PROVIDES HIGH-LEVEL INTEGRATION ROUTINES\nC\n      SUBROUTINE INTEGRATE(F, A, B, METHOD, TOL, RESULT, INFO)\n      IMPLICIT REAL*8(A-H,O-Z)\n      EXTERNAL F\n      CHARACTER*(*) METHOD\n      \n      INFO = 0\n      \n      IF (METHOD .EQ. 'SIMPSON') THEN\n         CALL SIMPSN(F, A, B, TOL, RESULT, NEVAL)\n         INFO = NEVAL\n      ELSE IF (METHOD .EQ. 'GAUSS') THEN\n         N = 32\n         CALL GAUSSQ(F, A, B, N, RESULT)\n         INFO = N\n      ELSE\n         WRITE(*,*) 'UNKNOWN METHOD: ', METHOD\n         INFO = -1\n      ENDIF\n      \n      END\n      \nC     UTILITY FUNCTION TO COMPUTE INTEGRAL ERROR\n      SUBROUTINE INTERR(F, A, B, EXACT, METHOD, TOL, ERROR)\n      IMPLICIT REAL*8(A-H,O-Z)\n      EXTERNAL F\n      CHARACTER*(*) METHOD\n      \n      CALL INTEGRATE(F, A, B, METHOD, TOL, RESULT, INFO)\n      ERROR = DABS(RESULT - EXACT)\n      \n      END"", ""simpson.f"": ""C     ADAPTIVE SIMPSON'S RULE INTEGRATION\nC     LEGACY CODE FROM NUMERICAL RECIPES COLLECTION\nC     \n      SUBROUTINE SIMPSN(F, A, B, EPS, RESULT, NEVAL)\n      IMPLICIT REAL*8(A-H,O-Z)\n      EXTERNAL F\n      PARAMETER (MAXLEV=30)\n      DIMENSION S(MAXLEV), X(MAXLEV), H(MAXLEV)\n      \n      NEVAL = 0\n      LEVEL = 1\n      X(1) = A\n      H(1) = B - A\n      FA = F(A)\n      FB = F(B)\n      FC = F(A + 0.5D0*H(1))\n      NEVAL = 3\n      S(1) = H(1)*(FA + 4.D0*FC + FB)/6.D0\n      \n      RESULT = 0.D0\n      \n   10 CONTINUE\n      IF (LEVEL .LE. 0) RETURN\n      \n      XL = X(LEVEL)\n      HL = H(LEVEL)\n      SL = S(LEVEL)\n      \n      XM = XL + 0.5D0*HL\n      XR = XL + HL\n      \n      FL = F(XL)\n      FM = F(XM)\n      FR = F(XR)\n      \n      XML = XL + 0.25D0*HL\n      XMR = XL + 0.75D0*HL\n      \n      FML = F(XML)\n      FMR = F(XMR)\n      NEVAL = NEVAL + 2\n      \n      SL1 = HL*(FL + 4.D0*FML + FM)/12.D0\n      SR1 = HL*(FM + 4.D0*FMR + FR)/12.D0\n      S1 = SL1 + SR1\n      \n      ERR = DABS(S1 - SL)\n      \n      IF (ERR .LT. 15.D0*EPS .OR. LEVEL .GE. MAXLEV) THEN\n         RESULT = RESULT + S1\n         LEVEL = LEVEL - 1\n         GOTO 10\n      ENDIF\n      \n      S(LEVEL) = SR1\n      X(LEVEL) = XM\n      H(LEVEL) = 0.5D0*HL\n      \n      LEVEL = LEVEL + 1\n      X(LEVEL) = XL\n      H(LEVEL) = 0.5D0*HL\n      S(LEVEL) = SL1\n      \n      GOTO 10\n      \n      END""}",hard,2025-07-21T14:11:25.093484,2025-07-21T14:24:17.782813,,
draft_dp_52677cf4,Port the FORTRAN calculator at /app/legacy/calculator.f77 to Python. Need identical numerical outputs (within 1e-10) and exact same .DAT file formats.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

RUN apt-get update && apt-get install -y \
    gfortran \
    && rm -rf /var/lib/apt/lists/*

RUN pip install numpy scipy

RUN mkdir -p /app/legacy /app/data /app/results

# Copy the files
COPY calculator.f /app/legacy/calculator.f77
COPY CALC_INPUT.DAT /app/data/

# Compile the FORTRAN program
RUN cd /app/legacy && gfortran calculator.f77 -o calculator

# Run the calculator to generate initial results
RUN cd /app && /app/legacy/calculator

CMD [""/bin/bash""]","import os
import subprocess
import numpy as np

def test_matrix_operations():
    """"""Test that Python implementation produces correct numerical results""""""
    # First check if Python implementation exists
    assert os.path.exists('/app/calculator.py'), ""Python calculator not found""
    
    # Run the Python implementation
    result = subprocess.run(['python', '/app/calculator.py'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, f""Python calculator failed: {result.stderr}""
    
    # Check matrix multiplication result
    assert os.path.exists('/app/results/MATMUL.DAT'), ""MATMUL.DAT not found""
    
    with open('/app/results/MATMUL.DAT', 'r') as f:
        lines = f.readlines()
        assert lines[0].strip() == 'MATRIX MULTIPLICATION RESULT'
        dims = lines[1].strip().split()
        assert int(dims[0]) == 2 and int(dims[1]) == 2
        
        # Expected result of [[1,2,3]] * [[0.5,1],[1.5,2],[2.5,3]]
        # = [[1*0.5+2*1.5+3*2.5, 1*1+2*2+3*3]] = [[11, 14]]
        # [[4,5,6]] * same = [[35, 32]]
        row1_vals = [float(x) for x in lines[2].strip().split()]
        row2_vals = [float(x) for x in lines[3].strip().split()]
        
        assert abs(row1_vals[0] - 11.0) < 1e-10
        assert abs(row1_vals[1] - 14.0) < 1e-10
        assert abs(row2_vals[0] - 32.0) < 1e-10
        assert abs(row2_vals[1] - 40.0) < 1e-10
    
    # Check eigenvalues
    assert os.path.exists('/app/results/EIGENVAL.DAT'), ""EIGENVAL.DAT not found""
    
    with open('/app/results/EIGENVAL.DAT', 'r') as f:
        lines = f.readlines()
        assert lines[0].strip() == 'EIGENVALUES'
        n = int(lines[1].strip())
        assert n == 3
        eig_vals = [float(lines[i+2].strip()) for i in range(n)]
        assert abs(eig_vals[0] - 5.0) < 1e-10
        assert abs(eig_vals[1] - 3.0) < 1e-10
        assert abs(eig_vals[2] - 7.0) < 1e-10

def test_file_format():
    """"""Test that output files match exact FORTRAN format""""""
    # Check scientific notation format in MATMUL.DAT
    with open('/app/results/MATMUL.DAT', 'r') as f:
        lines = f.readlines()
        # Check that numerical values use E15.8 format
        for i in range(2, 4):  # Data lines
            vals = lines[i].strip().split()
            for val in vals:
                assert 'E' in val or 'e' in val, f""Value {val} not in scientific notation""
                assert len(val) == 15, f""Value {val} not 15 characters""
    
    # Check regression output format
    with open('/app/results/REGRESS.DAT', 'r') as f:
        lines = f.readlines()
        assert lines[0].strip() == 'LINEAR REGRESSION'
        # Check label formatting (9 chars) + E15.8
        for i in range(1, 4):
            parts = lines[i].split()
            label = parts[0]
            value = parts[1]
            assert len(label) <= 9, f""Label {label} too long""
            assert 'E' in value or 'e' in value, f""Value {value} not in scientific notation""","{""test_matrix_operations"": 0.7, ""test_file_format"": 0.3}","{""CALC_INPUT.DAT"": ""    1\n    2    3\n  1.0000  2.0000  3.0000\n  4.0000  5.0000  6.0000\n    3    2\n  0.5000  1.0000\n  1.5000  2.0000\n  2.5000  3.0000\n    2\n    3\n  5.0000  0.0000  0.0000\n  0.0000  3.0000  0.0000\n  0.0000  0.0000  7.0000\n    3\n    5\n  1.0000  2.3000\n  2.0000  4.1000\n  3.0000  6.2000\n  4.0000  7.9000\n  5.0000 10.1000"", ""calculator.f"": ""      PROGRAM CALCULATOR\n      IMPLICIT NONE\n      \n      INTEGER OPCODE, N, M, I, J, K, L, IOS\n      REAL*8 A(100,100), B(100,100), C(100,100)\n      REAL*8 EIGVAL(100), WORK(500)\n      REAL*8 X(100), Y(100), SXX, SYY, SXY, BETA, ALPHA, R2\n      CHARACTER*80 FNAME\n      \n      OPEN(10, FILE='/app/data/CALC_INPUT.DAT', STATUS='OLD')\n      \n   10 CONTINUE\n      READ(10, '(I5)', END=999) OPCODE\n      \n      IF (OPCODE .EQ. 1) THEN\nC       Matrix multiplication\n        READ(10, '(2I5)') N, M\n        DO I = 1, N\n          READ(10, '(10F8.4)') (A(I,J), J=1,M)\n        END DO\n        READ(10, '(2I5)') M, K\n        DO I = 1, M\n          READ(10, '(10F8.4)') (B(I,J), J=1,K)\n        END DO\n        \n        DO I = 1, N\n          DO J = 1, K\n            C(I,J) = 0.0D0\n            DO L = 1, M\n              C(I,J) = C(I,J) + A(I,L) * B(L,J)\n            END DO\n          END DO\n        END DO\n        \n        OPEN(20, FILE='/app/results/MATMUL.DAT', STATUS='REPLACE')\n        WRITE(20, '(A)') 'MATRIX MULTIPLICATION RESULT'\n        WRITE(20, '(2I5)') N, K\n        DO I = 1, N\n          WRITE(20, '(10E15.8)') (C(I,J), J=1,K)\n        END DO\n        CLOSE(20)\n        \n      ELSE IF (OPCODE .EQ. 2) THEN\nC       Eigenvalues (simplified - just diagonal matrix)\n        READ(10, '(I5)') N\n        DO I = 1, N\n          READ(10, '(10F8.4)') (A(I,J), J=1,N)\n        END DO\n        \n        DO I = 1, N\n          EIGVAL(I) = A(I,I)\n        END DO\n        \n        OPEN(20, FILE='/app/results/EIGENVAL.DAT', STATUS='REPLACE')\n        WRITE(20, '(A)') 'EIGENVALUES'\n        WRITE(20, '(I5)') N\n        DO I = 1, N\n          WRITE(20, '(E15.8)') EIGVAL(I)\n        END DO\n        CLOSE(20)\n        \n      ELSE IF (OPCODE .EQ. 3) THEN\nC       Linear regression\n        READ(10, '(I5)') N\n        DO I = 1, N\n          READ(10, '(2F8.4)') X(I), Y(I)\n        END DO\n        \n        SXX = 0.0D0\n        SYY = 0.0D0\n        SXY = 0.0D0\n        DO I = 1, N\n          SXX = SXX + X(I)*X(I)\n          SYY = SYY + Y(I)*Y(I)\n          SXY = SXY + X(I)*Y(I)\n        END DO\n        \n        BETA = SXY / SXX\n        ALPHA = 0.0D0\n        DO I = 1, N\n          ALPHA = ALPHA + Y(I) - BETA*X(I)\n        END DO\n        ALPHA = ALPHA / N\n        \n        R2 = (SXY * SXY) / (SXX * SYY)\n        \n        OPEN(20, FILE='/app/results/REGRESS.DAT', STATUS='REPLACE')\n        WRITE(20, '(A)') 'LINEAR REGRESSION'\n        WRITE(20, '(A,E15.8)') 'ALPHA    ', ALPHA\n        WRITE(20, '(A,E15.8)') 'BETA     ', BETA\n        WRITE(20, '(A,E15.8)') 'R-SQUARED', R2\n        CLOSE(20)\n      END IF\n      \n      GOTO 10\n      \n  999 CONTINUE\n      CLOSE(10)\n      \n      END PROGRAM CALCULATOR""}",hard,2025-07-21T16:43:08.997547,2025-07-21T16:56:21.865237,,
draft_dp_184d2304,The PostgreSQL container is configured with a read-only root filesystem for security. Deploy the custom JSON validator extension so it loads correctly and the validation functions work.,"FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

# Install PostgreSQL and development headers
RUN apt-get update && apt-get install -y \
    postgresql-16 \
    postgresql-server-dev-16 \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy extension source files
COPY jsonvalidator.c /tmp/extension/
COPY jsonvalidator.control /tmp/extension/
COPY jsonvalidator--1.0.sql /tmp/extension/
COPY Makefile /tmp/extension/

# Build the extension
WORKDIR /tmp/extension
RUN make PG_CONFIG=/usr/lib/postgresql/16/bin/pg_config && \
    make install PG_CONFIG=/usr/lib/postgresql/16/bin/pg_config

# Set up PostgreSQL
USER postgres
RUN /usr/lib/postgresql/16/bin/initdb -D /var/lib/postgresql/16/main

# Configure PostgreSQL for the extension
RUN echo ""shared_preload_libraries = ''"" >> /var/lib/postgresql/16/main/postgresql.conf && \
    echo ""listen_addresses = '*'"" >> /var/lib/postgresql/16/main/postgresql.conf

# Start PostgreSQL and create the extension
RUN /usr/lib/postgresql/16/bin/pg_ctl -D /var/lib/postgresql/16/main -o ""-c listen_addresses=''"" -w start && \
    /usr/lib/postgresql/16/bin/psql -c ""CREATE EXTENSION jsonvalidator;"" && \
    /usr/lib/postgresql/16/bin/pg_ctl -D /var/lib/postgresql/16/main -m fast -w stop

# Note: Container is not configured for read-only filesystem yet
# The agent needs to set up proper volume mounts for PostgreSQL writable directories

USER root
EXPOSE 5432

# Start script will be needed to handle read-only filesystem
CMD [""echo"", ""PostgreSQL with jsonvalidator extension installed. Configure read-only filesystem mounts.""]","import subprocess
import time
import os

def test_extension_loaded_and_functions_work():
    """"""Test that the JSON validator extension is loaded and functions work in read-only container.""""""
    # Give container time to start
    time.sleep(5)
    
    # Test that we can connect and use the extension functions
    result = subprocess.run([
        'docker', 'exec', 'postgres-readonly',
        'psql', '-U', 'postgres', '-t', '-c',
        ""SELECT json_validate_simple('{\""key\"": \""value\""}');""
    ], capture_output=True, text=True)
    
    assert result.returncode == 0, f""Failed to run validation function: {result.stderr}""
    assert 't' in result.stdout.strip(), f""Expected true, got: {result.stdout}""
    
def test_container_running_with_readonly_filesystem():
    """"""Test that PostgreSQL container is running with read-only filesystem properly configured.""""""
    # Check container is running
    result = subprocess.run([
        'docker', 'ps', '--filter', 'name=postgres-readonly', '--format', '{{.Names}}'
    ], capture_output=True, text=True)
    
    assert 'postgres-readonly' in result.stdout, ""Container not running""
    
    # Verify read-only root filesystem is configured
    result = subprocess.run([
        'docker', 'inspect', 'postgres-readonly', '--format', '{{.HostConfig.ReadonlyRootfs}}'
    ], capture_output=True, text=True)
    
    assert 'true' in result.stdout.strip().lower(), ""Container not configured with read-only filesystem""","{""test_extension_loaded_and_functions_work"": 0.6, ""test_container_running_with_readonly_filesystem"": 0.4}","{""jsonvalidator.c"": ""#include \""postgres.h\""\n#include \""fmgr.h\""\n#include \""utils/builtins.h\""\n\nPG_MODULE_MAGIC;\n\nPG_FUNCTION_INFO_V1(json_validate_simple);\n\nDatum\njson_validate_simple(PG_FUNCTION_ARGS)\n{\n    text *json_text = PG_GETARG_TEXT_P(0);\n    char *json_str = text_to_cstring(json_text);\n    \n    // Very simple validation - check for basic JSON structure\n    if (json_str && json_str[0] != '\\0') \n    {\n        char first = json_str[0];\n        int len = strlen(json_str);\n        char last = json_str[len-1];\n        \n        // Check if it starts with { or [ and ends with } or ]\n        if ((first == '{' && last == '}') || (first == '[' && last == ']'))\n        {\n            PG_RETURN_BOOL(true);\n        }\n    }\n    \n    PG_RETURN_BOOL(false);\n}\n\nPG_FUNCTION_INFO_V1(json_validate_schema);\n\nDatum  \njson_validate_schema(PG_FUNCTION_ARGS)\n{\n    text *json_text = PG_GETARG_TEXT_P(0);\n    text *schema_text = PG_GETARG_TEXT_P(1);\n    \n    // For this demo, just check if the JSON is valid (same as simple)\n    // and schema contains \""required\""\n    char *schema_str = text_to_cstring(schema_text);\n    char *json_str = text_to_cstring(json_text);\n    \n    if (strstr(schema_str, \""required\"") != NULL && json_str && json_str[0] != '\\0')\n    {\n        char first = json_str[0];\n        int len = strlen(json_str);\n        char last = json_str[len-1];\n        \n        if ((first == '{' && last == '}') || (first == '[' && last == ']'))\n        {\n            PG_RETURN_BOOL(true);\n        }\n    }\n    \n    PG_RETURN_BOOL(false);\n}"", ""Makefile"": ""MODULES = jsonvalidator\nEXTENSION = jsonvalidator\nDATA = jsonvalidator--1.0.sql\nPGFILEDESC = \""jsonvalidator - JSON validation functions\""\n\n# Disable bitcode generation\nNO_INSTALLCHECK = 1\nPGFILEDESC = \""jsonvalidator - JSON validation functions\""\n\nPG_CONFIG = pg_config\nPGXS := $(shell $(PG_CONFIG) --pgxs)\ninclude $(PGXS)"", ""jsonvalidator.control"": ""# jsonvalidator extension\ncomment = 'JSON validation functions'\ndefault_version = '1.0'\nmodule_pathname = '$libdir/jsonvalidator'\nrelocatable = true"", ""jsonvalidator--1.0.sql"": ""-- JSON Validator Extension SQL Interface\n\n-- Simple JSON validation function\nCREATE OR REPLACE FUNCTION json_validate_simple(json_doc text)\nRETURNS boolean\nAS 'MODULE_PATHNAME', 'json_validate_simple'\nLANGUAGE C STRICT;\n\n-- JSON schema validation function  \nCREATE OR REPLACE FUNCTION json_validate_schema(json_doc text, schema text)\nRETURNS boolean\nAS 'MODULE_PATHNAME', 'json_validate_schema'\nLANGUAGE C STRICT;""}",hard,2025-07-21T16:43:39.529632,2025-07-21T16:59:00.653811,,
draft_dp_a78bda25,The legacy POS system at /app/legacy/pos is writing transaction logs in a binary format. Need to migrate it to Node.js while keeping the exact same binary log format for accounting integration. Current system processes sales and calculates tax at 8.5%.,"FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

RUN apt-get update && apt-get install -y \
    nodejs \
    npm \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Create directory structure
RUN mkdir -p /app/legacy/pos /app/logs /app/src

# Copy legacy POS files
COPY legacy_pos.py /app/legacy/pos/
COPY transaction_format.txt /app/legacy/pos/

# Copy and run setup script to create sample log
COPY setup_sample_log.py /app/
RUN python3 /app/setup_sample_log.py && rm /app/setup_sample_log.py

# Create minimal package.json
RUN echo '{""name"":""pos"",""version"":""1.0.0"",""main"":""src/pos.js""}' > /app/package.json

CMD [""/bin/bash""]","import subprocess
import struct
import os
import json

def test_javascript_pos_exists():
    """"""Test that the JavaScript POS implementation exists""""""
    assert os.path.exists('/app/src/pos.js'), ""JavaScript POS implementation not found at /app/src/pos.js""

def test_binary_log_format_compatibility():
    """"""Test that new transactions maintain exact binary format""""""
    # Test data
    test_items = [
        {""sku"": ""TEST001"", ""price"": 10.00, ""quantity"": 3},
        {""sku"": ""TEST002"", ""price"": 25.50, ""quantity"": 1}
    ]
    
    # Get current log size
    original_size = os.path.getsize('/app/logs/TRANS.LOG')
    
    # Process transaction via new JavaScript system
    test_script = f""""""
const pos = require('./src/pos.js');
pos.processSale({json.dumps(test_items)});
""""""
    
    result = subprocess.run(['node', '-e', test_script], 
                          capture_output=True, text=True, cwd='/app')
    
    assert result.returncode == 0, f""Transaction processing failed: {result.stderr}""
    
    # Verify log was updated
    new_size = os.path.getsize('/app/logs/TRANS.LOG')
    assert new_size > original_size, ""Transaction log was not updated""
    
    # Read and verify the new transaction
    with open('/app/logs/TRANS.LOG', 'rb') as f:
        f.seek(original_size)  # Go to the new transaction
        
        # Read header
        header_data = f.read(23)
        assert len(header_data) == 23, ""Invalid header size""
        
        timestamp, trans_type, subtotal, tax, total, item_count = struct.unpack('<QBfffH', header_data)
        
        # Verify calculations
        expected_subtotal = 55.50
        expected_tax = round(expected_subtotal * 0.085, 2)  # 4.72
        expected_total = expected_subtotal + expected_tax  # 60.22
        
        assert trans_type == 1, f""Wrong transaction type: {trans_type}""
        assert abs(subtotal - expected_subtotal) < 0.01, f""Wrong subtotal: {subtotal}""
        assert abs(tax - expected_tax) < 0.01, f""Wrong tax: {tax}""
        assert abs(total - expected_total) < 0.01, f""Wrong total: {total}""
        assert item_count == 2, f""Wrong item count: {item_count}""","{""test_typescript_pos_exists"": 0.3, ""test_binary_log_format_compatibility"": 0.7}","{""setup_sample_log.py"": ""#!/usr/bin/env python3\nimport struct\nimport datetime\nimport os\n\n# Create sample transaction log\nos.makedirs('/app/logs', exist_ok=True)\n\nwith open('/app/logs/TRANS.LOG', 'wb') as f:\n    # Transaction 1: 2 items\n    timestamp = int(datetime.datetime(2024, 1, 15, 10, 30, 0).timestamp())\n    subtotal = 45.48\n    tax = 3.87\n    total = 49.35\n    \n    header = struct.pack('<QBfffH', timestamp, 1, subtotal, tax, total, 2)\n    f.write(header)\n    \n    # Item 1\n    f.write(struct.pack('<8sfH', b'PROD001\\x00', 19.99, 2))\n    # Item 2\n    f.write(struct.pack('<8sfH', b'PROD002\\x00', 5.50, 1))\n    \n    # Transaction 2: 1 item\n    timestamp = int(datetime.datetime(2024, 1, 15, 11, 15, 0).timestamp())\n    subtotal = 29.99\n    tax = 2.55\n    total = 32.54\n    \n    header = struct.pack('<QBfffH', timestamp, 1, subtotal, tax, total, 1)\n    f.write(header)\n    \n    # Item 1\n    f.write(struct.pack('<8sfH', b'PROD003\\x00', 29.99, 1))\n\nprint(\""Sample transaction log created\"")"", ""transaction_format.txt"": ""Legacy POS Transaction Log Format\n\nBinary format, little-endian encoding\n\nTransaction Header (23 bytes):\n- Timestamp: 8 bytes (Unix timestamp as unsigned long)\n- Type: 1 byte (1=sale, 2=return, 3=void)\n- Subtotal: 4 bytes (float)\n- Tax: 4 bytes (float)\n- Total: 4 bytes (float)\n- Item Count: 2 bytes (unsigned short)\n\nItem Record (14 bytes each):\n- SKU: 8 bytes (ASCII, null-padded)\n- Price: 4 bytes (float)\n- Quantity: 2 bytes (unsigned short)\n\nTax Rate: 8.5% (0.085)"", ""legacy_pos.py"": ""#!/usr/bin/env python3\nimport struct\nimport datetime\nimport os\n\nclass LegacyPOS:\n    def __init__(self):\n        self.log_file = \""/app/logs/TRANS.LOG\""\n        self.tax_rate = 0.085\n        \n    def process_sale(self, items):\n        subtotal = sum(item['price'] * item['quantity'] for item in items)\n        tax = round(subtotal * self.tax_rate, 2)\n        total = subtotal + tax\n        \n        transaction = {\n            'timestamp': datetime.datetime.now(),\n            'type': 1,  # 1=sale, 2=return, 3=void\n            'subtotal': subtotal,\n            'tax': tax,\n            'total': total,\n            'item_count': len(items)\n        }\n        \n        self._write_transaction(transaction, items)\n        return transaction\n    \n    def _write_transaction(self, trans, items):\n        with open(self.log_file, 'ab') as f:\n            # Header: timestamp(8) + type(1) + subtotal(4) + tax(4) + total(4) + item_count(2)\n            timestamp = int(trans['timestamp'].timestamp())\n            header = struct.pack('<QBfffH', \n                timestamp,\n                trans['type'],\n                trans['subtotal'],\n                trans['tax'],\n                trans['total'],\n                trans['item_count']\n            )\n            f.write(header)\n            \n            # Items: sku(8) + price(4) + quantity(2)\n            for item in items:\n                item_data = struct.pack('<8sfH',\n                    item['sku'].encode('ascii').ljust(8, b'\\x00'),\n                    item['price'],\n                    item['quantity']\n                )\n                f.write(item_data)\n\nif __name__ == '__main__':\n    pos = LegacyPOS()\n    \n    # Example transaction\n    items = [\n        {'sku': 'ITEM001', 'price': 19.99, 'quantity': 2},\n        {'sku': 'ITEM002', 'price': 5.50, 'quantity': 1}\n    ]\n    \n    result = pos.process_sale(items)\n    print(f\""Transaction complete. Total: ${result['total']:.2f}\"")""}",hard,2025-07-21T16:59:50.610136,2025-07-21T17:12:27.317872,,
draft_dp_e846e03e,Process the CodeSearchNet dataset and count tokens by language using CodeBERT tokenizer. Output results to /app/language_tokens.json with language names as keys and token counts as values.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

RUN pip install --no-cache-dir \
    transformers \
    datasets \
    torch \
    tqdm \
    numpy

COPY config.json /app/
COPY tokenizer_utils.py /app/

ENV HF_HOME=/app/.cache
ENV TRANSFORMERS_CACHE=/app/.cache/transformers
ENV HF_DATASETS_CACHE=/app/.cache/datasets

CMD [""/bin/bash""]","import os
import json

def test_output_file_structure():
    """"""Test that the output JSON file exists and has valid structure.""""""
    output_path = ""/app/language_tokens.json""
    assert os.path.exists(output_path), f""Output file {output_path} does not exist""
    
    with open(output_path, 'r') as f:
        data = json.load(f)
    
    assert isinstance(data, dict), ""Output should be a JSON object (dictionary)""
    assert len(data) > 0, ""Output should not be empty""

def test_language_coverage_and_values():
    """"""Test that all required languages are present with positive token counts.""""""
    expected_languages = {""python"", ""javascript"", ""go"", ""java"", ""php"", ""ruby""}
    
    with open(""/app/language_tokens.json"", 'r') as f:
        data = json.load(f)
    
    actual_languages = set(data.keys())
    assert actual_languages == expected_languages, f""Expected languages {expected_languages}, got {actual_languages}""
    
    for language, count in data.items():
        assert isinstance(count, int), f""Token count for {language} should be an integer, got {type(count)}""
        assert count > 0, f""Token count for {language} should be positive, got {count}""
    
    total_tokens = sum(data.values())
    assert total_tokens > 1000000, f""Total token count should be > 1M, got {total_tokens}""","{""test_output_file_structure"": 0.3, ""test_language_coverage_and_values"": 0.7}","{""config.json"": ""{\n  \""dataset\"": \""code_search_net\"",\n  \""languages\"": [\""python\"", \""javascript\"", \""go\"", \""java\"", \""php\"", \""ruby\""],\n  \""tokenizer\"": \""microsoft/codebert-base\"",\n  \""output_path\"": \""/app/language_tokens.json\"",\n  \""batch_size\"": 1000\n}"", ""tokenizer_utils.py"": ""from transformers import AutoTokenizer\nimport json\n\ndef load_tokenizer(model_name):\n    \""\""\""Load the tokenizer from the specified model.\""\""\""\n    return AutoTokenizer.from_pretrained(model_name)\n\ndef count_tokens(text, tokenizer):\n    \""\""\""Count the number of tokens in the given text.\""\""\""\n    tokens = tokenizer.encode(text, truncation=True, max_length=512)\n    return len(tokens)\n\ndef save_results(results, output_path):\n    \""\""\""Save the results to a JSON file.\""\""\""\n    with open(output_path, 'w') as f:\n        json.dump(results, f, indent=2)""}",hard,2025-07-21T17:07:22.614661,2025-07-21T17:19:04.320718,,
draft_dp_7c327b27,Need to evaluate our molecular GNN model on the BBBP dataset. Get ROC-AUC > 0.90 on test set and save full metrics to results/molecular_gnn_evaluation.json.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /workspace

# Install system dependencies for RDKit and molecular chemistry libraries
RUN apt-get update && apt-get install -y \
    libxrender1 \
    libxext6 \
    libgomp1 \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip install --no-cache-dir \
    torch==2.7.0 \
    torch-geometric \
    torch-scatter \
    torch-sparse \
    rdkit \
    deepchem \
    scikit-learn \
    numpy \
    pandas

# Copy project files
COPY evaluate_gnn.py /workspace/
COPY model_utils.py /workspace/
COPY pretrained_gnn.pth /workspace/
COPY requirements.txt /workspace/

# Create results directory
RUN mkdir -p /workspace/results

CMD [""/bin/bash""]","import json
import os

def test_results_file_exists_and_valid():
    """"""Test that the results file exists and contains valid JSON with required fields.""""""
    results_path = '/workspace/results/molecular_gnn_evaluation.json'
    assert os.path.exists(results_path), f""Results file not found at {results_path}""
    
    with open(results_path, 'r') as f:
        results = json.load(f)
    
    # Check required fields exist
    required_fields = ['roc_auc', 'accuracy', 'num_molecules', 'avg_nodes_per_molecule', 'class_distribution']
    for field in required_fields:
        assert field in results, f""Missing required field: {field}""
    
    # Validate data types
    assert isinstance(results['roc_auc'], (int, float)), ""roc_auc must be numeric""
    assert isinstance(results['accuracy'], (int, float)), ""accuracy must be numeric""
    assert isinstance(results['num_molecules'], int), ""num_molecules must be integer""
    assert isinstance(results['avg_nodes_per_molecule'], (int, float)), ""avg_nodes_per_molecule must be numeric""
    assert isinstance(results['class_distribution'], dict), ""class_distribution must be dict""
    
    # Check class distribution
    assert 'positive' in results['class_distribution']
    assert 'negative' in results['class_distribution']
    assert results['class_distribution']['positive'] + results['class_distribution']['negative'] == results['num_molecules']

def test_roc_auc_threshold():
    """"""Test that the model achieves ROC-AUC > 0.90 on the test set.""""""
    results_path = '/workspace/results/molecular_gnn_evaluation.json'
    assert os.path.exists(results_path), f""Results file not found at {results_path}""
    
    with open(results_path, 'r') as f:
        results = json.load(f)
    
    roc_auc = results['roc_auc']
    assert roc_auc > 0.90, f""ROC-AUC {roc_auc:.4f} does not meet threshold of 0.90""","{""test_results_file_exists_and_valid"": 0.3, ""test_roc_auc_threshold"": 0.7}","{""model_utils.py"": ""import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch_geometric.data import Data\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\n\nclass MolecularGNN(torch.nn.Module):\n    def __init__(self, num_features, hidden_dim, num_classes):\n        super(MolecularGNN, self).__init__()\n        self.conv1 = GCNConv(num_features, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n        self.dropout = torch.nn.Dropout(0.2)\n        \n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.dropout(x)\n        x = F.relu(self.conv2(x, edge_index))\n        x = self.dropout(x)\n        x = F.relu(self.conv3(x, edge_index))\n        \n        x = global_mean_pool(x, batch)\n        x = self.fc(x)\n        return x\n\n\ndef atom_features(atom):\n    \""\""\""Extract features for an atom\""\""\""\n    return [\n        atom.GetAtomicNum(),\n        atom.GetDegree(),\n        atom.GetFormalCharge(),\n        int(atom.GetHybridization()),\n        int(atom.GetIsAromatic()),\n        atom.GetMass(),\n        atom.GetTotalNumHs(),\n        atom.GetNumRadicalElectrons(),\n        int(atom.IsInRing())\n    ]\n\n\ndef smiles_to_graph(smiles):\n    \""\""\""Convert SMILES string to graph representation\""\""\""\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return None\n    \n    # Get atom features\n    atom_feats = []\n    for atom in mol.GetAtoms():\n        atom_feats.append(atom_features(atom))\n    \n    # Get bonds\n    edge_indices = []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_indices.extend([[i, j], [j, i]])\n    \n    # Create PyG data object\n    x = torch.tensor(atom_feats, dtype=torch.float)\n    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n    \n    return Data(x=x, edge_index=edge_index)"", ""requirements.txt"": ""torch==2.7.0\ntorch-geometric\ntorch-scatter\ntorch-sparse\nrdkit\ndeepchem\nscikit-learn\nnumpy\npandas"", ""evaluate_gnn.py"": ""#!/usr/bin/env python3\n\""\""\""\nEvaluate GNN model on BBBP molecular property prediction dataset\n\""\""\""\n\nimport json\nimport torch\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom deepchem.molnet import load_bbbp\nfrom rdkit import Chem\nfrom torch_geometric.data import Data, DataLoader\nimport torch.nn.functional as F\nfrom model_utils import MolecularGNN, smiles_to_graph\n\n\ndef evaluate_model(model, loader, device):\n    \""\""\""Run evaluation on the dataset\""\""\""\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            pred = torch.sigmoid(out).cpu().numpy()\n            all_preds.extend(pred)\n            all_labels.extend(batch.y.cpu().numpy())\n    \n    return np.array(all_preds), np.array(all_labels)\n\n\ndef main():\n    # Load BBBP dataset\n    print(\""Loading BBBP dataset...\"")\n    tasks, datasets, transformers = load_bbbp(featurizer='Raw', split='scaffold')\n    train_dataset, valid_dataset, test_dataset = datasets\n    \n    # Convert SMILES to graphs\n    print(\""Converting molecules to graphs...\"")\n    test_graphs = []\n    test_labels = []\n    node_counts = []\n    \n    for i in range(len(test_dataset)):\n        smiles = test_dataset.X[i][0]\n        label = test_dataset.y[i][0]\n        \n        if np.isnan(label):\n            continue\n            \n        graph = smiles_to_graph(smiles)\n        if graph is not None:\n            graph.y = torch.tensor([label], dtype=torch.float)\n            test_graphs.append(graph)\n            test_labels.append(label)\n            node_counts.append(graph.x.size(0))\n    \n    # Create data loader\n    test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n    \n    # Load pre-trained model\n    print(\""Loading pre-trained model...\"")\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = MolecularGNN(num_features=9, hidden_dim=128, num_classes=1)\n    model.load_state_dict(torch.load('pretrained_gnn.pth', map_location=device))\n    model = model.to(device)\n    \n    # Evaluate\n    print(\""Running evaluation...\"")\n    predictions, labels = evaluate_model(model, test_loader, device)\n    \n    # Calculate metrics\n    roc_auc = roc_auc_score(labels, predictions)\n    accuracy = accuracy_score(labels, (predictions > 0.5).astype(int))\n    \n    # Calculate class distribution\n    class_dist = {\n        'positive': int(np.sum(labels)),\n        'negative': int(len(labels) - np.sum(labels))\n    }\n    \n    # Prepare results\n    results = {\n        'roc_auc': float(roc_auc),\n        'accuracy': float(accuracy),\n        'num_molecules': len(test_graphs),\n        'avg_nodes_per_molecule': float(np.mean(node_counts)),\n        'class_distribution': class_dist\n    }\n    \n    # Save results\n    with open('results/molecular_gnn_evaluation.json', 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    print(f\""Evaluation complete! ROC-AUC: {roc_auc:.4f}\"")\n    print(f\""Results saved to results/molecular_gnn_evaluation.json\"")\n\n\nif __name__ == \""__main__\"":\n    main()"", ""pretrained_gnn.pth"": ""# Placeholder for pre-trained GNN model weights\n# This would normally be a binary PyTorch model file\n# The agent will need to obtain or train an appropriate model""}",extremely_hard,2025-07-22T11:01:54.556046+00:00,2025-07-22T11:02:33.091715+00:00,,
draft_dp_b775f40a,"Need to export business accounts from NA/EU regions from the user_analytics collection. Exclude all PII fields (email, phone, ssn, credit_card) and internal fields (_internal_id, _debug_info). Output to /export/analytics_cleaned.json with field mappings and stats.","FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

WORKDIR /workspace

# Install MongoDB and Python dependencies
RUN apt-get update && apt-get install -y \
    gnupg curl wget \
    python3-pip \
    python3-venv \
    libssl-dev \
    && wget -qO - https://www.mongodb.org/static/pgp/server-7.0.asc | apt-key add - \
    && echo ""deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse"" | tee /etc/apt/sources.list.d/mongodb-org-7.0.list \
    && apt-get update \
    && apt-get install -y mongodb-org \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Create export directory
RUN mkdir -p /export /var/lib/mongodb /var/log/mongodb

# Install Python dependencies
RUN pip3 install pymongo==4.0.2

# Copy setup script
COPY setup_mongodb.py /workspace/

# Initialize MongoDB and populate data
RUN mkdir -p /data/db && \
    mongod --fork --logpath /var/log/mongodb/mongod.log --dbpath /data/db && \
    sleep 5 && \
    python3 /workspace/setup_mongodb.py && \
    mongod --shutdown --dbpath /data/db

# Add a startup script to ensure MongoDB is running
RUN echo '#!/bin/bash\nmongod --fork --logpath /var/log/mongodb/mongod.log --dbpath /data/db\nsleep 2\nexec ""$@""' > /start.sh && \
    chmod +x /start.sh

ENTRYPOINT [""/start.sh""]
CMD [""/bin/bash""]","import os
import json
import csv
import subprocess

def test_export_contains_only_business_na_eu_without_pii():
    """"""Test that exported data contains only business accounts from NA/EU without PII fields.""""""
    assert os.path.exists('/export/analytics_cleaned.json'), ""Export file does not exist""
    
    # Check exported documents
    with open('/export/analytics_cleaned.json', 'r') as f:
        exported_docs = [json.loads(line) for line in f]
    
    assert len(exported_docs) > 0, ""No documents were exported""
    
    # Verify all documents match criteria and have no PII
    sensitive_fields = {'email', 'phone', 'ssn', 'credit_card', '_internal_id', '_debug_info'}
    
    for doc in exported_docs:
        # Check query criteria
        assert doc['account_type'] == 'business', f""Found non-business account: {doc.get('account_type')}""
        assert doc['region'] in ['NA', 'EU'], f""Found invalid region: {doc.get('region')}""
        
        # Check no sensitive fields
        doc_fields = set(doc.keys())
        found_sensitive = doc_fields.intersection(sensitive_fields)
        assert not found_sensitive, f""Found sensitive fields in export: {found_sensitive}""

def test_field_mappings_and_stats_are_correct():
    """"""Test that field mappings and statistics files are generated correctly.""""""
    # Check field mappings
    assert os.path.exists('/export/field_mappings.csv'), ""Field mappings file does not exist""
    
    with open('/export/field_mappings.csv', 'r') as f:
        reader = csv.DictReader(f)
        mappings = list(reader)
    
    # Verify excluded fields are marked correctly
    excluded_fields = {'email', 'phone', 'ssn', 'credit_card', '_internal_id', '_debug_info'}
    field_map = {row['field']: row['included'] for row in mappings}
    
    for field in excluded_fields:
        if field in field_map:
            assert field_map[field].lower() in ['false', 'no', 'excluded'], f""Sensitive field {field} not marked as excluded""
    
    # Check stats file
    assert os.path.exists('/export/export_stats.txt'), ""Stats file does not exist""
    
    with open('/export/export_stats.txt', 'r') as f:
        stats_content = f.read()
    
    # Basic validation of stats content
    assert 'scanned' in stats_content.lower() or 'total' in stats_content.lower(), ""Stats missing scan count""
    assert 'exported' in stats_content.lower(), ""Stats missing export count""","{""test_export_contains_only_business_na_eu_without_pii"": 0.7, ""test_field_mappings_and_stats_are_correct"": 0.3}","{""setup_mongodb.py"": ""#!/usr/bin/env python3\nimport pymongo\nimport random\nfrom datetime import datetime, timedelta\n\nclient = pymongo.MongoClient('localhost', 27017)\ndb = client['analytics_db']\ncollection = db['user_analytics']\n\n# Clear existing data\ncollection.drop()\n\n# Generate sample data\nregions = ['NA', 'EU', 'APAC', 'SA', 'AF']\naccount_types = ['business', 'personal', 'enterprise', 'trial']\n\ndocuments = []\nfor i in range(1000):\n    base_doc = {\n        '_id': i,\n        'user_id': f'usr_{i:06d}',\n        'account_type': random.choice(account_types),\n        'region': random.choice(regions),\n        'usage_metrics': {\n            'logins': random.randint(1, 500),\n            'api_calls': random.randint(0, 10000),\n            'storage_gb': round(random.uniform(0, 100), 2)\n        },\n        'created_date': datetime.now() - timedelta(days=random.randint(1, 365)),\n        'status': random.choice(['active', 'inactive', 'suspended']),\n        'plan_level': random.choice(['basic', 'pro', 'enterprise'])\n    }\n    \n    # Add sensitive fields\n    if random.random() > 0.1:  # 90% have email\n        base_doc['email'] = f'user{i}@example.com'\n    if random.random() > 0.3:  # 70% have phone\n        base_doc['phone'] = f'+1-555-{random.randint(100, 999)}-{random.randint(1000, 9999)}'\n    if random.random() > 0.5:  # 50% have ssn\n        base_doc['ssn'] = f'{random.randint(100, 999)}-{random.randint(10, 99)}-{random.randint(1000, 9999)}'\n    if random.random() > 0.6:  # 40% have credit_card\n        base_doc['credit_card'] = f'{random.randint(1000, 9999)}-{random.randint(1000, 9999)}-{random.randint(1000, 9999)}-{random.randint(1000, 9999)}'\n    \n    # Add internal fields\n    base_doc['_internal_id'] = f'int_{i:08d}'\n    base_doc['_debug_info'] = {'version': '1.0', 'server': 'prod-01'}\n    \n    documents.append(base_doc)\n\n# Insert documents\ncollection.insert_many(documents)\nprint(f\""Inserted {len(documents)} documents into user_analytics collection\"")\n\n# Create indexes for performance\ncollection.create_index('account_type')\ncollection.create_index('region')\ncollection.create_index([('account_type', 1), ('region', 1)])""}",hard,2025-07-22T11:58:04.745116+00:00,2025-07-22T12:02:32.783916+00:00,,
draft_dp_eeefb322,The inference_server.py is failing after upgrading to TF 2.x. Fix the model loading and prediction code to work with TensorFlow 2.x while keeping the exact same API and predictions.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

# Copy all application files
COPY requirements.txt /app/
COPY inference_server.py /app/
COPY create_test_model.py /app/
COPY create_test_data.py /app/
COPY capture_predictions.py /app/

# Install Python 3.7 for TensorFlow 1.x compatibility
RUN apt-get update && apt-get install -y \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update \
    && apt-get install -y python3.7 python3.7-dev python3.7-distutils \
    && curl https://bootstrap.pypa.io/pip/3.7/get-pip.py | python3.7 \
    && rm -rf /var/lib/apt/lists/*

# Install TF 1.x dependencies with Python 3.7
RUN python3.7 -m pip install --no-cache-dir -r requirements.txt

# Create the test model and data
RUN python3.7 create_test_model.py
RUN python3.7 create_test_data.py

# Start the server in background and capture predictions
RUN python3.7 inference_server.py & \
    sleep 5 && \
    python3.7 capture_predictions.py && \
    pkill -f inference_server.py

# Set Python 3.7 as default for the agent's work
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.7 1

CMD [""/bin/bash""]","import subprocess
import json
import os
import time
import requests

def test_server_runs_with_tf2():
    """"""Test that the inference server runs successfully with TensorFlow 2.x""""""
    # First check if TF 2.x is installed
    result = subprocess.run(['python', '-c', 'import tensorflow as tf; print(tf.__version__)'], 
                          capture_output=True, text=True)
    assert result.returncode == 0
    assert result.stdout.strip().startswith('2.'), f""Expected TF 2.x but got {result.stdout.strip()}""
    
    # Start the server
    proc = subprocess.Popen(['python', 'inference_server.py'], 
                           stdout=subprocess.PIPE, 
                           stderr=subprocess.PIPE)
    
    # Wait for server to be ready
    server_ready = False
    for i in range(30):
        try:
            response = requests.get('http://localhost:5000/health')
            if response.status_code == 200:
                server_ready = True
                break
        except:
            pass
        time.sleep(1)
    
    # Clean up
    proc.terminate()
    proc.wait(timeout=5)
    
    assert server_ready, ""Server failed to start with TF 2.x""

def test_predictions_match_expected():
    """"""Test that TF 2.x predictions match the expected TF 1.x predictions""""""
    # Load test data and expected predictions
    assert os.path.exists('test_images/test_data.json'), ""Test data not found""
    assert os.path.exists('test_images/expected_predictions.json'), ""Expected predictions not found""
    
    with open('test_images/test_data.json', 'r') as f:
        test_data = json.load(f)
    
    with open('test_images/expected_predictions.json', 'r') as f:
        expected_predictions = json.load(f)
    
    # Start the server
    proc = subprocess.Popen(['python', 'inference_server.py'],
                           stdout=subprocess.PIPE,
                           stderr=subprocess.PIPE)
    
    # Wait for server
    for i in range(30):
        try:
            response = requests.get('http://localhost:5000/health')
            if response.status_code == 200:
                break
        except:
            pass
        time.sleep(1)
    
    try:
        # Test each image
        for name in ['red_gradient', 'green_gradient']:  # Test 2 images
            image_base64 = test_data[name]['image_base64']
            
            response = requests.post('http://localhost:5000/predict',
                                   json={'image': image_base64})
            
            assert response.status_code == 200, f""Prediction failed for {name}""
            
            actual_predictions = response.json()['predictions']
            expected = expected_predictions[name]
            
            # Check top-5 predictions match
            assert len(actual_predictions) == 5, ""Should return top-5 predictions""
            
            for i in range(5):
                assert actual_predictions[i]['class'] == expected[i]['class'], \
                    f""Class mismatch for {name} at position {i}""
                
                # Check confidence within tolerance
                actual_conf = actual_predictions[i]['confidence']
                expected_conf = expected[i]['confidence']
                assert abs(actual_conf - expected_conf) < 1e-5, \
                    f""Confidence mismatch for {name}: {actual_conf} vs {expected_conf}""
    
    finally:
        proc.terminate()
        proc.wait(timeout=5)","{""test_server_runs_with_tf2"": 0.3, ""test_predictions_match_expected"": 0.7}","{""requirements.txt"": ""tensorflow==1.15.5\nnumpy==1.19.5\nflask==2.0.3\npillow==9.5.0\nrequests==2.31.0\nwerkzeug==2.0.3"", ""inference_server.py"": ""import tensorflow as tf\nimport numpy as np\nimport base64\nimport io\nfrom PIL import Image\nfrom flask import Flask, request, jsonify\nimport json\nimport sys\n\napp = Flask(__name__)\n\n# Load model info\nwith open('legacy_model/model_info.json', 'r') as f:\n    model_info = json.load(f)\n\n# Load the TF 1.x model\ngraph = tf.Graph()\nsess = tf.Session(graph=graph)\n\nwith graph.as_default():\n    # Load the model\n    with tf.gfile.GFile('legacy_model/model.pb', 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        tf.import_graph_def(graph_def, name='')\n    \n    # Get input and output tensors\n    input_tensor = graph.get_tensor_by_name(model_info['input_tensor_name'])\n    output_tensor = graph.get_tensor_by_name(model_info['output_tensor_name'])\n\n# Load class labels\nwith open('legacy_model/labels.json', 'r') as f:\n    labels = json.load(f)\n\ndef preprocess_image(image_data):\n    \""\""\""Preprocess image for the model\""\""\""\n    img = Image.open(io.BytesIO(image_data))\n    img = img.convert('RGB')\n    img = img.resize((224, 224))\n    img_array = np.array(img).astype(np.float32)\n    # Normalize to [-1, 1]\n    img_array = (img_array / 127.5) - 1.0\n    return np.expand_dims(img_array, axis=0)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    try:\n        data = request.get_json()\n        \n        if 'image' not in data:\n            return jsonify({'error': 'No image provided'}), 400\n        \n        # Decode base64 image\n        image_data = base64.b64decode(data['image'])\n        \n        # Preprocess the image\n        processed_image = preprocess_image(image_data)\n        \n        # Run inference\n        predictions = sess.run(output_tensor, feed_dict={input_tensor: processed_image})\n        \n        # Get top 5 predictions\n        top_5_indices = np.argsort(predictions[0])[-5:][::-1]\n        \n        results = []\n        for idx in top_5_indices:\n            results.append({\n                'class': labels[str(idx)],\n                'confidence': float(predictions[0][idx])\n            })\n        \n        return jsonify({'predictions': results})\n    \n    except Exception as e:\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/health', methods=['GET'])\ndef health():\n    return jsonify({'status': 'healthy'})\n\nif __name__ == '__main__':\n    print(\""Starting inference server on port 5000...\"")\n    app.run(host='0.0.0.0', port=5000)"", ""create_test_model.py"": ""import tensorflow as tf\nimport numpy as np\nimport json\nimport os\n\n# Create a simple test model in TF 1.x format\ntf.compat.v1.disable_eager_execution()\n\n# Create directories\nos.makedirs('legacy_model', exist_ok=True)\n\n# Define a simple model\ninput_tensor = tf.compat.v1.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_1')\n\n# Simple convnet layers\nx = tf.compat.v1.layers.conv2d(input_tensor, 32, 3, activation=tf.nn.relu, name='conv1')\nx = tf.compat.v1.layers.max_pooling2d(x, 2, 2)\nx = tf.compat.v1.layers.conv2d(x, 64, 3, activation=tf.nn.relu, name='conv2')\nx = tf.compat.v1.layers.max_pooling2d(x, 2, 2)\nx = tf.compat.v1.layers.flatten(x)\nx = tf.compat.v1.layers.dense(x, 128, activation=tf.nn.relu, name='dense1')\noutput_tensor = tf.compat.v1.layers.dense(x, 1000, name='predictions/Softmax')\n\n# Apply softmax\noutput_tensor = tf.nn.softmax(output_tensor, name='predictions/Softmax_output')\n\n# Save the graph\nwith tf.compat.v1.Session() as sess:\n    sess.run(tf.compat.v1.global_variables_initializer())\n    \n    # Save as .pb file\n    graph_def = sess.graph.as_graph_def()\n    with open('legacy_model/model.pb', 'wb') as f:\n        f.write(graph_def.SerializeToString())\n    \n    # Save variables (even though this simple model doesn't have trainable vars in the traditional sense)\n    saver = tf.compat.v1.train.Saver()\n    saver.save(sess, 'legacy_model/variables/variables')\n\n# Save model info\nmodel_info = {\n    'input_tensor_name': 'input_1:0',\n    'output_tensor_name': 'predictions/Softmax_output:0'\n}\n\nwith open('legacy_model/model_info.json', 'w') as f:\n    json.dump(model_info, f, indent=2)\n\n# Create dummy labels\nlabels = {}\nfor i in range(1000):\n    labels[str(i)] = f\""class_{i}\""\n\nwith open('legacy_model/labels.json', 'w') as f:\n    json.dump(labels, f, indent=2)\n\nprint(\""Test model created successfully!\"")"", ""create_test_data.py"": ""import numpy as np\nfrom PIL import Image\nimport json\nimport base64\nimport io\nimport os\n\n# Create test_images directory\nos.makedirs('test_images', exist_ok=True)\n\n# Create test images with different patterns\ntest_patterns = [\n    ('red_gradient', lambda x, y: (255 * x // 224, 0, 0)),\n    ('green_gradient', lambda x, y: (0, 255 * y // 224, 0)),\n    ('diagonal_pattern', lambda x, y: (128 + 127 * (x + y) // 448, 128 - 64 * (x - y) // 224, 200))\n]\n\ntest_data = {}\n\nfor i, (name, pattern_func) in enumerate(test_patterns):\n    # Create image\n    img_array = np.zeros((224, 224, 3), dtype=np.uint8)\n    for x in range(224):\n        for y in range(224):\n            img_array[y, x] = pattern_func(x, y)\n    \n    img = Image.fromarray(img_array)\n    \n    # Save as file\n    img_path = f'test_images/{name}.png'\n    img.save(img_path)\n    \n    # Convert to base64\n    buffer = io.BytesIO()\n    img.save(buffer, format='PNG')\n    img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n    \n    test_data[name] = {\n        'image_base64': img_base64,\n        'file_path': img_path\n    }\n\n# Save test data\nwith open('test_images/test_data.json', 'w') as f:\n    json.dump(test_data, f, indent=2)\n\nprint(\""Test images created successfully!\"")"", ""capture_predictions.py"": ""import requests\nimport json\nimport time\nimport sys\n\n# Wait for server to start\nprint(\""Waiting for server to start...\"")\nfor i in range(30):\n    try:\n        response = requests.get('http://localhost:5000/health')\n        if response.status_code == 200:\n            print(\""Server is ready!\"")\n            break\n    except:\n        pass\n    time.sleep(1)\nelse:\n    print(\""Server failed to start!\"")\n    sys.exit(1)\n\n# Load test data\nwith open('test_images/test_data.json', 'r') as f:\n    test_data = json.load(f)\n\n# Capture predictions for each test image\nexpected_predictions = {}\n\nfor name, data in test_data.items():\n    response = requests.post('http://localhost:5000/predict', \n                           json={'image': data['image_base64']})\n    \n    if response.status_code == 200:\n        predictions = response.json()['predictions']\n        expected_predictions[name] = predictions\n        print(f\""Captured predictions for {name}\"")\n    else:\n        print(f\""Failed to get predictions for {name}: {response.status_code}\"")\n\n# Save expected predictions\nwith open('test_images/expected_predictions.json', 'w') as f:\n    json.dump(expected_predictions, f, indent=2)\n\nprint(\""Expected predictions saved!\"")""}",hard,2025-07-22T11:58:12.957377+00:00,2025-07-22T11:58:12.988821+00:00,,
draft_dp_252c2aa5,"Getting ""Permission denied"" when running npm build. The Python build script can't execute. Fix it so npm run build works.","FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

RUN apt-get update && apt-get install -y nodejs npm && rm -rf /var/lib/apt/lists/*

RUN useradd -m -s /bin/bash user

WORKDIR /app

COPY package.json /app/
COPY build.py /app/
COPY src /app/src/

RUN chmod 644 /app/build.py && \
    chown root:root /app && \
    chmod 755 /app

USER user

WORKDIR /app","import os
import subprocess

def test_build_completes_successfully():
    """"""Test that npm build runs without permission errors""""""
    result = subprocess.run(['npm', 'run', 'build'], 
                          capture_output=True, text=True, cwd='/app')
    assert result.returncode == 0, f""Build failed with: {result.stderr}""
    assert ""Permission denied"" not in result.stderr

def test_dist_directory_created():
    """"""Test that the build output directory and file exist""""""
    assert os.path.exists('/app/dist'), ""dist directory was not created""
    assert os.path.exists('/app/dist/app.py'), ""app.py was not created""","{""test_build_completes_successfully"": 0.6, ""test_dist_directory_created"": 0.4}","{""build.py"": ""#!/usr/bin/env python3\nimport os\nimport shutil\n\nprint(\""Starting build process...\"")\n\n# Create output directory\nos.makedirs('dist', exist_ok=True)\n\n# Read source files\nwith open('src/main.py', 'r') as f:\n    content = f.read()\n\n# Write output\noutput_path = 'dist/app.py'\nwith open(output_path, 'w') as f:\n    f.write(\""# Built application\\n\"")\n    f.write(content)\n\nprint(\""Build completed successfully!\"")"", ""package.json"": ""{\n  \""name\"": \""myapp\"",\n  \""version\"": \""1.0.0\"",\n  \""description\"": \""Application build\"",\n  \""scripts\"": {\n    \""build\"": \""python3 build.py\"",\n    \""clean\"": \""rm -rf dist\""\n  },\n  \""author\"": \""\"",\n  \""license\"": \""MIT\""\n}"", ""src/main.py"": ""def process_data(input_data):\n    \""\""\""Process input data and return results.\""\""\""\n    return [x * 2 for x in input_data]\n\ndef main():\n    data = [1, 2, 3, 4, 5]\n    result = process_data(data)\n    print(f\""Processed: {result}\"")\n\nif __name__ == \""__main__\"":\n    main()""}",medium,2025-07-22T15:08:38.981529+00:00,2025-07-22T15:38:22.084510+00:00,,
draft_dp_ed920fe7,Tried upgrading our Spring Boot service from 2.7 to 3.0 but it won't start - getting namespace errors and security config issues. Need to complete the migration so the API works again.,"FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

# Install Java 17 and Maven
RUN apt-get update && \
    apt-get install -y openjdk-17-jdk maven curl && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy the Spring Boot project files
COPY pom.xml /app/
COPY src /app/src/

CMD [""/bin/bash""]","import subprocess
import time
import json

def test_application_starts_successfully():
    """"""Test that the Spring Boot application starts without errors after migration.""""""
    # Build the project
    build_result = subprocess.run(
        [""mvn"", ""clean"", ""package"", ""-DskipTests""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    
    # Check build succeeded
    assert build_result.returncode == 0, f""Build failed: {build_result.stderr}""
    
    # Start the application
    proc = subprocess.Popen(
        [""java"", ""-jar"", ""target/demo-0.0.1-SNAPSHOT.jar""],
        cwd=""/app"",
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True
    )
    
    # Wait for startup (check for success within 30 seconds)
    started = False
    start_time = time.time()
    
    while time.time() - start_time < 30:
        line = proc.stdout.readline()
        if ""Started DemoApplication"" in line:
            started = True
            break
        if proc.poll() is not None:
            # Process exited early
            stdout, stderr = proc.communicate()
            assert False, f""Application failed to start: {stderr}""
    
    proc.terminate()
    proc.wait()
    
    assert started, ""Application did not start successfully within 30 seconds""

def test_api_endpoints_work():
    """"""Test that API endpoints work correctly with JWT authentication.""""""
    # Start the application in background
    proc = subprocess.Popen(
        [""mvn"", ""spring-boot:run""],
        cwd=""/app"",
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True
    )
    
    # Wait for application to be ready
    time.sleep(15)
    
    try:
        # Register a user
        register_result = subprocess.run(
            [""curl"", ""-X"", ""POST"", ""http://localhost:8080/api/auth/register"",
             ""-H"", ""Content-Type: application/json"",
             ""-d"", '{""username"":""testuser"",""password"":""password123"",""email"":""test@example.com""}'],
            capture_output=True,
            text=True
        )
        assert register_result.returncode == 0
        
        # Login to get JWT token
        login_result = subprocess.run(
            [""curl"", ""-X"", ""POST"", ""http://localhost:8080/api/auth/login"",
             ""-H"", ""Content-Type: application/json"",
             ""-d"", '{""username"":""testuser"",""password"":""password123""}'],
            capture_output=True,
            text=True
        )
        assert login_result.returncode == 0
        token_response = json.loads(login_result.stdout)
        assert ""token"" in token_response
        
        # Access protected endpoint with token
        users_result = subprocess.run(
            [""curl"", ""-X"", ""GET"", ""http://localhost:8080/api/users"",
             ""-H"", f""Authorization: Bearer {token_response['token']}""],
            capture_output=True,
            text=True
        )
        assert users_result.returncode == 0
        users = json.loads(users_result.stdout)
        assert isinstance(users, list)
        
    finally:
        proc.terminate()
        proc.wait()","{""test_application_starts_successfully"": 0.6, ""test_api_endpoints_work"": 0.4}","{""pom.xml"": ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n<project xmlns=\""http://maven.apache.org/POM/4.0.0\"" xmlns:xsi=\""http://www.w3.org/2001/XMLSchema-instance\""\n    xsi:schemaLocation=\""http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>3.0.0</version>\n        <relativePath/>\n    </parent>\n    <groupId>com.example</groupId>\n    <artifactId>demo</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>demo</name>\n    <description>Demo project for Spring Boot</description>\n    <properties>\n        <java.version>17</java.version>\n    </properties>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-data-jpa</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-security</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>com.h2database</groupId>\n            <artifactId>h2</artifactId>\n            <scope>runtime</scope>\n        </dependency>\n        <!-- Old JWT library that uses javax namespace -->\n        <dependency>\n            <groupId>io.jsonwebtoken</groupId>\n            <artifactId>jjwt</artifactId>\n            <version>0.9.1</version>\n        </dependency>\n        <!-- Old validation API -->\n        <dependency>\n            <groupId>javax.validation</groupId>\n            <artifactId>validation-api</artifactId>\n            <version>2.0.1.Final</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n</project>"", ""src/main/resources/application.properties"": ""spring.h2.console.enabled=true\nspring.datasource.url=jdbc:h2:mem:testdb\nspring.jpa.hibernate.ddl-auto=create\nspring.jpa.show-sql=true\njwt.secret=mysecretkey\nserver.port=8080"", ""src/main/java/com/example/demo/SecurityConfig.java"": ""package com.example.demo;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.config.http.SessionCreationPolicy;\nimport org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;\nimport org.springframework.security.crypto.password.PasswordEncoder;\nimport org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter;\n\n@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n    \n    @Autowired\n    private JwtAuthenticationFilter jwtAuthenticationFilter;\n    \n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.csrf().disable()\n            .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n            .and()\n            .authorizeRequests()\n                .antMatchers(\""/api/auth/**\"").permitAll()\n                .anyRequest().authenticated()\n            .and()\n            .addFilterBefore(jwtAuthenticationFilter, UsernamePasswordAuthenticationFilter.class);\n    }\n    \n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n}"", ""src/main/java/com/example/demo/User.java"": ""package com.example.demo;\n\nimport javax.persistence.*;\nimport javax.validation.constraints.NotBlank;\nimport javax.validation.constraints.Email;\n\n@Entity\n@Table(name = \""users\"")\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    @NotBlank\n    private String username;\n    \n    @NotBlank\n    private String password;\n    \n    @Email\n    private String email;\n    \n    public User() {}\n    \n    public User(String username, String password, String email) {\n        this.username = username;\n        this.password = password;\n        this.email = email;\n    }\n    \n    public Long getId() {\n        return id;\n    }\n    \n    public void setId(Long id) {\n        this.id = id;\n    }\n    \n    public String getUsername() {\n        return username;\n    }\n    \n    public void setUsername(String username) {\n        this.username = username;\n    }\n    \n    public String getPassword() {\n        return password;\n    }\n    \n    public void setPassword(String password) {\n        this.password = password;\n    }\n    \n    public String getEmail() {\n        return email;\n    }\n    \n    public void setEmail(String email) {\n        this.email = email;\n    }\n}"", ""src/main/java/com/example/demo/AuthController.java"": ""package com.example.demo;\n\nimport io.jsonwebtoken.Jwts;\nimport io.jsonwebtoken.SignatureAlgorithm;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.security.crypto.password.PasswordEncoder;\nimport org.springframework.web.bind.annotation.*;\n\nimport javax.validation.Valid;\nimport java.util.Date;\nimport java.util.HashMap;\nimport java.util.Map;\n\n@RestController\n@RequestMapping(\""/api/auth\"")\npublic class AuthController {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Autowired\n    private PasswordEncoder passwordEncoder;\n    \n    @Value(\""${jwt.secret:mysecretkey}\"")\n    private String jwtSecret;\n    \n    @PostMapping(\""/login\"")\n    public Map<String, String> login(@RequestBody Map<String, String> loginRequest) {\n        String username = loginRequest.get(\""username\"");\n        String password = loginRequest.get(\""password\"");\n        \n        User user = userRepository.findByUsername(username);\n        \n        if (user != null && passwordEncoder.matches(password, user.getPassword())) {\n            String token = Jwts.builder()\n                .setSubject(username)\n                .setIssuedAt(new Date())\n                .setExpiration(new Date(System.currentTimeMillis() + 86400000)) // 24 hours\n                .signWith(SignatureAlgorithm.HS512, jwtSecret)\n                .compact();\n            \n            Map<String, String> response = new HashMap<>();\n            response.put(\""token\"", token);\n            return response;\n        }\n        \n        throw new RuntimeException(\""Invalid credentials\"");\n    }\n    \n    @PostMapping(\""/register\"")\n    public User register(@Valid @RequestBody User user) {\n        user.setPassword(passwordEncoder.encode(user.getPassword()));\n        return userRepository.save(user);\n    }\n}"", ""src/main/java/com/example/demo/UserRepository.java"": ""package com.example.demo;\n\nimport org.springframework.data.jpa.repository.JpaRepository;\nimport org.springframework.stereotype.Repository;\n\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    User findByUsername(String username);\n}"", ""src/main/java/com/example/demo/JwtAuthenticationFilter.java"": ""package com.example.demo;\n\nimport io.jsonwebtoken.Claims;\nimport io.jsonwebtoken.Jwts;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.security.authentication.UsernamePasswordAuthenticationToken;\nimport org.springframework.security.core.context.SecurityContextHolder;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.filter.OncePerRequestFilter;\n\nimport javax.servlet.FilterChain;\nimport javax.servlet.ServletException;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport java.io.IOException;\nimport java.util.ArrayList;\n\n@Component\npublic class JwtAuthenticationFilter extends OncePerRequestFilter {\n    \n    @Value(\""${jwt.secret:mysecretkey}\"")\n    private String jwtSecret;\n    \n    @Override\n    protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, \n                                  FilterChain filterChain) throws ServletException, IOException {\n        \n        String token = extractToken(request);\n        \n        if (token != null) {\n            try {\n                Claims claims = Jwts.parser()\n                    .setSigningKey(jwtSecret)\n                    .parseClaimsJws(token)\n                    .getBody();\n                \n                String username = claims.getSubject();\n                \n                UsernamePasswordAuthenticationToken auth = \n                    new UsernamePasswordAuthenticationToken(username, null, new ArrayList<>());\n                \n                SecurityContextHolder.getContext().setAuthentication(auth);\n            } catch (Exception e) {\n                // Invalid token\n            }\n        }\n        \n        filterChain.doFilter(request, response);\n    }\n    \n    private String extractToken(HttpServletRequest request) {\n        String bearerToken = request.getHeader(\""Authorization\"");\n        if (bearerToken != null && bearerToken.startsWith(\""Bearer \"")) {\n            return bearerToken.substring(7);\n        }\n        return null;\n    }\n}"", ""src/main/java/com/example/demo/DemoApplication.java"": ""package com.example.demo;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class DemoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(DemoApplication.class, args);\n    }\n}"", ""src/main/java/com/example/demo/UserController.java"": ""package com.example.demo;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.*;\nimport javax.validation.Valid;\nimport java.util.List;\n\n@RestController\n@RequestMapping(\""/api/users\"")\npublic class UserController {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @GetMapping\n    public List<User> getAllUsers() {\n        return userRepository.findAll();\n    }\n    \n    @PostMapping\n    public User createUser(@Valid @RequestBody User user) {\n        return userRepository.save(user);\n    }\n    \n    @GetMapping(\""/{id}\"")\n    public User getUserById(@PathVariable Long id) {\n        return userRepository.findById(id)\n            .orElseThrow(() -> new RuntimeException(\""User not found\""));\n    }\n}""}",extremely_hard,2025-07-22T15:09:43.501188+00:00,2025-07-22T15:28:04.141245+00:00,,
draft_dp_f95c80ae,Build a service that streams MongoDB oplog changes via REST API (port 5000) and WebSocket. Needs to handle resume tokens for fault tolerance and support filtering by collection/operation type.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

# Install MongoDB
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    && wget -qO- https://www.mongodb.org/static/pgp/server-7.0.asc | tee /etc/apt/trusted.gpg.d/server-7.0.asc \
    && echo ""deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse"" | tee /etc/apt/sources.list.d/mongodb-org-7.0.list \
    && apt-get update \
    && apt-get install -y mongodb-org \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Create MongoDB data directory
RUN mkdir -p /data/db /var/log

WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt /app/
RUN pip install -r requirements.txt

# Copy all scripts
COPY data_generator.py /app/
COPY startup.sh /app/
RUN chmod +x /app/startup.sh /app/data_generator.py

# Create workspace directory
RUN mkdir -p /workspace

# Run startup script when container starts
RUN echo '#!/bin/bash\n/app/startup.sh\nexec ""$@""' > /entrypoint.sh && \
    chmod +x /entrypoint.sh

ENTRYPOINT [""/entrypoint.sh""]
CMD [""/bin/bash""]

# Set working directory
WORKDIR /workspace","import subprocess
import json
import time

def test_oplog_streaming_api_running():
    """"""Test that the oplog streaming API is running on port 5000.""""""
    # Give service time to start if needed
    time.sleep(2)
    
    # Check if API is responding
    result = subprocess.run(
        ['curl', '-s', '-f', 'http://localhost:5000/changes/position'],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0, f""API not responding on port 5000: {result.stderr}""
    
    # Verify response is valid JSON with oplog position info
    try:
        data = json.loads(result.stdout)
        assert 'position' in data or 'timestamp' in data or 'resume_token' in data, \
            f""Response missing position info: {result.stdout}""
    except json.JSONDecodeError:
        assert False, f""Invalid JSON response: {result.stdout}""

def test_oplog_changes_captured():
    """"""Test that recent database changes are captured by the streaming service.""""""
    # Query recent changes endpoint
    result = subprocess.run(
        ['curl', '-s', '-f', 'http://localhost:5000/changes/recent?limit=10'],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0, f""Failed to get recent changes: {result.stderr}""
    
    # Verify we have captured some changes
    try:
        data = json.loads(result.stdout)
        # Should be a list of changes or have a 'changes' key
        if isinstance(data, dict):
            changes = data.get('changes', [])
        else:
            changes = data
            
        assert isinstance(changes, list), f""Expected list of changes, got: {type(changes)}""
        assert len(changes) > 0, ""No database changes captured - oplog streaming not working""
        
        # Verify change structure
        if changes:
            change = changes[0]
            # Check for basic oplog fields
            assert any(key in change for key in ['operation', 'op', 'operationType', 'ns', 'collection']), \
                f""Change missing operation info: {change}""
                
    except json.JSONDecodeError:
        assert False, f""Invalid JSON response: {result.stdout}""","{""test_oplog_streaming_api_running"": 0.4, ""test_oplog_changes_captured"": 0.6}","{""requirements.txt"": ""pymongo==4.6.1\nmotor==3.3.2\nfastapi==0.108.0\nuvicorn==0.25.0\nwebsockets==12.0\npydantic==2.5.3"", ""startup.sh"": ""#!/bin/bash\n# Start MongoDB and initialize replica set\n\n# Start MongoDB in background\nmongod --replSet rs0 --bind_ip_all --port 27017 --dbpath /data/db --logpath /var/log/mongodb.log --fork\n\n# Wait for MongoDB to be ready\nsleep 5\n\n# Initialize replica set\nmongosh --eval \""\ntry {\n  rs.initiate({\n    _id: 'rs0',\n    members: [{ _id: 0, host: 'localhost:27017' }]\n  })\n} catch(e) {\n  print('Replica set already initialized')\n}\n\""\n\n# Wait for replica set to be ready\nsleep 5\n\n# Create initial data if needed\nmongosh --eval \""\nuse sampledb\nif (db.users.countDocuments({}) == 0) {\n  db.users.insertMany([\n    { name: 'Alice', age: 30, email: 'alice@example.com' },\n    { name: 'Bob', age: 25, email: 'bob@example.com' },\n    { name: 'Charlie', age: 35, email: 'charlie@example.com' }\n  ])\n  db.products.insertMany([\n    { name: 'Laptop', price: 999.99, category: 'Electronics' },\n    { name: 'Mouse', price: 29.99, category: 'Electronics' },\n    { name: 'Desk', price: 299.99, category: 'Furniture' }\n  ])\n  print('Sample data created')\n}\n\""\n\n# Start data generator in background\nnohup python /app/data_generator.py > /var/log/data_generator.log 2>&1 &\n\necho \""MongoDB replica set and data generator started\"""", ""data_generator.py"": ""#!/usr/bin/env python3\n\""\""\""Generates continuous CRUD operations on MongoDB to create oplog activity.\""\""\""\nimport time\nimport random\nfrom pymongo import MongoClient\nfrom datetime import datetime\n\ndef generate_data():\n    client = MongoClient('mongodb://localhost:27017/?replicaSet=rs0')\n    db = client.sampledb\n    \n    operations = ['insert', 'update', 'delete']\n    collections = ['users', 'products']\n    \n    counter = 0\n    while True:\n        try:\n            collection_name = random.choice(collections)\n            collection = db[collection_name]\n            operation = random.choice(operations)\n            \n            if operation == 'insert':\n                if collection_name == 'users':\n                    doc = {\n                        'name': f'User{counter}',\n                        'age': random.randint(18, 65),\n                        'email': f'user{counter}@example.com',\n                        'created_at': datetime.now()\n                    }\n                else:\n                    doc = {\n                        'name': f'Product{counter}',\n                        'price': round(random.uniform(10, 1000), 2),\n                        'category': random.choice(['Electronics', 'Furniture', 'Clothing']),\n                        'created_at': datetime.now()\n                    }\n                collection.insert_one(doc)\n                print(f\""Inserted into {collection_name}: {doc['name']}\"")\n                \n            elif operation == 'update':\n                # Update a random document\n                docs = list(collection.find().limit(10))\n                if docs:\n                    doc = random.choice(docs)\n                    update = {'$set': {'updated_at': datetime.now()}}\n                    if collection_name == 'users':\n                        update['$inc'] = {'age': 1}\n                    else:\n                        update['$inc'] = {'price': round(random.uniform(-10, 10), 2)}\n                    collection.update_one({'_id': doc['_id']}, update)\n                    print(f\""Updated in {collection_name}: {doc.get('name', 'unknown')}\"")\n                    \n            elif operation == 'delete':\n                # Delete oldest document if collection has more than 10\n                if collection.count_documents({}) > 10:\n                    oldest = collection.find_one(sort=[('_id', 1)])\n                    if oldest:\n                        collection.delete_one({'_id': oldest['_id']})\n                        print(f\""Deleted from {collection_name}: {oldest.get('name', 'unknown')}\"")\n            \n            counter += 1\n            time.sleep(random.uniform(0.5, 2.0))  # Random delay between operations\n            \n        except Exception as e:\n            print(f\""Error in data generator: {e}\"")\n            time.sleep(5)\n\nif __name__ == '__main__':\n    print(\""Starting MongoDB data generator...\"")\n    generate_data()""}",extremely_hard,2025-07-22T15:10:06.360984+00:00,2025-07-22T15:16:23.423327+00:00,,
draft_dp_47ae770b,"The warehouse team just uploaded their physical counts in warehouse_counts.csv. Can you compare these against our system inventory in system_inventory.db and calculate the average discrepancy percentage? Save the result to inventory_discrepancy.txt as just the percentage number (like ""4.23"").","FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

# Install pandas
RUN pip install pandas==2.2.0

# Copy data files
COPY warehouse_counts.csv /app/
COPY system_inventory.db /app/

CMD [""bash""]","import os
import subprocess

def test_discrepancy_file_exists():
    """"""Test that inventory_discrepancy.txt was created.""""""
    assert os.path.exists('/app/inventory_discrepancy.txt'), ""inventory_discrepancy.txt file not found""

def test_discrepancy_value_correct():
    """"""Test that the calculated average discrepancy is correct.""""""
    # Read the result
    with open('/app/inventory_discrepancy.txt', 'r') as f:
        content = f.read().strip()
    
    # Convert to float
    try:
        discrepancy = float(content)
    except ValueError:
        assert False, f""Invalid percentage format: '{content}'""
    
    # The expected average discrepancy based on our test data
    # Excluding EFG123 (0 system count) and SKUs only in one source
    # Average of all matching SKUs with non-zero system counts: ~6.33
    assert 6.0 <= discrepancy <= 7.0, f""Average discrepancy {discrepancy}% outside expected range [6.0, 7.0]""","{""test_discrepancy_file_exists"": 0.3, ""test_discrepancy_value_correct"": 0.7}","{""warehouse_counts.csv"": ""SKU,physical_count\nABC123,145\nDEF456,89\nGHI789,234\nJKL012,0\nMNO345,567\nPQR678,123\nSTU901,456\nVWX234,78\nYZA567,912\nBCD890,345\nEFG123,0\nHIJ456,234\nKLM789,567\nNOP012,123\nQRS345,890\nTUV678,456\nWXY901,234\nZAB234,678\nCDE567,345\nFGH890,123""}",hard,2025-07-22T18:00:12.312798+00:00,2025-07-22T18:00:36.312098+00:00,,
draft_dp_42c2dc56,"The rpy2 interface is failing with ""VECTOR_ELT() can only be applied to a 'list', not a 'closure'"" when converting our DESeq2 results to pandas. Need this fixed ASAP - analysis pipeline is down.","FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

# Install R and system dependencies
RUN apt-get update && apt-get install -y \
    r-base \
    r-base-dev \
    libcurl4-openssl-dev \
    libssl-dev \
    libxml2-dev \
    libfontconfig1-dev \
    libharfbuzz-dev \
    libfribidi-dev \
    libfreetype6-dev \
    libpng-dev \
    libtiff5-dev \
    libjpeg-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Set R environment variables for rpy2
ENV R_HOME=/usr/lib/R
ENV LD_LIBRARY_PATH=""${R_HOME}/lib:${LD_LIBRARY_PATH}""

# Install Python packages
RUN pip install pandas numpy && \
    pip install rpy2

# Install R packages
RUN R -e ""install.packages('BiocManager', repos='https://cloud.r-project.org/')"" && \
    R -e ""BiocManager::install(c('DESeq2', 'BiocGenerics'), ask=FALSE, update=FALSE)""

# Create directory structure
RUN mkdir -p /data /results

# Copy files
COPY generate_test_data.R /scripts/
COPY analysis_pipeline.py /app/

# Generate test data
RUN Rscript /scripts/generate_test_data.R

WORKDIR /app","import os
import pandas as pd
import subprocess

def test_deseq2_results_exist():
    """"""Test that DESeq2 results file was created successfully.""""""
    # Run the analysis pipeline
    result = subprocess.run(
        ['python3', '/app/analysis_pipeline.py'],
        capture_output=True,
        text=True
    )
    
    # Check if results file exists
    assert os.path.exists('/results/deseq2_results.csv'), ""DESeq2 results file not created""
    
    # Verify it's a valid CSV with expected columns
    df = pd.read_csv('/results/deseq2_results.csv', index_col=0)
    expected_columns = ['baseMean', 'log2FoldChange', 'lfcSE', 'stat', 'pvalue', 'padj']
    
    for col in expected_columns:
        assert col in df.columns, f""Missing expected column: {col}""
    
    # Check we have results for genes
    assert len(df) > 0, ""No gene results in output""
    assert len(df) == 1000, f""Expected 1000 genes, got {len(df)}""

def test_differential_expression_detected():
    """"""Test that differential expression was properly detected.""""""
    # Read results
    df = pd.read_csv('/results/deseq2_results.csv', index_col=0)
    
    # Check that we have significant results
    significant = df[df['padj'] < 0.05]
    assert len(significant) > 0, ""No significantly differentially expressed genes found""
    
    # The first 50 genes should be among the most significant
    top_50_indices = df.nsmallest(50, 'padj').index
    gene_numbers = [int(idx.replace('Gene', '')) for idx in top_50_indices]
    
    # At least 30 of the first 50 genes should be detected as significant
    detected_from_first_50 = sum(1 for g in gene_numbers if g <= 50)
    assert detected_from_first_50 >= 30, f""Only {detected_from_first_50} of the first 50 genes detected as significant""","{""test_deseq2_results_exist"": 0.6, ""test_differential_expression_detected"": 0.4}","{""generate_test_data.R"": ""#!/usr/bin/env Rscript\n# Generate test data for DESeq2 analysis\n\nlibrary(DESeq2)\n\n# Create count matrix\nset.seed(42)\nn_genes <- 1000\nn_samples <- 6\n\ncounts <- matrix(\n    as.integer(rnbinom(n_genes * n_samples, mu=100, size=1)),\n    nrow=n_genes,\n    ncol=n_samples\n)\n\n# Add some differentially expressed genes\ncounts[1:50, 4:6] <- counts[1:50, 4:6] * 5\n\nrownames(counts) <- paste0(\""Gene\"", 1:n_genes)\ncolnames(counts) <- paste0(\""Sample\"", 1:n_samples)\n\n# Create sample info\nsample_info <- data.frame(\n    condition = factor(rep(c(\""control\"", \""treated\""), each=3)),\n    row.names = colnames(counts)\n)\n\n# Save data\nwrite.csv(counts, \""/data/counts.csv\"")\nwrite.csv(sample_info, \""/data/samples.csv\"")\n\nprint(\""Test data generated successfully!\"")"", ""analysis_pipeline.py"": ""#!/usr/bin/env python3\n\""\""\""Bioinformatics analysis pipeline using R packages through rpy2.\""\""\""\n\nimport pandas as pd\nimport numpy as np\nimport rpy2.robjects as ro\nfrom rpy2.robjects import pandas2ri\nfrom rpy2.robjects.packages import importr\nfrom rpy2.robjects.conversion import localconverter\n\n# Activate pandas conversion\npandas2ri.activate()\n\n# Import R packages\nbase = importr('base')\nstats = importr('stats')\ndeseq2 = importr('DESeq2')\n\ndef run_deseq2_analysis(count_matrix_file, sample_info_file):\n    \""\""\""Run DESeq2 differential expression analysis.\""\""\""\n    # Load data\n    counts = pd.read_csv(count_matrix_file, index_col=0)\n    samples = pd.read_csv(sample_info_file, index_col=0)\n    \n    # Convert to R objects\n    with localconverter(ro.default_converter + pandas2ri.converter):\n        r_counts = ro.conversion.py2rpy(counts)\n        r_samples = ro.conversion.py2rpy(samples)\n    \n    # Create DESeqDataSet\n    dds = deseq2.DESeqDataSetFromMatrix(\n        countData=r_counts,\n        colData=r_samples,\n        design=ro.Formula('~ condition')\n    )\n    \n    # Run DESeq2\n    dds = deseq2.DESeq(dds)\n    \n    # Get results\n    res = deseq2.results(dds)\n    \n    # This is where it breaks - converting results back to pandas\n    # Error: VECTOR_ELT() can only be applied to a 'list', not a 'closure'\n    with localconverter(ro.default_converter + pandas2ri.converter):\n        results_df = ro.conversion.rpy2py(res)\n    \n    return results_df\n\nif __name__ == \""__main__\"":\n    # Run analysis\n    results = run_deseq2_analysis(\n        \""/data/counts.csv\"",\n        \""/data/samples.csv\""\n    )\n    \n    # Save results\n    results.to_csv(\""/results/deseq2_results.csv\"")\n    print(\""Analysis complete!\"")""}",hard,2025-07-22T21:12:26.627976+00:00,2025-07-22T21:20:22.423438+00:00,,
draft_dp_f35d42f5,"RStudio Server needs to be set up with SSL for our analysts. Create users analyst1/benchmarkpass1 and analyst2/benchmarkpass2, configure HTTPS on port 8787, and add an R script for analyst1 and an Rmd report for analyst2.","FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

WORKDIR /root

# Install basic dependencies for simulating RStudio setup
RUN apt-get update && apt-get install -y \
    openssl \
    sudo \
    && rm -rf /var/lib/apt/lists/*

# Create directory structure for RStudio config
RUN mkdir -p /etc/rstudio
COPY rserver.conf /etc/rstudio/

# Create a mock rstudio server script
COPY mock_rstudio.sh /usr/local/bin/rserver
RUN chmod +x /usr/local/bin/rserver

# Set working directory
WORKDIR /root","import os
import subprocess
import pwd

def test_ssl_configuration_complete():
    """"""Test that SSL certificates and configuration are properly set up""""""
    # Check SSL certificate exists
    assert os.path.exists('/etc/rstudio/ssl/cert.pem'), ""SSL certificate not found""
    assert os.path.exists('/etc/rstudio/ssl/key.pem'), ""SSL key not found""
    
    # Check that SSL is enabled in config
    with open('/etc/rstudio/rserver.conf', 'r') as f:
        config = f.read()
        assert 'ssl-enabled=1' in config, ""SSL not enabled in configuration""
        assert 'ssl-certificate=/etc/rstudio/ssl/cert.pem' in config, ""SSL certificate path not configured""
        assert 'ssl-certificate-key=/etc/rstudio/ssl/key.pem' in config, ""SSL key path not configured""

def test_users_created():
    """"""Test that both analyst users exist""""""
    # Check analyst1 user exists
    try:
        user1 = pwd.getpwnam('analyst1')
        assert user1.pw_dir == '/home/analyst1', ""analyst1 home directory incorrect""
    except KeyError:
        assert False, ""User analyst1 does not exist""
    
    # Check analyst2 user exists
    try:
        user2 = pwd.getpwnam('analyst2')
        assert user2.pw_dir == '/home/analyst2', ""analyst2 home directory incorrect""
    except KeyError:
        assert False, ""User analyst2 does not exist""","{""test_ssl_configuration_complete"": 0.6, ""test_users_created"": 0.4}","{""rserver.conf"": ""# RStudio Server configuration\n# Basic config without SSL setup\nwww-address=0.0.0.0\nwww-port=8787"", ""mock_rstudio.sh"": ""#!/bin/bash\n# Mock RStudio Server script\necho \""Mock RStudio Server - not actually running\""""}",medium,2025-07-22T21:32:02.308789+00:00,2025-07-22T21:43:23.667012+00:00,,
draft_dp_d4935d46,"Set up Grafana with HTTPS on port 3000 (admin password: benchmarkpass) and connect it to Prometheus. Need a ""System Metrics Dashboard"" showing CPU/memory usage.","FROM ubuntu:22.04

WORKDIR /monitoring

# Install tmux and asciinema (required by t-bench)
RUN apt-get update && apt-get install -y \
    tmux \
    asciinema \
    wget \
    curl \
    openssl \
    supervisor \
    procps \
    net-tools \
    gnupg \
    python3-requests \
    python3-urllib3 \
    && rm -rf /var/lib/apt/lists/*

# Install Prometheus
RUN wget https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz && \
    tar xvf prometheus-2.45.0.linux-amd64.tar.gz && \
    mv prometheus-2.45.0.linux-amd64 /opt/prometheus && \
    rm prometheus-2.45.0.linux-amd64.tar.gz

# Install Node Exporter for metrics
RUN wget https://github.com/prometheus/node_exporter/releases/download/v1.6.1/node_exporter-1.6.1.linux-amd64.tar.gz && \
    tar xvf node_exporter-1.6.1.linux-amd64.tar.gz && \
    mv node_exporter-1.6.1.linux-amd64/node_exporter /opt/prometheus/ && \
    rm -rf node_exporter-1.6.1.linux-amd64*

# Install Grafana
RUN wget -q -O - https://packages.grafana.com/gpg.key | apt-key add - && \
    echo ""deb https://packages.grafana.com/oss/deb stable main"" > /etc/apt/sources.list.d/grafana.list && \
    apt-get update && \
    apt-get install -y grafana && \
    rm -rf /var/lib/apt/lists/*

# Copy configuration files
COPY prometheus.yml /opt/prometheus/
COPY supervisord.conf /etc/supervisor/conf.d/
COPY grafana.ini /etc/grafana/

# Create directory for Grafana provisioning
RUN mkdir -p /etc/grafana/provisioning/datasources


# Start services with supervisor
CMD [""/usr/bin/supervisord"", ""-n"", ""-c"", ""/etc/supervisor/supervisord.conf""]","import subprocess
import json
import time
import requests
import urllib3

# Disable SSL warnings for self-signed certificates
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def test_grafana_https_with_auth():
    """"""Test that Grafana is running on HTTPS port 3000 with authentication""""""
    # Test HTTPS endpoint with admin credentials
    try:
        response = requests.get(
            'https://localhost:3000/api/health', 
            auth=('admin', 'benchmarkpass'),
            verify=False,
            timeout=5
        )
        assert response.status_code == 200
        assert response.json()['database'] == 'ok'
    except requests.exceptions.SSLError:
        # If we get SSL error, it means HTTP is being used instead of HTTPS
        assert False, ""Grafana is not using HTTPS""
    except requests.exceptions.ConnectionError:
        assert False, ""Cannot connect to Grafana on port 3000""

def test_dashboard_exists():
    """"""Test that the System Metrics Dashboard exists with required panels""""""
    # Get all dashboards
    response = requests.get(
        'https://localhost:3000/api/search?type=dash-db',
        auth=('admin', 'benchmarkpass'),
        verify=False,
        timeout=5
    )
    assert response.status_code == 200
    
    dashboards = response.json()
    dashboard_names = [d['title'] for d in dashboards]
    assert 'System Metrics Dashboard' in dashboard_names
    
    # Get the specific dashboard
    dashboard_uid = None
    for d in dashboards:
        if d['title'] == 'System Metrics Dashboard':
            dashboard_uid = d['uid']
            break
    
    assert dashboard_uid is not None
    
    # Fetch dashboard details
    response = requests.get(
        f'https://localhost:3000/api/dashboards/uid/{dashboard_uid}',
        auth=('admin', 'benchmarkpass'),
        verify=False,
        timeout=5
    )
    assert response.status_code == 200
    
    dashboard = response.json()['dashboard']
    panels = dashboard.get('panels', [])
    
    # Check that we have at least 3 panels (CPU, memory, text)
    assert len(panels) >= 3
    
    # Check panel titles/content
    panel_titles = [p.get('title', '').lower() for p in panels]
    assert any('cpu' in title for title in panel_titles)
    assert any('memory' in title for title in panel_titles)","{""test_grafana_https_with_auth"": 0.5, ""test_dashboard_exists"": 0.5}","{""grafana.ini"": ""[server]\nhttp_addr = 0.0.0.0\nhttp_port = 3000\nprotocol = http\n\n[security]\nadmin_user = admin"", ""supervisord.conf"": ""[supervisord]\nnodaemon=true\n\n[program:prometheus]\ncommand=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data\ndirectory=/opt/prometheus\nautostart=true\nautorestart=true\nstderr_logfile=/var/log/prometheus.err.log\nstdout_logfile=/var/log/prometheus.out.log\n\n[program:node_exporter]\ncommand=/opt/prometheus/node_exporter\nautostart=true\nautorestart=true\nstderr_logfile=/var/log/node_exporter.err.log\nstdout_logfile=/var/log/node_exporter.out.log\n\n[program:grafana]\ncommand=/usr/sbin/grafana-server --config=/etc/grafana/grafana.ini --homepath=/usr/share/grafana\ndirectory=/usr/share/grafana\nautostart=true\nautorestart=true\nstderr_logfile=/var/log/grafana.err.log\nstdout_logfile=/var/log/grafana.out.log"", ""prometheus.yml"": ""global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n  \n  - job_name: 'node'\n    static_configs:\n      - targets: ['localhost:9100']""}",medium,2025-07-22T21:32:33.419498+00:00,2025-07-22T21:38:44.514219+00:00,,
draft_dp_b2f38533,The STM32F4 firmware build is broken after updating CMake. Need to fix the cross-compilation setup - build fails with toolchain errors.,"FROM ubuntu:22.04

# Install tmux, asciinema, and ARM toolchain
RUN apt-get update && apt-get install -y \
    tmux \
    asciinema \
    cmake \
    make \
    gcc-arm-none-eabi \
    libnewlib-arm-none-eabi \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /firmware

# Copy project files
COPY CMakeLists.txt /firmware/
COPY toolchain.cmake /firmware/
COPY src/ /firmware/src/
COPY hal/ /firmware/hal/
COPY startup/ /firmware/startup/
COPY linker_script.ld /firmware/

# Create build directory
RUN mkdir -p build

WORKDIR /firmware/build","import os
import subprocess
import re

def test_cmake_build_succeeds():
    """"""Test that CMake configuration and build completes successfully.""""""
    # Run cmake configuration
    config_result = subprocess.run(
        ['cmake', '-DCMAKE_TOOLCHAIN_FILE=../toolchain.cmake', '..'],
        cwd='/firmware/build',
        capture_output=True,
        text=True
    )
    assert config_result.returncode == 0, f""CMake configuration failed: {config_result.stderr}""
    
    # Run make
    build_result = subprocess.run(
        ['make', '-j4'],
        cwd='/firmware/build',
        capture_output=True,
        text=True
    )
    assert build_result.returncode == 0, f""Build failed: {build_result.stderr}""

def test_build_artifacts_generated():
    """"""Test that the expected build artifacts are generated.""""""
    # Check for ELF file
    assert os.path.exists('/firmware/build/stm32f4_firmware.elf'), ""ELF file not generated""
    
    # Check for binary file
    assert os.path.exists('/firmware/build/stm32f4_firmware.bin'), ""Binary file not generated""
    
    # Check for map file
    assert os.path.exists('/firmware/build/stm32f4_firmware.map'), ""Map file not generated""
    
    # Verify binary is not empty and reasonable size for embedded firmware
    bin_size = os.path.getsize('/firmware/build/stm32f4_firmware.bin')
    assert bin_size > 1000, f""Binary file too small: {bin_size} bytes""
    assert bin_size < 1048576, f""Binary file too large: {bin_size} bytes""","{""test_cmake_build_succeeds"": 0.6, ""test_build_artifacts_generated"": 0.4}","{""toolchain.cmake"": ""# Broken ARM toolchain configuration\nset(CMAKE_SYSTEM_NAME Linux)\nset(CMAKE_SYSTEM_PROCESSOR arm)\n\n# Incomplete toolchain specification\nset(CMAKE_C_COMPILER arm-none-eabi-gcc)\nset(CMAKE_CXX_COMPILER arm-none-eabi-g++)\n\n# Missing critical settings for embedded systems"", ""CMakeLists.txt"": ""cmake_minimum_required(VERSION 3.22)\nproject(stm32f4_firmware C CXX ASM)\n\nset(CMAKE_C_STANDARD 11)\nset(CMAKE_CXX_STANDARD 17)\n\n# Broken toolchain setup - missing proper cross-compilation configuration\nset(CMAKE_C_COMPILER arm-none-eabi-gcc)\nset(CMAKE_CXX_COMPILER arm-none-eabi-g++)\n\n# Missing proper flags\nset(CMAKE_C_FLAGS \""-Wall -Wextra\"")\nset(CMAKE_CXX_FLAGS \""-Wall -Wextra\"")\n\n# Source files\nset(SOURCES\n    src/main.cpp\n    src/system_init.c\n    hal/gpio.c\n    hal/uart.c\n    startup/startup_stm32f407xx.s\n)\n\n# Create executable\nadd_executable(${PROJECT_NAME}.elf ${SOURCES})\n\n# Missing linker configuration\ntarget_link_options(${PROJECT_NAME}.elf PRIVATE\n    -Wl,-Map=${PROJECT_NAME}.map\n)\n\n# Generate binary\nadd_custom_command(TARGET ${PROJECT_NAME}.elf POST_BUILD\n    COMMAND ${CMAKE_OBJCOPY} -O binary ${PROJECT_NAME}.elf ${PROJECT_NAME}.bin\n    COMMENT \""Generating binary file\""\n)"", ""linker_script.ld"": ""MEMORY\n{\n  FLASH (rx)  : ORIGIN = 0x08000000, LENGTH = 1024K\n  RAM   (xrw) : ORIGIN = 0x20000000, LENGTH = 128K\n  CCMRAM (xrw): ORIGIN = 0x10000000, LENGTH = 64K\n}\n\n_estack = 0x20020000;\n\nSECTIONS\n{\n  .isr_vector :\n  {\n    . = ALIGN(4);\n    KEEP(*(.isr_vector))\n    . = ALIGN(4);\n  } >FLASH\n\n  .text :\n  {\n    . = ALIGN(4);\n    *(.text)\n    *(.text*)\n    *(.glue_7)\n    *(.glue_7t)\n    *(.eh_frame)\n\n    KEEP (*(.init))\n    KEEP (*(.fini))\n\n    . = ALIGN(4);\n    _etext = .;\n  } >FLASH\n\n  .rodata :\n  {\n    . = ALIGN(4);\n    *(.rodata)\n    *(.rodata*)\n    . = ALIGN(4);\n  } >FLASH\n\n  .ARM.extab   : { *(.ARM.extab* .gnu.linkonce.armextab.*) } >FLASH\n  .ARM : {\n    __exidx_start = .;\n    *(.ARM.exidx*)\n    __exidx_end = .;\n  } >FLASH\n\n  .preinit_array     :\n  {\n    PROVIDE_HIDDEN (__preinit_array_start = .);\n    KEEP (*(.preinit_array*))\n    PROVIDE_HIDDEN (__preinit_array_end = .);\n  } >FLASH\n  .init_array :\n  {\n    PROVIDE_HIDDEN (__init_array_start = .);\n    KEEP (*(SORT(.init_array.*)))\n    KEEP (*(.init_array*))\n    PROVIDE_HIDDEN (__init_array_end = .);\n  } >FLASH\n  .fini_array :\n  {\n    PROVIDE_HIDDEN (__fini_array_start = .);\n    KEEP (*(SORT(.fini_array.*)))\n    KEEP (*(.fini_array*))\n    PROVIDE_HIDDEN (__fini_array_end = .);\n  } >FLASH\n\n  _sidata = LOADADDR(.data);\n\n  .data : \n  {\n    . = ALIGN(4);\n    _sdata = .;\n    *(.data)\n    *(.data*)\n\n    . = ALIGN(4);\n    _edata = .;\n  } >RAM AT> FLASH\n\n  .ccmram :\n  {\n    . = ALIGN(4);\n    _sccmram = .;\n    *(.ccmram)\n    *(.ccmram*)\n    \n    . = ALIGN(4);\n    _eccmram = .;\n  } >CCMRAM\n\n  . = ALIGN(4);\n  .bss :\n  {\n    _sbss = .;\n    __bss_start__ = _sbss;\n    *(.bss)\n    *(.bss*)\n    *(COMMON)\n\n    . = ALIGN(4);\n    _ebss = .;\n    __bss_end__ = _ebss;\n  } >RAM\n\n  ._user_heap_stack :\n  {\n    . = ALIGN(8);\n    PROVIDE ( end = . );\n    PROVIDE ( _end = . );\n    . = . + _Min_Heap_Size;\n    . = . + _Min_Stack_Size;\n    . = ALIGN(8);\n  } >RAM\n\n  /DISCARD/ :\n  {\n    libc.a ( * )\n    libm.a ( * )\n    libgcc.a ( * )\n  }\n\n  .ARM.attributes 0 : { *(.ARM.attributes) }\n}\n\n_Min_Heap_Size = 0x200;\n_Min_Stack_Size = 0x400;"", ""hal/gpio.c"": ""#include \""gpio.h\""\n#include <stdint.h>\n\n#define GPIOD_BASE      0x40020C00\n#define RCC_AHB1ENR     *((volatile uint32_t*)0x40023830)\n\ntypedef struct {\n    volatile uint32_t MODER;\n    volatile uint32_t OTYPER;\n    volatile uint32_t OSPEEDR;\n    volatile uint32_t PUPDR;\n    volatile uint32_t IDR;\n    volatile uint32_t ODR;\n    volatile uint32_t BSRR;\n    volatile uint32_t LCKR;\n    volatile uint32_t AFR[2];\n} GPIO_TypeDef;\n\n#define GPIOD ((GPIO_TypeDef*)GPIOD_BASE)\n\nvoid GPIO_Init(void) {\n    // Enable GPIOD clock\n    RCC_AHB1ENR |= (1 << 3);\n    \n    // Configure PD12-15 as outputs (onboard LEDs)\n    GPIOD->MODER |= (1 << 24) | (1 << 26) | (1 << 28) | (1 << 30);\n}\n\nvoid GPIO_ToggleLED(void) {\n    GPIOD->ODR ^= (1 << 12);\n}"", ""hal/uart.h"": ""#ifndef UART_H\n#define UART_H\n\n#ifdef __cplusplus\nextern \""C\"" {\n#endif\n\nvoid UART_Init(void);\nvoid UART_SendString(const char* str);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif"", ""hal/gpio.h"": ""#ifndef GPIO_H\n#define GPIO_H\n\n#ifdef __cplusplus\nextern \""C\"" {\n#endif\n\nvoid GPIO_Init(void);\nvoid GPIO_ToggleLED(void);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif"", ""hal/uart.c"": ""#include \""uart.h\""\n#include <stdint.h>\n\n#define USART2_BASE     0x40004400\n#define RCC_APB1ENR     *((volatile uint32_t*)0x40023840)\n#define RCC_AHB1ENR     *((volatile uint32_t*)0x40023830)\n#define GPIOA_BASE      0x40020000\n\ntypedef struct {\n    volatile uint32_t SR;\n    volatile uint32_t DR;\n    volatile uint32_t BRR;\n    volatile uint32_t CR1;\n    volatile uint32_t CR2;\n    volatile uint32_t CR3;\n    volatile uint32_t GTPR;\n} USART_TypeDef;\n\ntypedef struct {\n    volatile uint32_t MODER;\n    volatile uint32_t OTYPER;\n    volatile uint32_t OSPEEDR;\n    volatile uint32_t PUPDR;\n    volatile uint32_t IDR;\n    volatile uint32_t ODR;\n    volatile uint32_t BSRR;\n    volatile uint32_t LCKR;\n    volatile uint32_t AFR[2];\n} GPIO_TypeDef;\n\n#define USART2 ((USART_TypeDef*)USART2_BASE)\n#define GPIOA  ((GPIO_TypeDef*)GPIOA_BASE)\n\nvoid UART_Init(void) {\n    // Enable clocks\n    RCC_AHB1ENR |= (1 << 0);  // GPIOA\n    RCC_APB1ENR |= (1 << 17); // USART2\n    \n    // Configure PA2/PA3 as USART2 TX/RX\n    GPIOA->MODER &= ~((3 << 4) | (3 << 6));\n    GPIOA->MODER |= (2 << 4) | (2 << 6);\n    GPIOA->AFR[0] |= (7 << 8) | (7 << 12);\n    \n    // Configure USART2: 115200 baud @ 84MHz\n    USART2->BRR = 0x2D9;  // 84000000 / 115200\n    USART2->CR1 = (1 << 13) | (1 << 3) | (1 << 2);  // Enable, TX, RX\n}\n\nvoid UART_SendString(const char* str) {\n    while(*str) {\n        while(!(USART2->SR & (1 << 7)));\n        USART2->DR = *str++;\n    }\n}"", ""startup/startup_stm32f407xx.s"": "".syntax unified\n.cpu cortex-m4\n.fpu softvfp\n.thumb\n\n.global g_pfnVectors\n.global Default_Handler\n\n.word _sidata\n.word _sdata\n.word _edata\n.word _sbss\n.word _ebss\n\n.section .text.Reset_Handler\n.weak Reset_Handler\n.type Reset_Handler, %function\nReset_Handler:\n  movs r1, #0\n  b LoopCopyDataInit\n\nCopyDataInit:\n  ldr r3, =_sidata\n  ldr r3, [r3, r1]\n  str r3, [r0, r1]\n  adds r1, r1, #4\n\nLoopCopyDataInit:\n  ldr r0, =_sdata\n  ldr r3, =_edata\n  adds r2, r0, r1\n  cmp r2, r3\n  bcc CopyDataInit\n  ldr r2, =_sbss\n  b LoopFillZerobss\n\nFillZerobss:\n  movs r3, #0\n  str r3, [r2], #4\n\nLoopFillZerobss:\n  ldr r3, = _ebss\n  cmp r2, r3\n  bcc FillZerobss\n\n  bl SystemInit\n  bl main\n  bx lr\n.size Reset_Handler, .-Reset_Handler\n\n.section .text.Default_Handler,\""ax\"",%progbits\nDefault_Handler:\nInfinite_Loop:\n  b Infinite_Loop\n.size Default_Handler, .-Default_Handler\n\n.section .isr_vector,\""a\"",%progbits\n.type g_pfnVectors, %object\n.size g_pfnVectors, .-g_pfnVectors\n\ng_pfnVectors:\n  .word _estack\n  .word Reset_Handler\n  .word NMI_Handler\n  .word HardFault_Handler\n  .word MemManage_Handler\n  .word BusFault_Handler\n  .word UsageFault_Handler\n  .word 0\n  .word 0\n  .word 0\n  .word 0\n  .word SVC_Handler\n  .word DebugMon_Handler\n  .word 0\n  .word PendSV_Handler\n  .word SysTick_Handler\n\n  .weak NMI_Handler\n  .thumb_set NMI_Handler,Default_Handler\n\n  .weak HardFault_Handler\n  .thumb_set HardFault_Handler,Default_Handler\n\n  .weak MemManage_Handler\n  .thumb_set MemManage_Handler,Default_Handler\n\n  .weak BusFault_Handler\n  .thumb_set BusFault_Handler,Default_Handler\n\n  .weak UsageFault_Handler\n  .thumb_set UsageFault_Handler,Default_Handler\n\n  .weak SVC_Handler\n  .thumb_set SVC_Handler,Default_Handler\n\n  .weak DebugMon_Handler\n  .thumb_set DebugMon_Handler,Default_Handler\n\n  .weak PendSV_Handler\n  .thumb_set PendSV_Handler,Default_Handler\n\n  .weak SysTick_Handler\n  .thumb_set SysTick_Handler,Default_Handler"", ""src/system_init.c"": ""#include <stdint.h>\n\n#define RCC_BASE        0x40023800\n#define RCC_CR          *((volatile uint32_t*)(RCC_BASE + 0x00))\n#define RCC_CFGR        *((volatile uint32_t*)(RCC_BASE + 0x08))\n#define RCC_PLLCFGR     *((volatile uint32_t*)(RCC_BASE + 0x04))\n\nvoid SystemInit(void) {\n    // Enable HSE\n    RCC_CR |= (1 << 16);\n    while(!(RCC_CR & (1 << 17)));\n    \n    // Configure PLL\n    RCC_PLLCFGR = 0x24003010;  // HSE as PLL source, 168MHz\n    \n    // Enable PLL\n    RCC_CR |= (1 << 24);\n    while(!(RCC_CR & (1 << 25)));\n    \n    // Switch to PLL\n    RCC_CFGR |= 0x02;\n    while((RCC_CFGR & 0x0C) != 0x08);\n}"", ""src/main.cpp"": ""#include <stdint.h>\n#include \""../hal/gpio.h\""\n#include \""../hal/uart.h\""\n\nextern \""C\"" void SystemInit(void);\n\nvoid delay(uint32_t ms) {\n    volatile uint32_t count = ms * 1000;\n    while(count--);\n}\n\nint main() {\n    SystemInit();\n    \n    GPIO_Init();\n    UART_Init();\n    \n    const char* msg = \""STM32F4 Running\\n\"";\n    \n    while(1) {\n        GPIO_ToggleLED();\n        UART_SendString(msg);\n        delay(1000);\n    }\n    \n    return 0;\n}""}",hard,2025-07-22T21:34:58.039892+00:00,2025-07-22T21:39:40.749895+00:00,,
draft_dp_749ba561,Our Electron app won't build after upgrading to Node 18. Getting native module errors with sqlite3 and the renderer process webpack is failing. Need to fix the build and update for latest Electron security practices.,"FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y \
    curl \
    build-essential \
    python3 \
    python3-pip \
    libsqlite3-dev \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

# Install Node.js 18
RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - && \
    apt-get install -y nodejs

WORKDIR /app

# Copy application files
COPY package.json /app/
COPY package-lock.json /app/
COPY webpack.main.config.js /app/
COPY webpack.renderer.config.js /app/
COPY electron-builder.json /app/
COPY src /app/src/
COPY native /app/native/

# Initial npm install will fail due to native module issues
RUN npm install || true

# Install pytest for test validation
RUN pip3 install pytest","import subprocess
import os
import json

def test_electron_build_succeeds():
    """"""Test that the Electron app builds successfully with Node 18.""""""
    # Run the build command
    result = subprocess.run(['npm', 'run', 'build'], 
                          capture_output=True, text=True, cwd='/app')
    
    # Build should succeed
    assert result.returncode == 0, f""Build failed: {result.stderr}""
    
    # Check that webpack output files exist
    assert os.path.exists('/app/dist/main.js'), ""Main process bundle not created""
    assert os.path.exists('/app/dist/renderer.js'), ""Renderer process bundle not created""

def test_electron_security_updated():
    """"""Test that Electron security settings are properly configured.""""""
    # Read the main process file to check security settings
    with open('/app/src/main/index.js', 'r') as f:
        main_content = f.read()
    
    # Check that contextIsolation is enabled (security best practice)
    assert 'contextIsolation: true' in main_content, ""Context isolation not enabled""
    
    # Check that nodeIntegration is disabled (security best practice)
    assert 'nodeIntegration: false' in main_content, ""Node integration should be disabled""
    
    # Check for preload script configuration
    assert 'preload:' in main_content, ""Preload script not configured""","{""test_electron_build_succeeds"": 0.6, ""test_electron_security_updated"": 0.4}","{""webpack.renderer.config.js"": ""const path = require('path');\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\n\nmodule.exports = {\n  entry: './src/renderer/index.js',\n  target: 'electron-renderer',\n  output: {\n    path: path.resolve(__dirname, 'dist'),\n    filename: 'renderer.js'\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        use: {\n          loader: 'babel-loader',\n          options: {\n            presets: ['@babel/preset-env']\n          }\n        }\n      }\n    ]\n  },\n  plugins: [\n    new HtmlWebpackPlugin({\n      template: './src/renderer/index.html'\n    })\n  ]\n};"", ""webpack.main.config.js"": ""const path = require('path');\n\nmodule.exports = {\n  entry: './src/main/index.js',\n  target: 'electron-main',\n  output: {\n    path: path.resolve(__dirname, 'dist'),\n    filename: 'main.js'\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        use: {\n          loader: 'babel-loader',\n          options: {\n            presets: ['@babel/preset-env']\n          }\n        }\n      }\n    ]\n  },\n  node: {\n    __dirname: false,\n    __filename: false\n  }\n};"", ""package-lock.json"": ""{\n  \""name\"": \""electron-app\"",\n  \""version\"": \""1.0.0\"",\n  \""lockfileVersion\"": 2,\n  \""requires\"": true,\n  \""packages\"": {\n    \""\"": {\n      \""name\"": \""electron-app\"",\n      \""version\"": \""1.0.0\"",\n      \""dependencies\"": {\n        \""sqlite3\"": \""^5.0.2\"",\n        \""bcrypt\"": \""^5.0.1\"",\n        \""electron-updater\"": \""^4.3.9\""\n      },\n      \""devDependencies\"": {\n        \""electron\"": \""^13.1.7\"",\n        \""electron-builder\"": \""^22.11.7\"",\n        \""electron-rebuild\"": \""^2.3.5\"",\n        \""webpack\"": \""^5.42.0\"",\n        \""webpack-cli\"": \""^4.7.2\"",\n        \""@babel/core\"": \""^7.14.6\"",\n        \""@babel/preset-env\"": \""^7.14.7\"",\n        \""babel-loader\"": \""^8.2.2\"",\n        \""html-webpack-plugin\"": \""^5.3.2\""\n      },\n      \""engines\"": {\n        \""node\"": \"">=14.0.0\""\n      }\n    }\n  }\n}"", ""package.json"": ""{\n  \""name\"": \""electron-app\"",\n  \""version\"": \""1.0.0\"",\n  \""description\"": \""Desktop application\"",\n  \""main\"": \""dist/main.js\"",\n  \""scripts\"": {\n    \""dev\"": \""webpack --config webpack.main.config.js --mode development && webpack --config webpack.renderer.config.js --mode development && electron .\"",\n    \""build\"": \""webpack --config webpack.main.config.js --mode production && webpack --config webpack.renderer.config.js --mode production\"",\n    \""dist\"": \""npm run build && electron-builder\"",\n    \""rebuild\"": \""electron-rebuild\"",\n    \""start\"": \""electron .\""\n  },\n  \""dependencies\"": {\n    \""sqlite3\"": \""^5.0.2\"",\n    \""bcrypt\"": \""^5.0.1\"",\n    \""electron-updater\"": \""^4.3.9\""\n  },\n  \""devDependencies\"": {\n    \""electron\"": \""^13.1.7\"",\n    \""electron-builder\"": \""^22.11.7\"",\n    \""electron-rebuild\"": \""^2.3.5\"",\n    \""webpack\"": \""^5.42.0\"",\n    \""webpack-cli\"": \""^4.7.2\"",\n    \""@babel/core\"": \""^7.14.6\"",\n    \""@babel/preset-env\"": \""^7.14.7\"",\n    \""babel-loader\"": \""^8.2.2\"",\n    \""html-webpack-plugin\"": \""^5.3.2\""\n  },\n  \""engines\"": {\n    \""node\"": \"">=14.0.0\""\n  }\n}"", ""electron-builder.json"": ""{\n  \""appId\"": \""com.example.electronapp\"",\n  \""productName\"": \""ElectronApp\"",\n  \""directories\"": {\n    \""output\"": \""dist-app\""\n  },\n  \""files\"": [\n    \""dist/**/*\"",\n    \""node_modules/**/*\""\n  ],\n  \""mac\"": {\n    \""category\"": \""public.app-category.productivity\""\n  },\n  \""linux\"": {\n    \""target\"": \""AppImage\""\n  }\n}"", ""native/native_module.cc"": ""#include <node.h>\n\nnamespace demo {\n\nusing v8::FunctionCallbackInfo;\nusing v8::Isolate;\nusing v8::Local;\nusing v8::Object;\nusing v8::String;\nusing v8::Value;\n\nvoid Method(const FunctionCallbackInfo<Value>& args) {\n  Isolate* isolate = args.GetIsolate();\n  args.GetReturnValue().Set(String::NewFromUtf8(isolate, \""native module works\"").ToLocalChecked());\n}\n\nvoid Initialize(Local<Object> exports) {\n  NODE_SET_METHOD(exports, \""hello\"", Method);\n}\n\nNODE_MODULE(NODE_GYP_MODULE_NAME, Initialize)\n\n}  // namespace demo"", ""native/binding.gyp"": ""{\n  \""targets\"": [\n    {\n      \""target_name\"": \""native_module\"",\n      \""sources\"": [ \""native_module.cc\"" ]\n    }\n  ]\n}"", ""src/renderer/index.html"": ""<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\""UTF-8\"">\n  <title>Electron App</title>\n  <meta http-equiv=\""Content-Security-Policy\"" content=\""default-src 'self'; script-src 'self'\"">\n</head>\n<body>\n  <h1>Electron Application</h1>\n  <div id=\""app\"">\n    <button id=\""testDb\"">Test Database</button>\n    <button id=\""testHash\"">Test Hashing</button>\n    <div id=\""output\""></div>\n  </div>\n  <script src=\""./renderer.js\""></script>\n</body>\n</html>"", ""src/renderer/index.js"": ""const { ipcRenderer } = require('electron');\n\ndocument.getElementById('testDb').addEventListener('click', async () => {\n  try {\n    const result = await ipcRenderer.invoke('db-query', 'SELECT * FROM users');\n    document.getElementById('output').innerText = 'Database test: ' + JSON.stringify(result);\n  } catch (err) {\n    document.getElementById('output').innerText = 'Database error: ' + err.message;\n  }\n});\n\ndocument.getElementById('testHash').addEventListener('click', async () => {\n  try {\n    const hash = await ipcRenderer.invoke('hash-password', 'test123');\n    document.getElementById('output').innerText = 'Hash generated: ' + hash;\n  } catch (err) {\n    document.getElementById('output').innerText = 'Hash error: ' + err.message;\n  }\n});"", ""src/main/index.js"": ""const { app, BrowserWindow, ipcMain, Tray, Menu } = require('electron');\nconst path = require('path');\nconst { autoUpdater } = require('electron-updater');\nconst sqlite3 = require('sqlite3').verbose();\nconst bcrypt = require('bcrypt');\n\nlet mainWindow;\nlet tray;\nlet db;\n\nfunction createWindow() {\n  mainWindow = new BrowserWindow({\n    width: 800,\n    height: 600,\n    webPreferences: {\n      nodeIntegration: true,\n      contextIsolation: false\n    }\n  });\n\n  mainWindow.loadFile(path.join(__dirname, 'index.html'));\n\n  mainWindow.on('closed', () => {\n    mainWindow = null;\n  });\n}\n\nfunction createTray() {\n  tray = new Tray(path.join(__dirname, 'icon.png'));\n  const contextMenu = Menu.buildFromTemplate([\n    { label: 'Show App', click: () => mainWindow.show() },\n    { label: 'Quit', click: () => app.quit() }\n  ]);\n  tray.setContextMenu(contextMenu);\n}\n\napp.whenReady().then(() => {\n  db = new sqlite3.Database(':memory:');\n  \n  db.run(\""CREATE TABLE users (id INTEGER PRIMARY KEY, username TEXT, password TEXT)\"", (err) => {\n    if (err) console.error('Database creation failed:', err);\n  });\n\n  createWindow();\n  createTray();\n  \n  autoUpdater.checkForUpdatesAndNotify();\n});\n\napp.on('window-all-closed', () => {\n  if (process.platform !== 'darwin') {\n    app.quit();\n  }\n});\n\napp.on('activate', () => {\n  if (mainWindow === null) {\n    createWindow();\n  }\n});\n\nipcMain.handle('hash-password', async (event, password) => {\n  return await bcrypt.hash(password, 10);\n});\n\nipcMain.handle('db-query', async (event, query) => {\n  return new Promise((resolve, reject) => {\n    db.all(query, (err, rows) => {\n      if (err) reject(err);\n      else resolve(rows);\n    });\n  });\n});""}",extremely_hard,2025-07-22T21:42:54.648222+00:00,2025-07-22T21:44:39.884211+00:00,,
draft_dp_6f697c57,Set up a Redis cluster (3 masters on ports 7000-7002) and create a Python client for storing ML feature vectors with sharding and fault tolerance. The client should support batch operations and TTL.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

# Install Redis and Python dependencies
RUN apt-get -o Acquire::AllowInsecureRepositories=true \
    -o Acquire::AllowDowngradeToInsecureRepositories=true \
    update && \
    apt-get -o APT::Get::AllowUnauthenticated=true install -y \
    redis-server \
    redis-tools \
    netcat-openbsd \
    procps \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip install redis redis-py-cluster numpy

# Create Redis directories and logs
RUN mkdir -p /var/lib/redis/7000 /var/lib/redis/7001 /var/lib/redis/7002 /var/log/redis

# Copy Redis configuration files
COPY redis-7000.conf /etc/redis/redis-7000.conf
COPY redis-7001.conf /etc/redis/redis-7001.conf
COPY redis-7002.conf /etc/redis/redis-7002.conf

# Copy feature store client
COPY feature_store.py /app/feature_store.py

# Set permissions
RUN chmod -R 777 /var/lib/redis /var/log/redis /etc/redis

WORKDIR /app","import subprocess
import time
import json

def test_redis_cluster_formed():
    """"""Test that Redis cluster is properly formed with 3 nodes""""""
    # Check cluster info on port 7000
    result = subprocess.run(
        ['redis-cli', '-p', '7000', 'cluster', 'info'],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0, ""Failed to get cluster info""
    output = result.stdout
    
    # Check cluster state is ok
    assert 'cluster_state:ok' in output, ""Cluster state is not OK""
    
    # Check we have 3 nodes
    assert 'cluster_known_nodes:3' in output, ""Cluster doesn't have 3 nodes""
    
    # Verify cluster slots are assigned
    assert 'cluster_slots_assigned:16384' in output, ""Not all slots are assigned""

def test_data_distribution():
    """"""Test that data is distributed across cluster nodes""""""
    # Set multiple keys and check they're on different nodes
    keys_to_nodes = {}
    
    for i in range(10):
        key = f""test_key_{i}""
        # Set the key
        subprocess.run(['redis-cli', '-p', '7000', '-c', 'SET', key, f'value_{i}'])
        
        # Get which node has this key
        result = subprocess.run(
            ['redis-cli', '-p', '7000', 'CLUSTER', 'KEYSLOT', key],
            capture_output=True,
            text=True
        )
        slot = int(result.stdout.strip())
        
        # Get node for this slot
        nodes_result = subprocess.run(
            ['redis-cli', '-p', '7000', 'CLUSTER', 'NODES'],
            capture_output=True,
            text=True
        )
        
        # Simple check: we should have keys on multiple nodes
        for line in nodes_result.stdout.split('\n'):
            if 'master' in line and str(slot) in line:
                node_id = line.split()[0]
                if node_id not in keys_to_nodes:
                    keys_to_nodes[node_id] = 0
                keys_to_nodes[node_id] += 1
                break
    
    # Verify data is distributed (at least 2 different nodes used)
    assert len(keys_to_nodes) >= 2, ""Data not distributed across multiple nodes""

def test_fault_tolerance():
    """"""Test cluster continues operating when one node stops""""""
    # First verify cluster is healthy
    result = subprocess.run(
        ['redis-cli', '-p', '7000', 'cluster', 'info'],
        capture_output=True,
        text=True
    )
    assert 'cluster_state:ok' in result.stdout
    
    # Stop one Redis instance (port 7002)
    subprocess.run(['pkill', '-f', 'redis-server.*:7002'])
    
    # Wait for cluster to detect the failure
    time.sleep(6)
    
    # Try to set and get a value on remaining cluster
    set_result = subprocess.run(
        ['redis-cli', '-p', '7000', '-c', 'SET', 'fault_test', 'working'],
        capture_output=True,
        text=True
    )
    assert set_result.returncode == 0, ""Failed to set value after node failure""
    
    get_result = subprocess.run(
        ['redis-cli', '-p', '7000', '-c', 'GET', 'fault_test'],
        capture_output=True,
        text=True
    )
    assert get_result.returncode == 0, ""Failed to get value after node failure""
    assert 'working' in get_result.stdout, ""Value not retrieved correctly""","{""test_redis_cluster_formed"": 0.4, ""test_data_distribution"": 0.3, ""test_fault_tolerance"": 0.3}","{""feature_store.py"": ""import redis\nimport json\nimport numpy as np\nfrom typing import Dict, List, Optional\n\nclass FeatureStoreClient:\n    def __init__(self, startup_nodes):\n        # TODO: Initialize Redis cluster client\n        pass\n    \n    def store_feature(self, key: str, vector: np.ndarray, ttl: Optional[int] = None):\n        \""\""\""Store a single feature vector\""\""\""\n        # TODO: Implement single feature storage\n        raise NotImplementedError(\""store_feature not implemented\"")\n    \n    def get_feature(self, key: str) -> Optional[np.ndarray]:\n        \""\""\""Retrieve a single feature vector\""\""\""\n        # TODO: Implement feature retrieval\n        raise NotImplementedError(\""get_feature not implemented\"")\n    \n    def batch_store(self, features: Dict[str, np.ndarray], ttl: Optional[int] = None):\n        \""\""\""Store multiple feature vectors in batch\""\""\""\n        # TODO: Implement batch storage\n        raise NotImplementedError(\""batch_store not implemented\"")\n    \n    def batch_get(self, keys: List[str]) -> Dict[str, Optional[np.ndarray]]:\n        \""\""\""Retrieve multiple feature vectors\""\""\""\n        # TODO: Implement batch retrieval\n        raise NotImplementedError(\""batch_get not implemented\"")"", ""redis-7002.conf"": ""port 7002\ncluster-enabled yes\ncluster-config-file nodes-7002.conf\ncluster-node-timeout 5000\nappendonly yes\nappendfilename \""appendonly-7002.aof\""\ndbfilename dump-7002.rdb\nlogfile /var/log/redis/redis-7002.log\ndir /var/lib/redis/7002/"", ""redis-7001.conf"": ""port 7001\ncluster-enabled yes\ncluster-config-file nodes-7001.conf\ncluster-node-timeout 5000\nappendonly yes\nappendfilename \""appendonly-7001.aof\""\ndbfilename dump-7001.rdb\nlogfile /var/log/redis/redis-7001.log\ndir /var/lib/redis/7001/"", ""redis-7000.conf"": ""port 7000\ncluster-enabled yes\ncluster-config-file nodes-7000.conf\ncluster-node-timeout 5000\nappendonly yes\nappendfilename \""appendonly-7000.aof\""\ndbfilename dump-7000.rdb\nlogfile /var/log/redis/redis-7000.log\ndir /var/lib/redis/7000/""}",hard,2025-07-22T21:43:25.793317+00:00,2025-07-22T21:45:56.085694+00:00,,
draft_dp_8fc15d3b,Port the hierarchical model in clinical_analysis.R to PyMC. Need the Bayesian posterior means to match the lme4 estimates within 5% and include proper convergence diagnostics.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

# Install R and additional dependencies
RUN apt-get update && apt-get install -y \
    r-base \
    r-base-dev \
    && rm -rf /var/lib/apt/lists/*

# Install R packages
RUN R -e ""install.packages(c('lme4', 'tidyverse'), repos='https://cloud.r-project.org/')""

# Install Python packages
RUN pip3 install --break-system-packages \
    pymc \
    arviz \
    pandas \
    numpy \
    matplotlib

WORKDIR /workspace

# Copy all necessary files
COPY generate_data.R /workspace/
COPY clinical_analysis.R /workspace/
COPY pymc_model.py /workspace/

# Generate the clinical trial data
RUN Rscript generate_data.R

# Run the R analysis to generate reference results
RUN Rscript clinical_analysis.R","import subprocess
import os
import json
import numpy as np

def test_pymc_model_exists_and_runs():
    """"""Test that the PyMC model runs without errors and produces results""""""
    result = subprocess.run(
        ['python3', 'pymc_model.py'],
        capture_output=True,
        text=True,
        cwd='/workspace'
    )
    assert result.returncode == 0, f""PyMC model failed to run: {result.stderr}""
    assert os.path.exists('/workspace/pymc_results.json'), ""PyMC results file not created""

def test_posterior_estimates_match_lme4():
    """"""Test that PyMC posterior means match lme4 fixed effects within 5%""""""
    # Load R results
    r_cmd = """"""
    library(jsonlite)
    results <- readRDS('lme4_results.rds')
    cat(toJSON(list(fixed_effects = as.list(results$fixed_effects))))
    """"""
    r_result = subprocess.run(
        ['R', '--slave', '-e', r_cmd],
        capture_output=True,
        text=True,
        cwd='/workspace'
    )
    assert r_result.returncode == 0, ""Failed to load R results""
    r_data = json.loads(r_result.stdout)
    
    # Load PyMC results
    assert os.path.exists('/workspace/pymc_results.json'), ""PyMC results not found""
    with open('/workspace/pymc_results.json', 'r') as f:
        pymc_data = json.load(f)
    
    # Compare fixed effects
    for param in ['treatment', 'age', 'baseline_score']:
        r_value = r_data['fixed_effects'][param]
        pymc_value = pymc_data['posterior_means'][param]
        relative_diff = abs(pymc_value - r_value) / abs(r_value)
        assert relative_diff < 0.05, f""{param}: PyMC estimate {pymc_value:.3f} differs from lme4 {r_value:.3f} by {relative_diff*100:.1f}%""

def test_convergence_diagnostics():
    """"""Test that the PyMC model has good convergence diagnostics""""""
    assert os.path.exists('/workspace/convergence_diagnostics.json'), ""Convergence diagnostics not found""
    
    with open('/workspace/convergence_diagnostics.json', 'r') as f:
        diagnostics = json.load(f)
    
    # Check R-hat values
    for param, rhat in diagnostics['rhat'].items():
        assert rhat < 1.01, f""{param} has poor convergence: R-hat = {rhat:.3f}""
    
    # Check ESS values
    for param, ess in diagnostics['ess_bulk'].items():
        assert ess > 400, f""{param} has low ESS: {ess:.0f}""","{""test_pymc_model_exists_and_runs"": 0.2, ""test_posterior_estimates_match_lme4"": 0.5, ""test_convergence_diagnostics"": 0.3}","{""pymc_model.py"": ""import pymc as pm\nimport pandas as pd\nimport numpy as np\nimport arviz as az\n\n# Load the clinical trial data\nclinical_data = pd.read_csv(\""clinical_trial_data.csv\"")\n\n# TODO: Implement the PyMC hierarchical model\n# The model should match the R lme4 structure:\n# outcome ~ treatment + age + baseline_score + (1 + treatment | center_id)\n\ndef build_model():\n    \""\""\""Build the PyMC hierarchical model\""\""\""\n    # Your implementation here\n    pass\n\ndef run_analysis():\n    \""\""\""Run the full Bayesian analysis with diagnostics\""\""\""\n    # Your implementation here\n    pass\n\nif __name__ == \""__main__\"":\n    run_analysis()"", ""generate_data.R"": ""set.seed(42)\n\n# Generate synthetic clinical trial data\nn_centers <- 10\nn_per_center <- 50\nn_total <- n_centers * n_per_center\n\n# Center random effects\ncenter_intercepts <- rnorm(n_centers, 0, 1.5)\ncenter_treatment_effects <- rnorm(n_centers, 0, 0.8)\n\n# Generate data\ndata <- data.frame(\n  patient_id = 1:n_total,\n  center_id = rep(1:n_centers, each = n_per_center),\n  treatment = rep(c(0, 1), n_total/2),\n  age = round(rnorm(n_total, 50, 10)),\n  baseline_score = rnorm(n_total, 100, 15)\n)\n\n# Generate outcomes with hierarchical structure\ndata$outcome <- with(data, \n  80 + \n  5 * treatment + \n  0.3 * age + \n  0.5 * baseline_score +\n  center_intercepts[center_id] +\n  center_treatment_effects[center_id] * treatment +\n  rnorm(n_total, 0, 5)\n)\n\n# Save dataset\nwrite.csv(data, \""clinical_trial_data.csv\"", row.names = FALSE)"", ""clinical_analysis.R"": ""library(lme4)\nlibrary(tidyverse)\n\n# Load clinical trial data\nclinical_data <- read.csv(\""clinical_trial_data.csv\"")\n\n# Fit hierarchical linear model\n# outcome ~ treatment + baseline covariates + (1 + treatment | center)\nmodel <- lmer(outcome ~ treatment + age + baseline_score + \n              (1 + treatment | center_id), \n              data = clinical_data,\n              REML = FALSE)\n\n# Extract model summaries\nfixed_effects <- fixef(model)\nrandom_effects <- ranef(model)\nvar_components <- VarCorr(model)\n\n# Save results for comparison\nresults <- list(\n  fixed_effects = fixed_effects,\n  random_var = as.data.frame(var_components),\n  model_summary = summary(model)\n)\n\nsaveRDS(results, \""lme4_results.rds\"")\n\n# Print key results\ncat(\""Fixed Effects:\\n\"")\nprint(fixed_effects)\ncat(\""\\nRandom Effects Variance:\\n\"")\nprint(var_components)""}",hard,2025-07-22T21:43:30.881817+00:00,2025-07-22T21:45:30.312751+00:00,,
draft_dp_2b2657b0,The setup.py is using deprecated distutils - need to migrate to setuptools before Python 3.12. Keep all the platform-specific flags and external library linking working.,"FROM python:3.11-slim

RUN apt-get update && apt-get install -y \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

RUN pip install --upgrade pip setuptools wheel

WORKDIR /workspace

COPY setup.py /workspace/
COPY src/ /workspace/src/
COPY lib/ /workspace/lib/
COPY test_extension.py /workspace/

RUN chmod +x test_extension.py","import os
import subprocess
import sys

def test_setuptools_import():
    """"""Test that setup.py imports setuptools instead of distutils.""""""
    with open('setup.py', 'r') as f:
        content = f.read()
    
    assert 'from setuptools' in content or 'import setuptools' in content, ""setup.py must import setuptools""
    assert 'from distutils.core import setup' not in content, ""setup.py must not import from distutils.core""
    assert 'from distutils.extension import Extension' not in content, ""setup.py must not import Extension from distutils""

def test_build_and_install():
    """"""Test that the package builds successfully and can be imported.""""""
    # First build the extension
    result = subprocess.run(
        [sys.executable, 'setup.py', 'build_ext', '--inplace'],
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f""Build failed: {result.stderr}""
    
    # Test wheel creation
    result = subprocess.run(
        [sys.executable, 'setup.py', 'bdist_wheel'],
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f""Wheel creation failed: {result.stderr}""
    assert os.path.exists('dist'), ""dist directory should exist""
    assert any(f.endswith('.whl') for f in os.listdir('dist')), ""Wheel file should be created""
    
    # Test that the extension test passes
    result = subprocess.run(
        [sys.executable, 'test_extension.py'],
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f""Extension test failed: {result.stderr}""
    assert ""Successfully imported pycrypto"" in result.stdout, ""Extension should import successfully""","{""test_setuptools_import"": 0.4, ""test_build_and_install"": 0.6}","{""test_extension.py"": ""#!/usr/bin/env python\n\""\""\""Simple test to verify the extension imports correctly.\""\""\""\n\nimport sys\nimport os\n\n# Add the build directory to path\nbuild_dir = None\nfor item in os.listdir('.'):\n    if item.startswith('build') and os.path.isdir(item):\n        lib_dir = os.path.join(item, [d for d in os.listdir(item) if d.startswith('lib.')][0])\n        if os.path.exists(lib_dir):\n            sys.path.insert(0, lib_dir)\n            build_dir = lib_dir\n            break\n\nif build_dir:\n    print(f\""Using build directory: {build_dir}\"")\n\ntry:\n    import pycrypto\n    print(f\""Successfully imported pycrypto version {pycrypto.__version__}\"")\n    print(f\""Crypto module version: {pycrypto._crypto.version()}\"")\n    print(f\""Compression module version: {pycrypto._compression.version()}\"")\n    print(\""All tests passed!\"")\nexcept Exception as e:\n    print(f\""Import failed: {e}\"")\n    sys.exit(1)"", ""setup.py"": ""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom distutils.core import setup\nfrom distutils.extension import Extension\nimport platform\nimport os\nimport sys\n\n# Platform-specific configuration\nextra_compile_args = ['-O3', '-Wall', '-Wextra']\nextra_link_args = []\nlibraries = ['ssl', 'crypto', 'z']\ninclude_dirs = ['./src/include']\nlibrary_dirs = []\n\nif platform.system() == 'Darwin':\n    # macOS specific flags\n    extra_compile_args.extend(['-mmacosx-version-min=10.9', '-stdlib=libc++'])\n    extra_link_args.extend(['-mmacosx-version-min=10.9', '-stdlib=libc++'])\n    include_dirs.append('/usr/local/opt/openssl/include')\n    library_dirs.append('/usr/local/opt/openssl/lib')\nelif platform.system() == 'Windows':\n    # Windows specific configuration\n    extra_compile_args = ['/O2', '/W3']\n    libraries = ['libeay32', 'ssleay32', 'zlib']\n    include_dirs.extend(['C:\\\\OpenSSL\\\\include', 'C:\\\\zlib\\\\include'])\n    library_dirs.extend(['C:\\\\OpenSSL\\\\lib', 'C:\\\\zlib\\\\lib'])\nelse:\n    # Linux/Unix\n    include_dirs.extend(['/usr/include/openssl'])\n    if os.path.exists('/usr/lib/x86_64-linux-gnu'):\n        library_dirs.append('/usr/lib/x86_64-linux-gnu')\n\n# Define the extension modules\ncrypto_ext = Extension(\n    'pycrypto._crypto',\n    sources=[\n        'src/crypto/cipher.c',\n        'src/crypto/hash.c',\n        'src/crypto/random.c',\n        'src/crypto/utils.c',\n        'src/crypto/module.c'\n    ],\n    include_dirs=include_dirs,\n    library_dirs=library_dirs,\n    libraries=libraries,\n    extra_compile_args=extra_compile_args,\n    extra_link_args=extra_link_args,\n    define_macros=[('NPY_NO_DEPRECATED_API', 'NPY_1_7_API_VERSION')]\n)\n\ncompression_ext = Extension(\n    'pycrypto._compression',\n    sources=[\n        'src/compression/compress.c',\n        'src/compression/decompress.c',\n        'src/compression/module.c'\n    ],\n    include_dirs=include_dirs,\n    library_dirs=library_dirs,\n    libraries=['z'],\n    extra_compile_args=extra_compile_args,\n    extra_link_args=extra_link_args\n)\n\nsetup(\n    name='pycrypto',\n    version='0.2.1',\n    description='Python cryptographic extensions',\n    author='Security Team',\n    author_email='security@example.com',\n    url='https://github.com/example/pycrypto',\n    packages=['pycrypto', 'pycrypto.utils'],\n    package_dir={'': 'lib'},\n    ext_modules=[crypto_ext, compression_ext],\n    classifiers=[\n        'Development Status :: 4 - Beta',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n    ]\n)"", ""lib/pycrypto/__init__.py"": ""\""\""\""PyCrypto - Python cryptographic extensions.\""\""\""\n\n__version__ = '0.2.1'\n\ntry:\n    from . import _crypto\n    from . import _compression\nexcept ImportError as e:\n    raise ImportError(f\""Failed to import C extensions: {e}\"")\n\nfrom .utils import helpers\n\n__all__ = ['_crypto', '_compression', 'utils']"", ""lib/pycrypto/utils/__init__.py"": ""\""\""\""Utility functions for pycrypto.\""\""\""\n\nfrom . import helpers\n\n__all__ = ['helpers']"", ""lib/pycrypto/utils/helpers.py"": ""\""\""\""Helper utilities for cryptographic operations.\""\""\""\n\ndef bytes_to_hex(data):\n    \""\""\""Convert bytes to hex string.\""\""\""\n    return data.hex()\n\ndef hex_to_bytes(hex_string):\n    \""\""\""Convert hex string to bytes.\""\""\""\n    return bytes.fromhex(hex_string)\n\ndef constant_time_compare(a, b):\n    \""\""\""Compare two byte strings in constant time.\""\""\""\n    if len(a) != len(b):\n        return False\n    \n    result = 0\n    for x, y in zip(a, b):\n        result |= x ^ y\n    \n    return result == 0"", ""src/crypto/module.c"": ""#include <Python.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* crypto_version(PyObject* self, PyObject* args) {\n    return PyUnicode_FromString(PYCRYPTO_VERSION);\n}\n\nstatic PyMethodDef crypto_methods[] = {\n    {\""version\"", crypto_version, METH_NOARGS, \""Get version\""},\n    {NULL, NULL, 0, NULL}\n};\n\nstatic struct PyModuleDef crypto_module = {\n    PyModuleDef_HEAD_INIT,\n    \""_crypto\"",\n    \""Cryptographic operations module\"",\n    -1,\n    crypto_methods\n};\n\nPyMODINIT_FUNC PyInit__crypto(void) {\n    PyObject* m = PyModule_Create(&crypto_module);\n    if (m == NULL)\n        return NULL;\n    \n    pycrypto_error = PyErr_NewException(\""pycrypto.CryptoError\"", NULL, NULL);\n    Py_XINCREF(pycrypto_error);\n    if (PyModule_AddObject(m, \""CryptoError\"", pycrypto_error) < 0) {\n        Py_XDECREF(pycrypto_error);\n        Py_CLEAR(pycrypto_error);\n        Py_DECREF(m);\n        return NULL;\n    }\n    \n    return m;\n}"", ""src/crypto/random.c"": ""#include <Python.h>\n#include <openssl/rand.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* random_bytes(PyObject* self, PyObject* args) {\n    int num_bytes;\n    \n    if (!PyArg_ParseTuple(args, \""i\"", &num_bytes)) {\n        return NULL;\n    }\n    \n    if (num_bytes <= 0) {\n        PyErr_SetString(PyExc_ValueError, \""Number of bytes must be positive\"");\n        return NULL;\n    }\n    \n    unsigned char* buffer = PyMem_Malloc(num_bytes);\n    if (!buffer) {\n        return PyErr_NoMemory();\n    }\n    \n    if (RAND_bytes(buffer, num_bytes) != 1) {\n        PyMem_Free(buffer);\n        PyErr_SetString(pycrypto_error, \""Failed to generate random bytes\"");\n        return NULL;\n    }\n    \n    PyObject* result = PyBytes_FromStringAndSize((char*)buffer, num_bytes);\n    PyMem_Free(buffer);\n    return result;\n}"", ""src/crypto/hash.c"": ""#include <Python.h>\n#include <openssl/sha.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* hash_sha256(PyObject* self, PyObject* args) {\n    const char* data;\n    Py_ssize_t data_len;\n    unsigned char hash[SHA256_DIGEST_LENGTH];\n    \n    if (!PyArg_ParseTuple(args, \""y#\"", &data, &data_len)) {\n        return NULL;\n    }\n    \n    SHA256((unsigned char*)data, data_len, hash);\n    return PyBytes_FromStringAndSize((char*)hash, SHA256_DIGEST_LENGTH);\n}"", ""src/crypto/utils.c"": ""#include <Python.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* utils_xor(PyObject* self, PyObject* args) {\n    const char *a, *b;\n    Py_ssize_t a_len, b_len;\n    \n    if (!PyArg_ParseTuple(args, \""y#y#\"", &a, &a_len, &b, &b_len)) {\n        return NULL;\n    }\n    \n    if (a_len != b_len) {\n        PyErr_SetString(PyExc_ValueError, \""Buffers must have same length\"");\n        return NULL;\n    }\n    \n    char* result = PyMem_Malloc(a_len);\n    if (!result) {\n        return PyErr_NoMemory();\n    }\n    \n    for (Py_ssize_t i = 0; i < a_len; i++) {\n        result[i] = a[i] ^ b[i];\n    }\n    \n    PyObject* py_result = PyBytes_FromStringAndSize(result, a_len);\n    PyMem_Free(result);\n    return py_result;\n}"", ""src/crypto/cipher.c"": ""#include <Python.h>\n#include <openssl/evp.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* cipher_encrypt(PyObject* self, PyObject* args) {\n    const char* data;\n    Py_ssize_t data_len;\n    \n    if (!PyArg_ParseTuple(args, \""y#\"", &data, &data_len)) {\n        return NULL;\n    }\n    \n    // Placeholder implementation\n    return PyBytes_FromStringAndSize(data, data_len);\n}"", ""src/include/pycrypto.h"": ""#ifndef PYCRYPTO_H\n#define PYCRYPTO_H\n\n#include <Python.h>\n\n#ifdef __cplusplus\nextern \""C\"" {\n#endif\n\n#define PYCRYPTO_VERSION \""0.2.1\""\n\ntypedef struct {\n    PyObject_HEAD\n    void *ctx;\n    size_t block_size;\n} PyCryptoObject;\n\nPyObject* pycrypto_error;\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif"", ""src/compression/compress.c"": ""#include <Python.h>\n#include <zlib.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* compress_data(PyObject* self, PyObject* args) {\n    const char* data;\n    Py_ssize_t data_len;\n    int level = Z_DEFAULT_COMPRESSION;\n    \n    if (!PyArg_ParseTuple(args, \""y#|i\"", &data, &data_len, &level)) {\n        return NULL;\n    }\n    \n    if (level < 0 || level > 9) {\n        PyErr_SetString(PyExc_ValueError, \""Compression level must be between 0 and 9\"");\n        return NULL;\n    }\n    \n    uLongf dest_len = compressBound(data_len);\n    Bytef* dest = PyMem_Malloc(dest_len);\n    if (!dest) {\n        return PyErr_NoMemory();\n    }\n    \n    int result = compress2(dest, &dest_len, (const Bytef*)data, data_len, level);\n    if (result != Z_OK) {\n        PyMem_Free(dest);\n        PyErr_SetString(pycrypto_error, \""Compression failed\"");\n        return NULL;\n    }\n    \n    PyObject* py_result = PyBytes_FromStringAndSize((char*)dest, dest_len);\n    PyMem_Free(dest);\n    return py_result;\n}"", ""src/compression/decompress.c"": ""#include <Python.h>\n#include <zlib.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* decompress_data(PyObject* self, PyObject* args) {\n    const char* data;\n    Py_ssize_t data_len;\n    \n    if (!PyArg_ParseTuple(args, \""y#\"", &data, &data_len)) {\n        return NULL;\n    }\n    \n    // Initial buffer size guess\n    uLongf dest_len = data_len * 4;\n    Bytef* dest = PyMem_Malloc(dest_len);\n    if (!dest) {\n        return PyErr_NoMemory();\n    }\n    \n    int result = uncompress(dest, &dest_len, (const Bytef*)data, data_len);\n    if (result == Z_BUF_ERROR) {\n        // Try with larger buffer\n        PyMem_Free(dest);\n        dest_len = data_len * 10;\n        dest = PyMem_Malloc(dest_len);\n        if (!dest) {\n            return PyErr_NoMemory();\n        }\n        result = uncompress(dest, &dest_len, (const Bytef*)data, data_len);\n    }\n    \n    if (result != Z_OK) {\n        PyMem_Free(dest);\n        PyErr_SetString(pycrypto_error, \""Decompression failed\"");\n        return NULL;\n    }\n    \n    PyObject* py_result = PyBytes_FromStringAndSize((char*)dest, dest_len);\n    PyMem_Free(dest);\n    return py_result;\n}"", ""src/compression/module.c"": ""#include <Python.h>\n#include \""pycrypto.h\""\n\nstatic PyObject* compression_version(PyObject* self, PyObject* args) {\n    return PyUnicode_FromString(\""1.0.0\"");\n}\n\nstatic PyMethodDef compression_methods[] = {\n    {\""version\"", compression_version, METH_NOARGS, \""Get compression module version\""},\n    {NULL, NULL, 0, NULL}\n};\n\nstatic struct PyModuleDef compression_module = {\n    PyModuleDef_HEAD_INIT,\n    \""_compression\"",\n    \""Compression operations module\"",\n    -1,\n    compression_methods\n};\n\nPyMODINIT_FUNC PyInit__compression(void) {\n    return PyModule_Create(&compression_module);\n}""}",medium,2025-07-22T21:44:10.871393+00:00,2025-07-22T21:52:24.309828+00:00,,
draft_dp_d59b3e6f,"Just upgraded webpack from v4 to v5 and the build is completely broken. Getting errors about removed polyfills, deprecated plugins, and the dev server won't even start. Need to fix all three webpack configs to work with v5.","FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && \
    apt-get install -y curl wget && \
    curl -fsSL https://deb.nodesource.com/setup_18.x | bash - && \
    apt-get install -y nodejs tmux asciinema && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY package.json /app/
COPY package-lock.json /app/
COPY webpack.common.js /app/
COPY webpack.dev.js /app/
COPY webpack.prod.js /app/
COPY tsconfig.json /app/
COPY .babelrc /app/
COPY src /app/src/
COPY public /app/public/

RUN npm install

CMD [""/bin/bash""]","import subprocess
import os
import json

def test_development_build_succeeds():
    """"""Test that development build completes without errors""""""
    result = subprocess.run(['npm', 'run', 'dev'], 
                          capture_output=True, text=True, cwd='/app')
    assert result.returncode == 0, f""Development build failed: {result.stderr}""

def test_production_build_succeeds():
    """"""Test that production build completes and outputs expected files""""""
    result = subprocess.run(['npm', 'run', 'build'], 
                          capture_output=True, text=True, cwd='/app')
    assert result.returncode == 0, f""Production build failed: {result.stderr}""
    
    # Check that main bundle was created
    assert os.path.exists('/app/dist/main.js'), ""Main bundle not found in dist/""
    assert os.path.exists('/app/dist/index.html'), ""HTML file not generated""","{""test_development_build_succeeds"": 0.4, ""test_production_build_succeeds"": 0.6}","{"".babelrc"": ""{\n  \""presets\"": [\n    \""@babel/preset-env\"",\n    \""@babel/preset-react\"",\n    \""@babel/preset-typescript\""\n  ]\n}"", ""webpack.dev.js"": ""const merge = require('webpack-merge');\nconst common = require('./webpack.common.js');\nconst webpack = require('webpack');\n\nmodule.exports = merge(common, {\n  mode: 'development',\n  devtool: 'cheap-module-eval-source-map',\n  devServer: {\n    contentBase: './dist',\n    hot: true,\n    port: 3000,\n    historyApiFallback: true,\n    disableHostCheck: true\n  },\n  plugins: [\n    new webpack.HotModuleReplacementPlugin(),\n    new webpack.NamedModulesPlugin()\n  ]\n});"", ""package-lock.json"": ""{\n  \""name\"": \""react-webpack-app\"",\n  \""version\"": \""1.0.0\"",\n  \""lockfileVersion\"": 2,\n  \""requires\"": true,\n  \""packages\"": {\n    \""\"": {\n      \""name\"": \""react-webpack-app\"",\n      \""version\"": \""1.0.0\""\n    }\n  }\n}"", ""package.json"": ""{\n  \""name\"": \""react-webpack-app\"",\n  \""version\"": \""1.0.0\"",\n  \""description\"": \""React app with webpack 5\"",\n  \""scripts\"": {\n    \""dev\"": \""webpack serve --config webpack.dev.js\"",\n    \""build\"": \""webpack --config webpack.prod.js\"",\n    \""start\"": \""webpack serve --config webpack.dev.js --open\""\n  },\n  \""dependencies\"": {\n    \""react\"": \""^18.2.0\"",\n    \""react-dom\"": \""^18.2.0\""\n  },\n  \""devDependencies\"": {\n    \""@babel/core\"": \""^7.21.0\"",\n    \""@babel/preset-env\"": \""^7.20.2\"",\n    \""@babel/preset-react\"": \""^7.18.6\"",\n    \""@babel/preset-typescript\"": \""^7.21.0\"",\n    \""@types/react\"": \""^18.0.28\"",\n    \""@types/react-dom\"": \""^18.0.11\"",\n    \""babel-loader\"": \""^9.1.2\"",\n    \""css-loader\"": \""^6.7.3\"",\n    \""html-webpack-plugin\"": \""^5.5.0\"",\n    \""mini-css-extract-plugin\"": \""^2.7.2\"",\n    \""node-sass\"": \""^8.0.0\"",\n    \""sass-loader\"": \""^13.2.0\"",\n    \""style-loader\"": \""^3.3.1\"",\n    \""typescript\"": \""^4.9.5\"",\n    \""webpack\"": \""^5.75.0\"",\n    \""webpack-cli\"": \""^5.0.1\"",\n    \""webpack-dev-server\"": \""^4.11.1\"",\n    \""webpack-merge\"": \""^5.8.0\""\n  }\n}"", ""webpack.prod.js"": ""const merge = require('webpack-merge');\nconst common = require('./webpack.common.js');\nconst MiniCssExtractPlugin = require('mini-css-extract-plugin');\nconst OptimizeCSSAssetsPlugin = require('optimize-css-assets-webpack-plugin');\nconst TerserPlugin = require('terser-webpack-plugin');\n\nmodule.exports = merge(common, {\n  mode: 'production',\n  devtool: 'source-map',\n  module: {\n    rules: [\n      {\n        test: /\\.css$/,\n        use: [MiniCssExtractPlugin.loader, 'css-loader']\n      },\n      {\n        test: /\\.scss$/,\n        use: [MiniCssExtractPlugin.loader, 'css-loader', 'sass-loader']\n      }\n    ]\n  },\n  optimization: {\n    minimizer: [\n      new TerserPlugin({\n        cache: true,\n        parallel: true,\n        sourceMap: true\n      }),\n      new OptimizeCSSAssetsPlugin({})\n    ],\n    hashedModuleIds: true\n  },\n  plugins: [\n    new MiniCssExtractPlugin({\n      filename: '[name].[contenthash].css',\n      chunkFilename: '[id].[contenthash].css'\n    })\n  ]\n});"", ""tsconfig.json"": ""{\n  \""compilerOptions\"": {\n    \""target\"": \""es5\"",\n    \""module\"": \""esnext\"",\n    \""lib\"": [\""dom\"", \""es2015\"", \""es2017\""],\n    \""jsx\"": \""react\"",\n    \""strict\"": true,\n    \""esModuleInterop\"": true,\n    \""skipLibCheck\"": true,\n    \""forceConsistentCasingInFileNames\"": true,\n    \""moduleResolution\"": \""node\"",\n    \""resolveJsonModule\"": true,\n    \""isolatedModules\"": true,\n    \""noEmit\"": true\n  },\n  \""include\"": [\""src/**/*\""],\n  \""exclude\"": [\""node_modules\"", \""dist\""]\n}"", ""webpack.common.js"": ""const path = require('path');\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\n\nmodule.exports = {\n  entry: {\n    main: './src/index.tsx',\n    vendor: ['react', 'react-dom']\n  },\n  output: {\n    path: path.resolve(__dirname, 'dist'),\n    filename: '[name].[contenthash].js'\n  },\n  resolve: {\n    extensions: ['.tsx', '.ts', '.js'],\n    modules: ['node_modules', path.resolve(__dirname, 'src')],\n    fallback: {\n      fs: false,\n      path: require.resolve('path-browserify'),\n      crypto: require.resolve('crypto-browserify'),\n      stream: require.resolve('stream-browserify'),\n      buffer: require.resolve('buffer/')\n    }\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.(ts|tsx)$/,\n        exclude: /node_modules/,\n        use: {\n          loader: 'babel-loader'\n        }\n      },\n      {\n        test: /\\.css$/,\n        use: ['style-loader', 'css-loader']\n      },\n      {\n        test: /\\.scss$/,\n        use: ['style-loader', 'css-loader', 'sass-loader']\n      },\n      {\n        test: /\\.(png|svg|jpg|jpeg|gif)$/i,\n        use: {\n          loader: 'file-loader',\n          options: {\n            name: '[name].[hash].[ext]',\n            outputPath: 'images'\n          }\n        }\n      }\n    ]\n  },\n  plugins: [\n    new HtmlWebpackPlugin({\n      template: './public/index.html',\n      favicon: './public/favicon.ico'\n    })\n  ],\n  optimization: {\n    splitChunks: {\n      cacheGroups: {\n        vendor: {\n          test: /[\\\\/]node_modules[\\\\/]/,\n          name: 'vendors',\n          priority: 10\n        }\n      }\n    },\n    namedModules: true,\n    namedChunks: true\n  }\n};"", ""public/favicon.ico"": """", ""public/index.html"": ""<!DOCTYPE html>\n<html lang=\""en\"">\n<head>\n  <meta charset=\""UTF-8\"">\n  <meta name=\""viewport\"" content=\""width=device-width, initial-scale=1.0\"">\n  <meta http-equiv=\""X-UA-Compatible\"" content=\""ie=edge\"">\n  <title>React Webpack App</title>\n</head>\n<body>\n  <div id=\""root\""></div>\n</body>\n</html>"", ""src/index.tsx"": ""import React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport App from './App';\nimport './styles/main.scss';\n\nconst root = ReactDOM.createRoot(\n  document.getElementById('root') as HTMLElement\n);\n\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);"", ""src/App.tsx"": ""import React, { useState } from 'react';\nimport Header from './components/Header';\nimport Dashboard from './components/Dashboard';\nimport './styles/app.css';\n\nconst App: React.FC = () => {\n  const [count, setCount] = useState(0);\n\n  return (\n    <div className=\""app\"">\n      <Header title=\""React Webpack App\"" />\n      <main>\n        <h1>Welcome to our app</h1>\n        <p>Counter: {count}</p>\n        <button onClick={() => setCount(count + 1)}>Increment</button>\n        <Dashboard />\n      </main>\n    </div>\n  );\n};\n\nexport default App;"", ""src/styles/app.css"": "".app {\n  min-height: 100vh;\n  background-color: #f8f9fa;\n}\n\n.app main {\n  padding: 2rem;\n}\n\n.app h1 {\n  margin-bottom: 1rem;\n}\n\n.app button {\n  background-color: #007bff;\n  color: white;\n  border: none;\n  padding: 0.5rem 1rem;\n  border-radius: 4px;\n  cursor: pointer;\n  font-size: 1rem;\n}\n\n.app button:hover {\n  background-color: #0056b3;\n}"", ""src/styles/main.scss"": ""$primary-color: #007bff;\n$secondary-color: #6c757d;\n\n* {\n  margin: 0;\n  padding: 0;\n  box-sizing: border-box;\n}\n\nbody {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n  line-height: 1.6;\n  color: #333;\n}\n\n.container {\n  max-width: 1200px;\n  margin: 0 auto;\n  padding: 0 20px;\n}"", ""src/components/Dashboard.tsx"": ""import React, { useEffect, useState } from 'react';\nimport './Dashboard.scss';\n\nconst Dashboard: React.FC = () => {\n  const [data, setData] = useState<any[]>([]);\n\n  useEffect(() => {\n    // Simulate fetching data\n    setData([\n      { id: 1, name: 'Item 1', value: 100 },\n      { id: 2, name: 'Item 2', value: 200 },\n      { id: 3, name: 'Item 3', value: 300 }\n    ]);\n  }, []);\n\n  return (\n    <div className=\""dashboard\"">\n      <h2>Dashboard</h2>\n      <div className=\""data-grid\"">\n        {data.map(item => (\n          <div key={item.id} className=\""data-item\"">\n            <h3>{item.name}</h3>\n            <p>Value: {item.value}</p>\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n};\n\nexport default Dashboard;"", ""src/components/Dashboard.scss"": "".dashboard {\n  margin-top: 2rem;\n\n  h2 {\n    margin-bottom: 1rem;\n    color: #495057;\n  }\n\n  .data-grid {\n    display: grid;\n    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n    gap: 1rem;\n    margin-top: 1rem;\n  }\n\n  .data-item {\n    background: white;\n    padding: 1.5rem;\n    border-radius: 8px;\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n    transition: transform 0.2s;\n\n    &:hover {\n      transform: translateY(-2px);\n      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);\n    }\n\n    h3 {\n      color: #007bff;\n      margin-bottom: 0.5rem;\n    }\n\n    p {\n      color: #6c757d;\n    }\n  }\n}"", ""src/components/Header.tsx"": ""import React from 'react';\nimport './Header.css';\n\ninterface HeaderProps {\n  title: string;\n}\n\nconst Header: React.FC<HeaderProps> = ({ title }) => {\n  return (\n    <header className=\""header\"">\n      <h1>{title}</h1>\n      <nav>\n        <a href=\""/\"">Home</a>\n        <a href=\""/about\"">About</a>\n        <a href=\""/contact\"">Contact</a>\n      </nav>\n    </header>\n  );\n};\n\nexport default Header;"", ""src/components/Header.css"": "".header {\n  background-color: #343a40;\n  color: white;\n  padding: 1rem 2rem;\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n}\n\n.header h1 {\n  font-size: 1.5rem;\n}\n\n.header nav a {\n  color: white;\n  text-decoration: none;\n  margin-left: 1rem;\n  transition: opacity 0.3s;\n}\n\n.header nav a:hover {\n  opacity: 0.8;\n}""}",hard,2025-07-22T21:44:30.715859+00:00,2025-07-22T21:47:42.067295+00:00,,
draft_dp_6c80ef6f,"HAProxy is returning 503 errors for all API requests. Need JWT validation and rate limiting (10 req/min for /api/export, 100 req/min for others).","FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y \
    haproxy \
    python3 \
    python3-pip \
    python3-flask \
    python3-jwt \
    python3-cryptography \
    openssl \
    curl \
    net-tools \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

RUN pip3 install pyjwt[crypto] requests

WORKDIR /app

# Create error directory
RUN mkdir -p /etc/haproxy/errors

# Copy all the configuration and service files
COPY haproxy.cfg /etc/haproxy/
COPY jwt_validation.lua /etc/haproxy/
COPY public_key.pem /etc/haproxy/
COPY errors/*.http /etc/haproxy/errors/
COPY search_service.py /app/
COPY export_service.py /app/
COPY start_services.sh /app/
COPY test_tokens.json /app/

RUN chmod +x /app/start_services.sh

# Enable HAProxy
RUN sed -i 's/ENABLED=0/ENABLED=1/' /etc/default/haproxy

# Start services
CMD [""/app/start_services.sh""]","import subprocess
import json
import time
import os

def test_jwt_validation():
    """"""Test that HAProxy validates JWT tokens correctly""""""
    # Load test tokens
    with open('/app/test_tokens.json', 'r') as f:
        tokens = json.load(f)
    
    # Test with valid token - should get 200
    result = subprocess.run([
        'curl', '-s', '-o', '/dev/null', '-w', '%{http_code}',
        '-H', f'Authorization: Bearer {tokens[""valid_token""]}',
        'http://localhost:8080/api/search'
    ], capture_output=True, text=True)
    assert result.stdout == '200', f""Valid token should return 200, got {result.stdout}""
    
    # Test with invalid token - should get 401
    result = subprocess.run([
        'curl', '-s', '-o', '/dev/null', '-w', '%{http_code}',
        '-H', 'Authorization: Bearer invalid.token.here',
        'http://localhost:8080/api/search'
    ], capture_output=True, text=True)
    assert result.stdout == '401', f""Invalid token should return 401, got {result.stdout}""

def test_rate_limiting():
    """"""Test that rate limiting is enforced per endpoint""""""
    # Load valid token
    with open('/app/test_tokens.json', 'r') as f:
        tokens = json.load(f)
    valid_token = tokens[""valid_token""]
    
    # Test /api/export endpoint (10 req/min limit)
    # Send 12 requests rapidly
    status_codes = []
    for i in range(12):
        result = subprocess.run([
            'curl', '-s', '-o', '/dev/null', '-w', '%{http_code}',
            '-H', f'Authorization: Bearer {valid_token}',
            'http://localhost:8080/api/export'
        ], capture_output=True, text=True)
        status_codes.append(result.stdout)
        time.sleep(0.1)  # Small delay between requests
    
    # First 10 should be 200, 11th and 12th should be 429
    success_count = status_codes.count('200')
    rate_limited_count = status_codes.count('429')
    
    assert success_count >= 9, f""Expected at least 9 successful requests, got {success_count}""
    assert rate_limited_count >= 1, f""Expected at least 1 rate limited request (429), got {rate_limited_count}""","{""test_jwt_validation"": 0.6, ""test_rate_limiting"": 0.4}","{""haproxy.cfg"": ""global\n    log stdout local0\n    maxconn 4096\n    lua-load /etc/haproxy/jwt_validation.lua\n\ndefaults\n    log     global\n    mode    http\n    option  httplog\n    option  dontlognull\n    timeout connect 5000\n    timeout client  50000\n    timeout server  50000\n    \n    errorfile 401 /etc/haproxy/errors/401.http\n    errorfile 403 /etc/haproxy/errors/403.http\n    errorfile 429 /etc/haproxy/errors/429.http\n    errorfile 503 /etc/haproxy/errors/503.http\n\nfrontend api_gateway\n    bind *:8080\n    \n    # Basic routing without JWT validation\n    use_backend search_backend if { path_beg /api/search }\n    use_backend export_backend if { path_beg /api/export }\n    \n    default_backend no_backend\n\nbackend search_backend\n    server search1 127.0.0.1:5001 check\n\nbackend export_backend  \n    server export1 127.0.0.1:5002 check\n    \nbackend no_backend\n    http-request deny deny_status 503"", ""jwt_validation.lua"": ""-- JWT validation script for HAProxy\n-- Currently not implemented properly\n\nfunction jwt_validate(txn)\n    -- TODO: Implement JWT validation\n    -- Should extract Bearer token from Authorization header\n    -- Validate signature with public key\n    -- Check expiration\n    return true\nend\n\ncore.register_fetches(\""jwt_validate\"", jwt_validate)"", ""test_tokens.json"": ""{\n  \""valid_token\"": \""eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyMTIzIiwiZXhwIjoxNzUzMjI0MjY0LCJpYXQiOjE3NTMyMjA2NjR9.QPB0Lg_RzEFOPaLs8sXtifsi2__DRv6j5InBNpx24cMgRFurSp8jyykUgzZd4IJaiBz1kGz8-w3wBZDCKmssAUG4CPG5ym5AW77giknMKAy6czejB4jPylPk7lft0nx9n_nSx2d47h7G__y-au0VTfFfwfR2tw_DNVuVeu2eXDWg7mpJayF5qlJYQbpJx8qe_Jbwvn4vjEptiDA0B2v0YcaurRoig7lypKTPMhrT-d59eVP-zzSOUVYyujSoFzuxg5sFyIqABN_Pm8ul4XkQsB7u1AqN2p6o0LNM_AABev_4UbMKI86479LeDvO4xOfMmM6qJ_KwVxteJZL291ZMsQ\"",\n  \""expired_token\"": \""eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyMTIzIiwiZXhwIjoxNzUzMjE3MDY0LCJpYXQiOjE3NTMyMjA2NjR9.P1DcA18m9ffytgHSUJciyELSwpXH5wHrl5Hj697mWulbqYcBSoXGzlbVujxKWXFUwDGWoF8zFfO9cSopGAvNurGOokiEP5MH50tn-NXuuFs6RAhF9InwPz21Evppwm9V7585hWkHz_WvFVbnlnp5OUmdJYbg2EiWST5g_98t4LZhN0ZTNM7OCFolOtp6Tz7Ggr4vKWju561L01JzzxHtgIX6f3-xAUgWO3SxCtiw5HKOqRTpeoexyPU489r5nOtwyRYPx0H_zRyY4ikvO-RHa-i1FJy1BPCzlthTXdQg5aeGkqwXmuau3oZAiYkSYYkOih96lo5Z-L5kKfJAp5lpgA\""\n}"", ""export_service.py"": ""#!/usr/bin/env python3\nfrom flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/api/export', methods=['GET', 'POST'])\ndef export():\n    return jsonify({\n        \""service\"": \""export\"",\n        \""status\"": \""export initiated\"",\n        \""job_id\"": \""exp_12345\""\n    })\n\n@app.route('/health', methods=['GET'])\ndef health():\n    return jsonify({\""status\"": \""healthy\""})\n\nif __name__ == '__main__':\n    app.run(host='127.0.0.1', port=5002)"", ""public_key.pem"": ""-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvV68Bw+jSfbmXyrZf0D9\nd0nDpIeYnXS+/Gpaf27sfgp0iMUVUu3nEPfddDMs9XsOq0VQ/GoHYP8vsiBrhwDX\nntckZv09KFU7oWuiAV1GKGwURSrhR86C8QsMykeNAUPJnauRF6on+UpEvYCIDXEk\njV90zdtLmNRia1c6efW9A08JOatsMMcD1UYRInEvSMhQYm4zkOkxvUmdtOA2Q7k1\n7/M6FtEs68oRXbQ5RhDxokY6qSlh50tqm1eiA1vXtcTSj4qltnK8Xhn8XdjyGkEK\n5dp7nmrSO6x7fgh8DWy1dyXbt83h3dwGH/SKpMdC533/LquLKmReiqwYWY+JM6ei\nmwIDAQAB\n-----END PUBLIC KEY-----\n"", ""search_service.py"": ""#!/usr/bin/env python3\nfrom flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/api/search', methods=['GET', 'POST'])\ndef search():\n    return jsonify({\n        \""service\"": \""search\"",\n        \""results\"": [\n            {\""id\"": 1, \""name\"": \""Result 1\""},\n            {\""id\"": 2, \""name\"": \""Result 2\""}\n        ]\n    })\n\n@app.route('/health', methods=['GET'])\ndef health():\n    return jsonify({\""status\"": \""healthy\""})\n\nif __name__ == '__main__':\n    app.run(host='127.0.0.1', port=5001)"", ""start_services.sh"": ""#!/bin/bash\n\n# Start backend services\npython3 /app/search_service.py &\npython3 /app/export_service.py &\n\n# Wait for services to start\nsleep 3\n\n# Start HAProxy\nhaproxy -f /etc/haproxy/haproxy.cfg\n\n# Keep container running\ntail -f /dev/null"", ""errors/401.http"": ""HTTP/1.0 401 Unauthorized\nContent-Type: application/json\nCache-Control: no-cache\nConnection: close\n\n{\""error\"": \""Unauthorized\"", \""message\"": \""Invalid or missing JWT token\""}"", ""errors/503.http"": ""HTTP/1.0 503 Service Unavailable\nContent-Type: application/json\nCache-Control: no-cache\nConnection: close\n\n{\""error\"": \""Service Unavailable\"", \""message\"": \""Backend service not available\""}"", ""errors/429.http"": ""HTTP/1.0 429 Too Many Requests\nContent-Type: application/json\nCache-Control: no-cache\nConnection: close\nRetry-After: 60\n\n{\""error\"": \""Too Many Requests\"", \""message\"": \""Rate limit exceeded\""}"", ""errors/403.http"": ""HTTP/1.0 403 Forbidden\nContent-Type: application/json\nCache-Control: no-cache\nConnection: close\n\n{\""error\"": \""Forbidden\"", \""message\"": \""Access denied\""}""}",extremely_hard,2025-07-22T21:45:41.861330+00:00,2025-07-22T22:03:29.055733+00:00,,
draft_dp_ecdd65b6,The TF 1.x attention model in attention_model.py needs to be ported to JAX. Keep the same numerical results within 1e-5 tolerance and make it at least 80% as fast after JIT compilation.,"FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

WORKDIR /app

# Install Python 3.7 from deadsnakes PPA and curl
RUN apt-get update && apt-get install -y software-properties-common curl && \
    add-apt-repository ppa:deadsnakes/ppa && \
    apt-get update && apt-get install -y python3.7 python3.7-distutils python3.7-dev && \
    rm -rf /var/lib/apt/lists/*

# Install pip for Python 3.7
RUN curl https://bootstrap.pypa.io/pip/3.7/get-pip.py -o get-pip.py && \
    python3.7 get-pip.py && \
    rm get-pip.py

# Install TensorFlow 1.15 and JAX with dependencies
RUN python3.7 -m pip install tensorflow==1.15.5 jax==0.2.13 jaxlib==0.1.69 numpy==1.19.5

# Copy the TensorFlow model and data generation script
COPY attention_model.py /app/
COPY generate_test_data.py /app/

# Generate test data and model weights
RUN cd /app && python generate_test_data.py

# Set environment variables for TensorFlow 1.x
ENV TF_CPP_MIN_LOG_LEVEL=2
ENV TF_FORCE_GPU_ALLOW_GROWTH=true","import os
import subprocess
import numpy as np
import pickle

def test_jax_model_exists():
    """"""Test that the JAX implementation file was created.""""""
    # Check for either attention_model_jax.py or jax_attention.py as common naming conventions
    jax_files = ['attention_model_jax.py', 'jax_attention.py', 'attention_jax.py']
    exists = any(os.path.exists(f'/app/{f}') for f in jax_files)
    assert exists, ""No JAX implementation file found""

def test_numerical_equivalence():
    """"""Test that JAX model produces outputs within tolerance of TF model.""""""
    # Run a comparison script that tests numerical equivalence
    result = subprocess.run([
        'python', '-c',
        '''
import numpy as np
import pickle
import sys

# Load test data
data = np.load('/app/test_data.npz')
test_input = data['input']
expected_output = data['output']

# Try to import and run JAX model
try:
    # Try common naming patterns
    for module_name in ['attention_model_jax', 'jax_attention', 'attention_jax']:
        try:
            jax_module = __import__(module_name)
            break
        except ImportError:
            continue
    else:
        print(""Could not import JAX model"")
        sys.exit(1)
    
    # Load weights
    with open('/app/model_weights.pkl', 'rb') as f:
        weights = pickle.load(f)
    
    # Create JAX model and run inference
    if hasattr(jax_module, 'MultiHeadAttention'):
        model = jax_module.MultiHeadAttention()
        if hasattr(model, 'set_weights'):
            model.set_weights(weights)
        output = model.forward(test_input, training=False)
    elif hasattr(jax_module, 'forward') or hasattr(jax_module, 'attention_forward'):
        # Functional style
        forward_fn = getattr(jax_module, 'forward', None) or getattr(jax_module, 'attention_forward')
        output = forward_fn(test_input, weights, training=False)
    else:
        print(""No suitable forward function found"")
        sys.exit(1)
    
    # Check tolerance
    output = np.array(output)
    max_diff = np.max(np.abs(output - expected_output))
    print(f""Max difference: {max_diff}"")
    
    if max_diff > 1e-5:
        print(f""FAIL: Maximum difference {max_diff} exceeds tolerance 1e-5"")
        sys.exit(1)
    else:
        print(""PASS: Outputs match within tolerance"")
        sys.exit(0)
        
except Exception as e:
    print(f""Error during comparison: {str(e)}"")
    sys.exit(1)
'''
    ], capture_output=True, text=True)
    
    assert result.returncode == 0, f""Numerical equivalence test failed: {result.stdout} {result.stderr}""","{""test_jax_model_exists"": 0.3, ""test_numerical_equivalence"": 0.7}","{""generate_test_data.py"": ""import numpy as np\nimport pickle\n\n# Generate test data\nnp.random.seed(42)\nbatch_size = 2\nseq_len = 10\nd_model = 512\n\ntest_input = np.random.randn(batch_size, seq_len, d_model).astype(np.float32)\n\n# Generate expected output (this would normally come from running the TF model)\n# For this test, we'll create plausible attention output\noutput = np.random.randn(batch_size, seq_len, d_model).astype(np.float32) * 0.5\n\n# Save test data\nnp.savez('test_data.npz', input=test_input, output=output)\n\n# Generate and save model weights\nweights = {\n    'wq': np.random.randn(d_model, d_model).astype(np.float32) * 0.02,\n    'wk': np.random.randn(d_model, d_model).astype(np.float32) * 0.02,\n    'wv': np.random.randn(d_model, d_model).astype(np.float32) * 0.02,\n    'wo': np.random.randn(d_model, d_model).astype(np.float32) * 0.02\n}\n\nwith open('model_weights.pkl', 'wb') as f:\n    pickle.dump(weights, f)"", ""test_data.npz"": ""# Binary file placeholder - will be created when attention_model.py runs"", ""model_weights.pkl"": ""# Binary file placeholder - will be created when attention_model.py runs"", ""attention_model.py"": ""import tensorflow as tf\nimport numpy as np\nimport pickle\n\nclass MultiHeadAttention:\n    def __init__(self, d_model=512, num_heads=8):\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.depth = d_model // num_heads\n        \n        self.graph = tf.Graph()\n        with self.graph.as_default():\n            # Input placeholders\n            self.inputs = tf.placeholder(tf.float32, shape=[None, None, d_model], name='inputs')\n            self.training = tf.placeholder(tf.bool, name='training')\n            \n            # Weight variables\n            self.wq = tf.Variable(tf.random_normal([d_model, d_model], stddev=0.02), name='wq')\n            self.wk = tf.Variable(tf.random_normal([d_model, d_model], stddev=0.02), name='wk')\n            self.wv = tf.Variable(tf.random_normal([d_model, d_model], stddev=0.02), name='wv')\n            self.wo = tf.Variable(tf.random_normal([d_model, d_model], stddev=0.02), name='wo')\n            \n            # Positional encoding\n            self.pos_encoding = self._positional_encoding(1000, d_model)\n            \n            # Build the attention mechanism\n            self.output = self._build_attention()\n            \n            # Initialize session\n            self.sess = tf.Session()\n            self.sess.run(tf.global_variables_initializer())\n    \n    def _positional_encoding(self, max_len, d_model):\n        pos = np.arange(max_len)[:, np.newaxis]\n        i = np.arange(d_model)[np.newaxis, :]\n        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n        angle_rads = pos * angle_rates\n        \n        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n        \n        return tf.constant(angle_rads[np.newaxis, ...], dtype=tf.float32)\n    \n    def _split_heads(self, x, batch_size):\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n    \n    def _build_attention(self):\n        batch_size = tf.shape(self.inputs)[0]\n        seq_len = tf.shape(self.inputs)[1]\n        \n        # Add positional encoding\n        inputs_with_pos = self.inputs + self.pos_encoding[:, :seq_len, :]\n        \n        # Linear transformations\n        q = tf.matmul(inputs_with_pos, self.wq)\n        k = tf.matmul(inputs_with_pos, self.wk)\n        v = tf.matmul(inputs_with_pos, self.wv)\n        \n        # Split heads\n        q = self._split_heads(q, batch_size)\n        k = self._split_heads(k, batch_size)\n        v = self._split_heads(v, batch_size)\n        \n        # Scaled dot-product attention\n        matmul_qk = tf.matmul(q, k, transpose_b=True)\n        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n        \n        # Softmax\n        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n        \n        # Apply dropout in training mode\n        attention_weights = tf.cond(self.training,\n                                   lambda: tf.nn.dropout(attention_weights, keep_prob=0.9),\n                                   lambda: attention_weights)\n        \n        # Attention output\n        attention_output = tf.matmul(attention_weights, v)\n        attention_output = tf.transpose(attention_output, perm=[0, 2, 1, 3])\n        attention_output = tf.reshape(attention_output, (batch_size, -1, self.d_model))\n        \n        # Final linear transformation\n        output = tf.matmul(attention_output, self.wo)\n        \n        return output\n    \n    def forward(self, inputs, training=False):\n        return self.sess.run(self.output, feed_dict={\n            self.inputs: inputs,\n            self.training: training\n        })\n    \n    def get_weights(self):\n        with self.graph.as_default():\n            weights = {\n                'wq': self.sess.run(self.wq),\n                'wk': self.sess.run(self.wk),\n                'wv': self.sess.run(self.wv),\n                'wo': self.sess.run(self.wo)\n            }\n        return weights\n    \n    def set_weights(self, weights):\n        with self.graph.as_default():\n            self.sess.run([\n                tf.assign(self.wq, weights['wq']),\n                tf.assign(self.wk, weights['wk']),\n                tf.assign(self.wv, weights['wv']),\n                tf.assign(self.wo, weights['wo'])\n            ])\n\nif __name__ == \""__main__\"":\n    # Create model and save weights\n    model = MultiHeadAttention()\n    \n    # Generate some test data\n    batch_size = 2\n    seq_len = 10\n    d_model = 512\n    test_input = np.random.randn(batch_size, seq_len, d_model).astype(np.float32)\n    \n    # Run forward pass\n    output = model.forward(test_input, training=False)\n    \n    # Save test data and weights\n    np.savez('test_data.npz', input=test_input, output=output)\n    \n    weights = model.get_weights()\n    with open('model_weights.pkl', 'wb') as f:\n        pickle.dump(weights, f)""}",medium,2025-07-22T21:52:25.072797+00:00,2025-07-22T22:03:29.703715+00:00,,
draft_dp_014aa29c,The WASM runtime crashes with memory corruption when running array_test.wasm. Fix the bounds checking in the memory operations.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

RUN apt-get update && apt-get install -y \
    g++ \
    make \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY wasm_runtime.cpp /app/
COPY Makefile /app/
COPY create_wasm.py /app/

RUN python3 create_wasm.py
RUN make","import subprocess
import os

def test_runtime_no_crash():
    """"""Test that the runtime doesn't crash when running array_test.wasm""""""
    result = subprocess.run(['./wasm_runtime', 'array_test.wasm'], 
                          capture_output=True, text=True)
    assert result.returncode == 0
    assert ""Execution completed successfully"" in result.stdout

def test_bounds_checking_works():
    """"""Test that bounds checking prevents memory corruption""""""
    # The runtime should have proper bounds checking fixed
    # This test verifies the fix works by checking the runtime exits cleanly
    # without segmentation faults or other crashes
    result = subprocess.run(['./wasm_runtime', 'array_test.wasm'], 
                          capture_output=True, text=True)
    # Should complete without crashing (exit code 0)
    assert result.returncode == 0
    assert ""Runtime error:"" not in result.stderr or ""Memory access out of bounds"" in result.stderr","{""test_runtime_no_crash"": 0.6, ""test_bounds_checking_works"": 0.4}","{""Makefile"": ""CXX = g++\nCXXFLAGS = -std=c++17 -Wall -g -O2\nTARGET = wasm_runtime\n\nall: $(TARGET)\n\n$(TARGET): wasm_runtime.cpp\n\t$(CXX) $(CXXFLAGS) -o $@ $<\n\nclean:\n\trm -f $(TARGET)\n\n.PHONY: all clean"", ""array_test.wasm"": ""0061736d01000000"", ""create_wasm.py"": ""#!/usr/bin/env python3\n# Creates a minimal WASM file for testing\nimport struct\n\n# WASM magic number and version\nwasm_header = b'\\x00asm\\x01\\x00\\x00\\x00'\n\nwith open('array_test.wasm', 'wb') as f:\n    f.write(wasm_header)\n    # Add empty sections to make it a valid minimal WASM\n    # Type section (empty)\n    f.write(b'\\x01\\x01\\x00')  # section 1, size 1, 0 types\n    # Memory section - declare 1 page of memory\n    f.write(b'\\x05\\x03\\x01\\x00\\x01')  # section 5, size 3, 1 memory, min 1 page"", ""wasm_runtime.cpp"": ""#include <cstdint>\n#include <cstring>\n#include <vector>\n#include <fstream>\n#include <iostream>\n#include <stdexcept>\n\nclass WasmMemory {\nprivate:\n    std::vector<uint8_t> memory;\n    size_t page_size = 65536;\n    size_t max_pages = 256;\n    \npublic:\n    WasmMemory() : memory(page_size) {}\n    \n    void grow(size_t pages) {\n        size_t new_size = memory.size() + pages * page_size;\n        if (new_size > max_pages * page_size) {\n            throw std::runtime_error(\""Memory limit exceeded\"");\n        }\n        memory.resize(new_size);\n    }\n    \n    void store32(uint32_t offset, uint32_t value) {\n        // BUG: Missing bounds check for offset + 4\n        if (offset >= memory.size()) {\n            throw std::runtime_error(\""Memory access out of bounds\"");\n        }\n        memcpy(&memory[offset], &value, 4);\n    }\n    \n    uint32_t load32(uint32_t offset) {\n        if (offset >= memory.size()) {\n            throw std::runtime_error(\""Memory access out of bounds\"");\n        }\n        uint32_t value;\n        memcpy(&value, &memory[offset], 4);\n        return value;\n    }\n    \n    size_t size() const { return memory.size(); }\n};\n\nclass WasmRuntime {\nprivate:\n    WasmMemory memory;\n    std::vector<uint8_t> code;\n    \npublic:\n    void loadModule(const std::string& filename) {\n        std::ifstream file(filename, std::ios::binary);\n        if (!file) {\n            throw std::runtime_error(\""Failed to open WASM file\"");\n        }\n        \n        file.seekg(0, std::ios::end);\n        size_t size = file.tellg();\n        file.seekg(0, std::ios::beg);\n        \n        code.resize(size);\n        file.read(reinterpret_cast<char*>(code.data()), size);\n    }\n    \n    void execute() {\n        // Simplified execution for array_test.wasm\n        // The test module tries to write 1000 32-bit integers starting at offset 65530\n        uint32_t offset = 65530;\n        for (int i = 0; i < 1000; i++) {\n            memory.store32(offset + i * 4, i);\n        }\n        std::cout << \""Execution completed successfully\\n\"";\n    }\n};\n\nint main(int argc, char* argv[]) {\n    if (argc != 2) {\n        std::cerr << \""Usage: \"" << argv[0] << \"" <wasm_file>\\n\"";\n        return 1;\n    }\n    \n    try {\n        WasmRuntime runtime;\n        runtime.loadModule(argv[1]);\n        runtime.execute();\n    } catch (const std::exception& e) {\n        std::cerr << \""Runtime error: \"" << e.what() << \""\\n\"";\n        return 1;\n    }\n    \n    return 0;\n}""}",hard,2025-07-22T22:03:44.598053+00:00,2025-07-23T06:43:31.622531+00:00,,
draft_dp_6d31fe73,"ML pipeline broken after package upgrade. Need TensorFlow 2.10.x, PyTorch, and scikit-learn working together.","FROM python:3.9-slim

# Install tmux and asciinema
RUN apt-get update && apt-get install -y \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /project

# Copy the broken requirements file
COPY requirements.txt /project/
COPY test_imports.py /project/

# Try to install the broken requirements (this will likely fail or cause conflicts)
RUN pip3 install --upgrade pip
RUN pip3 install -r requirements.txt || true

CMD [""/bin/bash""]","import subprocess
import os
import re

def test_packages_installed():
    """"""Test that all required ML packages are installed and can be imported""""""
    # Test basic imports
    test_script = """"""
import tensorflow as tf
import torch
import sklearn
import numpy as np
import pandas as pd
import matplotlib

print(""All packages imported successfully"")
print(f""TensorFlow version: {tf.__version__}"")
print(f""PyTorch version: {torch.__version__}"")
print(f""scikit-learn version: {sklearn.__version__}"")
""""""
    
    result = subprocess.run(
        [""python3"", ""-c"", test_script],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0, f""Package imports failed: {result.stderr}""
    assert ""All packages imported successfully"" in result.stdout

def test_tensorflow_version():
    """"""Test that TensorFlow version is 2.10.x as required""""""
    result = subprocess.run(
        [""python3"", ""-c"", ""import tensorflow as tf; print(tf.__version__)""],
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0, ""Failed to get TensorFlow version""
    version = result.stdout.strip()
    
    # Check that version starts with 2.10
    assert version.startswith(""2.10""), f""TensorFlow version must be 2.10.x, got {version}""
    
    # Also verify requirements-fixed.txt exists
    assert os.path.exists(""/project/requirements-fixed.txt""), ""requirements-fixed.txt not found""","{""test_packages_installed"": 0.6, ""test_tensorflow_version"": 0.4}","{""requirements.txt"": ""# ML Pipeline Requirements - Currently broken after attempted upgrade\ntensorflow==2.14.0  # Someone tried to upgrade from 2.10\ntorch==2.0.1\ntorchvision==0.15.2\nscikit-learn==1.3.0\nnumpy==1.25.0\npandas==2.0.3\nmatplotlib==3.7.2\nscipy==1.11.1\nprotobuf==4.24.0"", ""test_imports.py"": ""#!/usr/bin/env python3\n\""\""\""Test script to verify all ML packages work together\""\""\""\n\nprint(\""Testing package imports and basic operations...\"")\n\ntry:\n    import tensorflow as tf\n    print(f\""\u2713 TensorFlow {tf.__version__} imported\"")\n    \n    # Test basic TF operation\n    x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n    y = tf.matmul(x, x)\n    print(f\""  TensorFlow matmul test: {y.shape}\"")\nexcept Exception as e:\n    print(f\""\u2717 TensorFlow error: {e}\"")\n\ntry:\n    import torch\n    print(f\""\u2713 PyTorch {torch.__version__} imported\"")\n    \n    # Test basic operation\n    x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n    y = torch.mm(x, x)\n    print(f\""  PyTorch matmul test: {list(y.shape)}\"")\nexcept Exception as e:\n    print(f\""\u2717 PyTorch error: {e}\"")\n\ntry:\n    import sklearn\n    import numpy as np\n    from sklearn.linear_model import LogisticRegression\n    print(f\""\u2713 scikit-learn {sklearn.__version__} imported\"")\n    \n    # Test basic sklearn operation\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 1, 0])\n    model = LogisticRegression(random_state=42)\n    model.fit(X, y)\n    print(f\""  scikit-learn model fitted successfully\"")\nexcept Exception as e:\n    print(f\""\u2717 scikit-learn error: {e}\"")\n\ntry:\n    import pandas as pd\n    print(f\""\u2713 pandas {pd.__version__} imported\"")\nexcept Exception as e:\n    print(f\""\u2717 pandas error: {e}\"")\n\ntry:\n    import matplotlib\n    print(f\""\u2713 matplotlib {matplotlib.__version__} imported\"")\nexcept Exception as e:\n    print(f\""\u2717 matplotlib error: {e}\"")\n\nprint(\""\\nAll tests completed!\"")""}",hard,2025-07-23T08:07:52.948802+00:00,2025-07-23T08:51:07.412978+00:00,,
draft_dp_19c13ba1,Our Rust web service won't compile - getting feature flag conflicts between tokio and async-std in our dependencies. Need to fix the Cargo.toml to make it build while keeping both PostgreSQL and SQLite support via sqlx.,"FROM rust:1.75

# Install tmux and asciinema (required for t-bench)
RUN apt-get update && apt-get install -y \
    tmux \
    asciinema \
    sqlite3 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy the project files
COPY Cargo.toml /app/
COPY src/main.rs /app/src/

# Pre-download dependencies (will fail but caches deps)
RUN cargo fetch || true

CMD [""/bin/bash""]","import subprocess
import os

def test_cargo_build_succeeds():
    """"""Test that the Rust project builds successfully after fixing conflicts.""""""
    result = subprocess.run(
        [""cargo"", ""build"", ""--release""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f""Cargo build failed: {result.stderr}""
    assert os.path.exists(""/app/target/release/web-service""), ""Binary not created""

def test_both_database_features_available():
    """"""Test that both PostgreSQL and SQLite features are properly enabled.""""""
    # Check Cargo.toml to verify both database features remain
    result = subprocess.run(
        [""cargo"", ""tree"", ""-e"", ""features""],
        cwd=""/app"", 
        capture_output=True,
        text=True
    )
    assert result.returncode == 0
    output = result.stdout
    # Verify sqlx has both postgres and sqlite features
    assert ""sqlx"" in output and ""postgres"" in output, ""PostgreSQL feature not found""
    assert ""sqlx"" in output and ""sqlite"" in output, ""SQLite feature not found""","{""test_cargo_build_succeeds"": 0.7, ""test_both_database_features_available"": 0.3}","{""Cargo.toml"": ""[package]\nname = \""web-service\""\nversion = \""0.1.0\""\nedition = \""2021\""\n\n[dependencies]\n# Async runtimes - both with conflicting features\ntokio = { version = \""1.35\"", features = [\""full\"", \""rt-multi-thread\"", \""macros\""] }\nasync-std = { version = \""1.12\"", features = [\""attributes\"", \""tokio1\""] }\n\n# Web framework\naxum = \""0.7\""\n\n# Database with multiple backends\nsqlx = { version = \""0.7\"", features = [\""runtime-tokio-native-tls\"", \""runtime-async-std-rustls\"", \""postgres\"", \""sqlite\"", \""macros\""] }\n\n# Additional deps that might have conflicts\ntower = { version = \""0.4\"", features = [\""full\""] }\nhyper = { version = \""1.0\"", features = [\""full\""] }\n\n# Legacy component that requires async-std\nsurf = \""2.3\""\n\n[dev-dependencies]\ntokio-test = \""0.4\"""", ""src/main.rs"": ""use axum::{Router, routing::get};\nuse sqlx::{postgres::PgPool, sqlite::SqlitePool};\nuse std::net::SocketAddr;\n\nasync fn health_check() -> &'static str {\n    \""OK\""\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // PostgreSQL connection\n    let pg_url = std::env::var(\""DATABASE_URL\"").unwrap_or_else(|_| \""postgres://localhost/testdb\"".to_string());\n    let _pg_pool = PgPool::connect(&pg_url).await?;\n    \n    // SQLite connection\n    let sqlite_pool = SqlitePool::connect(\""sqlite::memory:\"").await?;\n    \n    // Run a simple query to verify SQLite works\n    sqlx::query(\""CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY)\"")\n        .execute(&sqlite_pool)\n        .await?;\n    \n    // Legacy component using async-std\n    async_std::task::spawn(async {\n        println!(\""Legacy component running on async-std\"");\n    });\n    \n    // Web server setup\n    let app = Router::new()\n        .route(\""/health\"", get(health_check));\n    \n    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));\n    println!(\""Server running on {}\"", addr);\n    \n    let listener = tokio::net::TcpListener::bind(addr).await?;\n    axum::serve(listener, app).await?;\n    \n    Ok(())\n}""}",extremely_hard,2025-07-23T08:47:39.484200+00:00,2025-07-23T08:54:05.132211+00:00,,
draft_dp_f17101e3,"We're migrating from Tomcat to Nginx and need to extract certificates from our JKS keystores. Convert them to PEM format for Nginx - need the cert, key, and full chain for each keystore.","FROM eclipse-temurin:17-jdk

WORKDIR /app

# Install required packages without GPG verification
RUN apt-get update -o Acquire::AllowInsecureRepositories=true -o Acquire::AllowDowngradeToInsecureRepositories=true && \
    apt-get install -y -o APT::Get::AllowUnauthenticated=true \
    openssl \
    nginx \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

# Create directories for keystores and output
RUN mkdir -p /app/keystores /app/output /app/nginx-configs

# Copy sample keystores and scripts
COPY create_keystores.sh /app/
COPY keystore_passwords.txt /app/

# Generate sample keystores with different configurations
RUN chmod +x /app/create_keystores.sh && \
    /app/create_keystores.sh

# Set proper permissions
RUN chmod 644 /app/keystores/*.jks && \
    chmod 600 /app/keystore_passwords.txt","import os
import subprocess
import json

def test_certificates_extracted_to_pem():
    """"""Test that certificates are extracted from all keystores to PEM format.""""""
    # Check that PEM files were created for each keystore
    expected_files = [
        '/app/output/server1-cert.pem',
        '/app/output/server1-key.pem',
        '/app/output/multi-webapp-cert.pem',
        '/app/output/multi-webapp-key.pem',
        '/app/output/multi-api-cert.pem',
        '/app/output/multi-api-key.pem',
        '/app/output/chain-server3-cert.pem',
        '/app/output/chain-server3-key.pem',
        '/app/output/chain-server3-chain.pem'
    ]
    
    missing_files = []
    for expected_file in expected_files:
        if not os.path.exists(expected_file):
            missing_files.append(expected_file)
    
    assert len(missing_files) == 0, f""Missing PEM files: {missing_files}""
    
    # Verify PEM format for a sample certificate
    result = subprocess.run(
        ['openssl', 'x509', '-in', '/app/output/server1-cert.pem', '-noout', '-text'],
        capture_output=True, text=True
    )
    assert result.returncode == 0, ""Certificate is not in valid PEM format""
    assert 'server1.example.com' in result.stdout, ""Certificate CN not found""

def test_nginx_configs_generated():
    """"""Test that Nginx SSL configuration snippets are generated for each domain.""""""
    # Check for Nginx config files
    expected_configs = [
        '/app/nginx-configs/server1.example.com.conf',
        '/app/nginx-configs/webapp.example.com.conf',
        '/app/nginx-configs/api.example.com.conf',
        '/app/nginx-configs/secure.example.com.conf'
    ]
    
    missing_configs = []
    for config in expected_configs:
        if not os.path.exists(config):
            missing_configs.append(config)
    
    assert len(missing_configs) == 0, f""Missing Nginx configs: {missing_configs}""
    
    # Verify config content contains SSL directives
    with open('/app/nginx-configs/server1.example.com.conf', 'r') as f:
        content = f.read()
        assert 'ssl_certificate' in content, ""SSL certificate directive missing""
        assert 'ssl_certificate_key' in content, ""SSL key directive missing""
        assert '/app/output/server1-cert.pem' in content, ""Certificate path not found""
        assert '/app/output/server1-key.pem' in content, ""Key path not found""","{""test_certificates_extracted_to_pem"": 0.6, ""test_nginx_configs_generated"": 0.4}","{""keystore_passwords.txt"": ""server1.jks:pass123\nmulti.jks:multi456\nchain.jks:chain999"", ""create_keystores.sh"": ""#!/bin/bash\n\n# Create sample keystores with certificates for testing\n\n# Keystore 1: Simple self-signed certificate\nkeytool -genkeypair -alias server1 -keyalg RSA -keysize 2048 \\\n    -validity 365 -keystore /app/keystores/server1.jks \\\n    -storepass pass123 -keypass pass123 \\\n    -dname \""CN=server1.example.com, O=Example Corp, L=San Francisco, ST=CA, C=US\"" \\\n    -ext san=dns:server1.example.com,dns:www.server1.example.com\n\n# Keystore 2: Multiple aliases with different certificates\nkeytool -genkeypair -alias webapp -keyalg RSA -keysize 2048 \\\n    -validity 365 -keystore /app/keystores/multi.jks \\\n    -storepass multi456 -keypass multi456 \\\n    -dname \""CN=webapp.example.com, O=Example Corp, L=San Francisco, ST=CA, C=US\""\n\nkeytool -genkeypair -alias api -keyalg RSA -keysize 2048 \\\n    -validity 365 -keystore /app/keystores/multi.jks \\\n    -storepass multi456 -keypass multi456 \\\n    -dname \""CN=api.example.com, O=Example Corp, L=San Francisco, ST=CA, C=US\""\n\n# Keystore 3: Certificate with chain (create CA first, then sign server cert)\n# Create CA\nkeytool -genkeypair -alias ca -keyalg RSA -keysize 2048 \\\n    -validity 3650 -keystore /app/keystores/ca.jks \\\n    -storepass capass789 -keypass capass789 \\\n    -dname \""CN=Example CA, O=Example Corp, L=San Francisco, ST=CA, C=US\"" \\\n    -ext bc:c\n\n# Export CA cert\nkeytool -exportcert -alias ca -keystore /app/keystores/ca.jks \\\n    -storepass capass789 -rfc -file /tmp/ca.crt\n\n# Create server key\nkeytool -genkeypair -alias server3 -keyalg RSA -keysize 2048 \\\n    -validity 365 -keystore /app/keystores/chain.jks \\\n    -storepass chain999 -keypass chain999 \\\n    -dname \""CN=secure.example.com, O=Example Corp, L=San Francisco, ST=CA, C=US\""\n\n# Create CSR\nkeytool -certreq -alias server3 -keystore /app/keystores/chain.jks \\\n    -storepass chain999 -file /tmp/server3.csr\n\n# Sign with CA\nkeytool -gencert -alias ca -keystore /app/keystores/ca.jks \\\n    -storepass capass789 -infile /tmp/server3.csr \\\n    -outfile /tmp/server3.crt -rfc -validity 365 \\\n    -ext san=dns:secure.example.com,dns:www.secure.example.com\n\n# Import CA cert to chain keystore\nkeytool -importcert -alias ca -keystore /app/keystores/chain.jks \\\n    -storepass chain999 -file /tmp/ca.crt -noprompt\n\n# Import signed cert\nkeytool -importcert -alias server3 -keystore /app/keystores/chain.jks \\\n    -storepass chain999 -file /tmp/server3.crt\n\n# Clean up temp files\nrm -f /tmp/ca.crt /tmp/server3.csr /tmp/server3.crt""}",medium,2025-07-23T08:48:08.824753+00:00,2025-07-23T08:55:43.723730+00:00,,
draft_dp_2327d2be,"Set up the translation API to work offline with the cached models. Need endpoints for Spanish, French, and German.","FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

# Copy requirements and install dependencies
COPY requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt

# Copy the application files
COPY translation_api.py /app/
COPY download_models.py /app/

# Download all the translation models during build
RUN python download_models.py

# Set environment variable to use offline mode by default
ENV TRANSFORMERS_OFFLINE=1

# Expose the API port
EXPOSE 8000

# The API isn't running yet - user needs to complete implementation and start it
CMD [""bash""]","import subprocess
import json
import time
import requests

def test_translation_endpoints_work():
    """"""Test that all three translation endpoints return valid translations.""""""
    # First check if the API is running
    try:
        response = requests.get(""http://localhost:8000/"")
        assert response.status_code == 200
    except:
        assert False, ""API is not running on port 8000""
    
    # Test each language endpoint
    test_texts = [""Hello world"", ""How are you?""]
    languages = [""es"", ""fr"", ""de""]
    
    for lang in languages:
        for text in test_texts:
            response = requests.post(
                f""http://localhost:8000/translate/{lang}"",
                json={""text"": text}
            )
            assert response.status_code == 200, f""Failed to translate to {lang}""
            
            data = response.json()
            assert ""translated_text"" in data, f""No translated_text in response for {lang}""
            assert data[""translated_text""] != text, f""Text not translated for {lang}""
            assert data[""translated_text""] != ""Not implemented yet"", f""Translation not implemented for {lang}""
            assert len(data[""translated_text""]) > 0, f""Empty translation for {lang}""

def test_offline_mode_works():
    """"""Test that the service works when HuggingFace is blocked.""""""
    # Block access to huggingface.co by adding to /etc/hosts
    # First, save current hosts file
    subprocess.run([""cp"", ""/etc/hosts"", ""/tmp/hosts.backup""], check=True)
    
    try:
        # Add blocking entries
        with open(""/etc/hosts"", ""a"") as f:
            f.write(""\n# Block HuggingFace for testing\n"")
            f.write(""127.0.0.1 huggingface.co\n"")
            f.write(""127.0.0.1 cdn.huggingface.co\n"")
            f.write(""127.0.0.1 cdn-lfs.huggingface.co\n"")
        
        # Wait a moment for changes to take effect
        time.sleep(1)
        
        # Test that translation still works
        response = requests.post(
            ""http://localhost:8000/translate/es"",
            json={""text"": ""Test offline mode""}
        )
        assert response.status_code == 200, ""API failed in offline mode""
        
        data = response.json()
        assert ""translated_text"" in data, ""No response in offline mode""
        assert len(data[""translated_text""]) > 0, ""Empty translation in offline mode""
        
    finally:
        # Restore original hosts file
        subprocess.run([""cp"", ""/tmp/hosts.backup"", ""/etc/hosts""], check=True)","{""test_translation_endpoints_work"": 0.7, ""test_offline_mode_works"": 0.3}","{""download_models.py"": ""#!/usr/bin/env python3\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# Download all the models we need\nprint(\""Downloading translation models...\"")\n\nmodels = {\n    \""es\"": \""Helsinki-NLP/opus-mt-en-es\"",\n    \""fr\"": \""Helsinki-NLP/opus-mt-en-fr\"",\n    \""de\"": \""Helsinki-NLP/opus-mt-en-de\""\n}\n\nfor lang, model_name in models.items():\n    print(f\""Downloading {model_name}...\"")\n    tokenizer = MarianTokenizer.from_pretrained(model_name)\n    model = MarianMTModel.from_pretrained(model_name)\n    print(f\""\u2713 {lang} model downloaded\"")\n\nprint(\""All models downloaded successfully!\"")"", ""requirements.txt"": ""transformers==4.36.2\ntorch==2.7.0\nfastapi==0.104.1\nuvicorn==0.24.0\npydantic==2.5.2\nsentencepiece==0.1.99\nprotobuf==4.25.1"", ""translation_api.py"": ""from fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom transformers import MarianMTModel, MarianTokenizer\n\napp = FastAPI()\n\nclass TranslationRequest(BaseModel):\n    text: str\n\n# Model names for each language pair\nmodels = {\n    \""es\"": \""Helsinki-NLP/opus-mt-en-es\"",\n    \""fr\"": \""Helsinki-NLP/opus-mt-en-fr\"", \n    \""de\"": \""Helsinki-NLP/opus-mt-en-de\""\n}\n\n# TODO: Load the models here\n# The models are already downloaded in the cache\n\n@app.get(\""/\"")\ndef root():\n    return {\""message\"": \""Translation API\""}\n\n@app.post(\""/translate/{lang}\"")\ndef translate(lang: str, request: TranslationRequest):\n    if lang not in models:\n        return {\""error\"": \""Language not supported\""}\n    \n    # TODO: Implement translation logic\n    # Need to use the cached models and return translations\n    \n    return {\""translated_text\"": \""Not implemented yet\""}""}",medium,2025-07-23T08:48:10.013253+00:00,2025-07-23T08:48:53.327122+00:00,,
draft_dp_4be830ca,The vendor build is broken - getting version conflicts with the AWS SDK v1.44.100 that we need to keep. Fix the go.mod so vendoring works again.,"FROM golang:1.20

RUN apt-get update && apt-get install -y \
    tmux \
    asciinema \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY go.mod /app/
COPY main.go /app/
COPY service.go /app/

ENV GOPROXY=https://proxy.golang.org,direct
ENV GOSUMDB=sum.golang.org

RUN go mod download || true

CMD [""/bin/bash""]","import os
import subprocess

def test_vendor_directory_created():
    """"""Test that go mod vendor creates the vendor directory successfully.""""""
    # Check if vendor directory exists
    vendor_path = ""/app/vendor""
    assert os.path.exists(vendor_path), ""vendor directory not found""
    assert os.path.isdir(vendor_path), ""vendor is not a directory""
    
    # Check that vendor has modules
    vendor_modules = os.path.join(vendor_path, ""modules.txt"")
    assert os.path.exists(vendor_modules), ""vendor/modules.txt not found""
    
    # Verify AWS SDK is vendored at the correct version
    with open(vendor_modules, 'r') as f:
        content = f.read()
        assert ""github.com/aws/aws-sdk-go v1.44.100"" in content, ""AWS SDK v1.44.100 not found in vendor modules""

def test_vendor_build_succeeds():
    """"""Test that the project builds successfully with vendored dependencies.""""""
    # Try to build with vendor flag
    result = subprocess.run(
        [""go"", ""build"", ""-mod=vendor"", ""-o"", ""/app/cloudservice"", ""/app/main.go"", ""/app/service.go""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0, f""Build failed: {result.stderr}""
    assert os.path.exists(""/app/cloudservice""), ""Binary not created""
    
    # Verify binary is executable
    assert os.access(""/app/cloudservice"", os.X_OK), ""Binary is not executable""","{""test_vendor_directory_created"": 0.5, ""test_vendor_build_succeeds"": 0.5}","{""go.mod"": ""module github.com/example/cloudservice\n\ngo 1.20\n\nrequire (\n\tgithub.com/aws/aws-sdk-go v1.44.100\n\tgithub.com/stretchr/testify v1.8.4\n\tgithub.com/gorilla/mux v1.8.0\n\tgithub.com/prometheus/client_golang v1.16.0\n)\n\nrequire (\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/jmespath/go-jmespath v0.4.0 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.2.0 // indirect\n\tgithub.com/golang/protobuf v1.5.3 // indirect\n\tgithub.com/matttproud/golang_protobuf_extensions v1.0.4 // indirect\n\tgithub.com/prometheus/client_model v0.4.0 // indirect\n\tgithub.com/prometheus/common v0.44.0 // indirect\n\tgithub.com/prometheus/procfs v0.11.0 // indirect\n\tgolang.org/x/sys v0.11.0 // indirect\n\tgoogle.golang.org/protobuf v1.31.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n\nreplace github.com/prometheus/client_golang => github.com/prometheus/client_golang v1.11.1\n\nreplace github.com/prometheus/common => github.com/prometheus/common v0.26.0"", ""service.go"": ""package main\n\nimport (\n\t\""github.com/aws/aws-sdk-go/aws\""\n\t\""github.com/aws/aws-sdk-go/service/dynamodb\""\n\t\""github.com/stretchr/testify/assert\""\n)\n\ntype Service struct {\n\tdb *dynamodb.DynamoDB\n}\n\nfunc NewService(db *dynamodb.DynamoDB) *Service {\n\treturn &Service{db: db}\n}\n\nfunc (s *Service) CreateTable(tableName string) error {\n\tinput := &dynamodb.CreateTableInput{\n\t\tTableName: aws.String(tableName),\n\t\tAttributeDefinitions: []*dynamodb.AttributeDefinition{\n\t\t\t{\n\t\t\t\tAttributeName: aws.String(\""ID\""),\n\t\t\t\tAttributeType: aws.String(\""S\""),\n\t\t\t},\n\t\t},\n\t\tKeySchema: []*dynamodb.KeySchemaElement{\n\t\t\t{\n\t\t\t\tAttributeName: aws.String(\""ID\""),\n\t\t\t\tKeyType:       aws.String(\""HASH\""),\n\t\t\t},\n\t\t},\n\t\tBillingMode: aws.String(\""PAY_PER_REQUEST\""),\n\t}\n\t\n\t_, err := s.db.CreateTable(input)\n\treturn err\n}\n\nfunc ValidateConfig(config map[string]interface{}) bool {\n\tt := &testing{config: config}\n\tassert.NotNil(t, config[\""region\""])\n\tassert.NotEmpty(t, config[\""region\""])\n\treturn t.failed == false\n}\n\ntype testing struct {\n\tconfig map[string]interface{}\n\tfailed bool\n}"", ""main.go"": ""package main\n\nimport (\n\t\""fmt\""\n\t\""log\""\n\t\""net/http\""\n\n\t\""github.com/aws/aws-sdk-go/aws\""\n\t\""github.com/aws/aws-sdk-go/aws/session\""\n\t\""github.com/aws/aws-sdk-go/service/s3\""\n\t\""github.com/gorilla/mux\""\n\t\""github.com/prometheus/client_golang/prometheus\""\n\t\""github.com/prometheus/client_golang/prometheus/promhttp\""\n)\n\nvar (\n\trequestCount = prometheus.NewCounterVec(\n\t\tprometheus.CounterOpts{\n\t\t\tName: \""http_requests_total\"",\n\t\t\tHelp: \""Total number of HTTP requests\"",\n\t\t},\n\t\t[]string{\""method\"", \""endpoint\""},\n\t)\n)\n\nfunc init() {\n\tprometheus.MustRegister(requestCount)\n}\n\nfunc main() {\n\tsess, err := session.NewSession(&aws.Config{\n\t\tRegion: aws.String(\""us-east-1\""),\n\t})\n\tif err != nil {\n\t\tlog.Fatal(\""Failed to create AWS session:\"", err)\n\t}\n\n\tsvc := s3.New(sess)\n\t\n\tr := mux.NewRouter()\n\t\n\tr.HandleFunc(\""/\"", func(w http.ResponseWriter, r *http.Request) {\n\t\trequestCount.WithLabelValues(r.Method, \""/\"").Inc()\n\t\tfmt.Fprintf(w, \""Cloud Service API v1.0\\n\"")\n\t})\n\t\n\tr.HandleFunc(\""/buckets\"", func(w http.ResponseWriter, r *http.Request) {\n\t\trequestCount.WithLabelValues(r.Method, \""/buckets\"").Inc()\n\t\tresult, err := svc.ListBuckets(nil)\n\t\tif err != nil {\n\t\t\thttp.Error(w, err.Error(), http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\t\tfmt.Fprintf(w, \""Found %d buckets\\n\"", len(result.Buckets))\n\t})\n\t\n\tr.Handle(\""/metrics\"", promhttp.Handler())\n\t\n\tlog.Println(\""Starting server on :8080\"")\n\tlog.Fatal(http.ListenAndServe(\"":8080\"", r))\n}""}",hard,2025-07-23T08:48:41.054174+00:00,2025-07-23T08:56:02.140707+00:00,,
draft_dp_1c318274,"The conda env creation is timing out - been stuck for 10+ minutes resolving bioconda dependencies. Need to fix the environment.yml so it builds in under 3 minutes while keeping all the required packages (especially snakemake, samtools, biopython).","FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

# Use Python to download Miniconda since wget/curl might not be available
RUN python3 -c ""import urllib.request; urllib.request.urlretrieve('https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh', '/tmp/miniconda.sh')"" && \
    bash /tmp/miniconda.sh -b -p /opt/conda && \
    rm /tmp/miniconda.sh && \
    /opt/conda/bin/conda clean -tipsy && \
    ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh && \
    echo "". /opt/conda/etc/profile.d/conda.sh"" >> ~/.bashrc && \
    echo ""conda activate base"" >> ~/.bashrc

ENV PATH=/opt/conda/bin:$PATH

# Configure conda for better solver output
RUN conda config --set show_channel_urls true && \
    conda config --set verbosity 2 && \
    conda config --set channel_priority strict

# Set working directory
WORKDIR /project

# Copy the problematic environment file
COPY environment.yml /project/

# Create a simple test script to verify package installation later
RUN echo '#!/bin/bash\necho ""Testing bioinformatics tools...""\nsamtools --version\nsnakemake --version\npython -c ""import biopython; print(f\""BioPython version: {biopython.__version__}\"")""' > /project/test_tools.sh && \
    chmod +x /project/test_tools.sh

# Don't actually create the environment - let the agent deal with the timeout issue
CMD [""/bin/bash""]","import os
import subprocess
import time
import json

def test_environment_created_quickly():
    """"""Test that conda environment exists and was created within reasonable time""""""
    # Check if environment-resolved.yml exists (agent should create this)
    assert os.path.exists('/project/environment-resolved.yml'), ""Resolved environment file not found""
    
    # Check if the environment exists
    result = subprocess.run(['/opt/conda/bin/conda', 'env', 'list', '--json'], 
                          capture_output=True, text=True)
    assert result.returncode == 0
    env_data = json.loads(result.stdout)
    env_names = [os.path.basename(env) for env in env_data.get('envs', [])]
    assert 'bioinfo_project' in env_names, ""bioinfo_project environment not found""

def test_core_packages_installed():
    """"""Test that core bioinformatics packages are installed and working""""""
    # Test snakemake
    result = subprocess.run(['/opt/conda/envs/bioinfo_project/bin/snakemake', '--version'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, ""Snakemake not installed or not working""
    
    # Test samtools
    result = subprocess.run(['/opt/conda/envs/bioinfo_project/bin/samtools', '--version'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, ""Samtools not installed or not working""
    
    # Test biopython import
    result = subprocess.run(['/opt/conda/envs/bioinfo_project/bin/python', '-c', 
                           'import biopython; print(biopython.__version__)'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, ""BioPython not installed or cannot be imported""","{""test_environment_created_quickly"": 0.4, ""test_core_packages_installed"": 0.6}","{""environment.yml"": ""name: bioinfo_project\nchannels:\n  - defaults\n  - conda-forge\n  - bioconda\n  - r\ndependencies:\n  # Core bioinformatics tools with specific versions\n  - snakemake=7.18.2\n  - samtools=1.16.1\n  - bcftools=1.16\n  - bwa=0.7.17\n  - bowtie2=2.4.5\n  - bedtools=2.30.0\n  - fastqc=0.11.9\n  - trimmomatic=0.39\n  - picard=2.27.5\n  - gatk4=4.3.0.0\n  \n  # Python packages with version constraints\n  - python=3.9.7\n  - biopython=1.79\n  - numpy=1.21.5\n  - pandas=1.4.2\n  - scipy=1.7.3\n  - matplotlib=3.5.1\n  - seaborn=0.11.2\n  - scikit-learn=1.0.2\n  - jupyter=1.0.0\n  - ipython=8.2.0\n  \n  # R and R packages\n  - r-base=4.1.3\n  - r-tidyverse=1.3.1\n  - r-ggplot2=3.3.5\n  - r-deseq2=1.34.0\n  - r-edger=3.36.0\n  - r-limma=3.50.0\n  - bioconductor-biostrings=2.62.0\n  - bioconductor-genomicranges=1.46.0\n  \n  # Additional scientific packages\n  - blast=2.12.0\n  - hmmer=3.3.2\n  - muscle=3.8.1551\n  - clustalw=2.1\n  - mafft=7.505\n  - raxml=8.2.12\n  - iqtree=2.2.0\n  - fasttree=2.1.11\n  \n  # Development tools\n  - git=2.35.1\n  - make=4.3\n  - cmake=3.22.1\n  - gcc_linux-64=11.2.0\n  \n  # Database tools\n  - sqlite=3.38.0\n  - postgresql=14.2\n  \n  # Additional dependencies that create conflicts\n  - pysam=0.19.1\n  - htseq=2.0.2\n  - subread=2.0.3\n  - star=2.7.10a\n  - kallisto=0.48.0\n  - salmon=1.9.0\n  \n  # pip dependencies\n  - pip\n  - pip:\n    - dendropy==4.5.2\n    - ete3==3.1.2\n    - pyvcf==0.6.8\n    - pybedtools==0.9.0""}",hard,2025-07-23T08:55:58.466167+00:00,2025-07-23T09:00:01.349573+00:00,,
draft_dp_41b0c692,I need to recreate the waveform visualization in waveform.png from audio.wav. Write a C program visualizer.c that generates reconstructed.png matching the original (correlation >= 0.96). Use FFTW3 for FFT.,"FROM python:3.11-slim

RUN apt-get update && apt-get install -y \
    gcc \
    libpng-dev \
    libfftw3-dev \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

RUN pip install pytest numpy scipy pillow matplotlib

WORKDIR /workspace

COPY generate_files.c /workspace/

RUN gcc -o generate_files generate_files.c -lpng -lfftw3 -lm && \
    ./generate_files && \
    rm generate_files generate_files.c

CMD [""/bin/bash""]","import os
import subprocess
import numpy as np
from scipy import signal
from scipy.stats import pearsonr
from PIL import Image

def test_visualizer_creates_output():
    """"""Test that visualizer.c creates reconstructed.png""""""
    # Check that visualizer.c exists
    assert os.path.exists('/workspace/visualizer.c'), ""visualizer.c not found""
    
    # Compile the visualizer
    result = subprocess.run(
        ['gcc', '-o', 'visualizer', 'visualizer.c', '-lfftw3', '-lpng', '-lm'],
        cwd='/workspace',
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f""Compilation failed: {result.stderr}""
    
    # Run the visualizer
    result = subprocess.run(
        ['./visualizer'],
        cwd='/workspace',
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f""Execution failed: {result.stderr}""
    
    # Check output exists
    assert os.path.exists('/workspace/reconstructed.png'), ""reconstructed.png not created""

def test_visualization_similarity():
    """"""Test that reconstructed visualization matches original with correlation >= 0.96""""""
    # Load both images
    original = np.array(Image.open('/workspace/waveform.png'))
    reconstructed = np.array(Image.open('/workspace/reconstructed.png'))
    
    # Ensure same dimensions
    assert original.shape == reconstructed.shape, f""Image dimensions don't match: {original.shape} vs {reconstructed.shape}""
    
    # Flatten and normalize
    orig_flat = original.flatten().astype(float) / 255.0
    recon_flat = reconstructed.flatten().astype(float) / 255.0
    
    # Calculate correlation
    correlation, _ = pearsonr(orig_flat, recon_flat)
    
    assert correlation >= 0.96, f""Correlation {correlation:.4f} is below required 0.96""","{""test_visualizer_creates_output"": 0.3, ""test_visualization_similarity"": 0.7}","{""generate_files.c"": ""#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <stdint.h>\n#include <string.h>\n#include <png.h>\n#include <fftw3.h>\n\n#define SAMPLE_RATE 44100\n#define DURATION 3.0\n#define WINDOW_SIZE 2048\n#define HOP_SIZE 512\n#define IMAGE_HEIGHT 256\n\ntypedef struct {\n    char chunkID[4];\n    uint32_t chunkSize;\n    char format[4];\n    char subchunk1ID[4];\n    uint32_t subchunk1Size;\n    uint16_t audioFormat;\n    uint16_t numChannels;\n    uint32_t sampleRate;\n    uint32_t byteRate;\n    uint16_t blockAlign;\n    uint16_t bitsPerSample;\n    char subchunk2ID[4];\n    uint32_t subchunk2Size;\n} WAVHeader;\n\nvoid generate_audio() {\n    int num_samples = (int)(SAMPLE_RATE * DURATION);\n    int16_t *samples = malloc(num_samples * sizeof(int16_t));\n    \n    // Generate a test signal with multiple frequency components\n    for (int i = 0; i < num_samples; i++) {\n        double t = (double)i / SAMPLE_RATE;\n        double signal = 0;\n        \n        // Add some frequency components\n        signal += 0.3 * sin(2 * M_PI * 440 * t);    // A4\n        signal += 0.2 * sin(2 * M_PI * 880 * t);    // A5\n        signal += 0.1 * sin(2 * M_PI * 1320 * t);   // E6\n        \n        // Add a frequency sweep\n        double sweep_freq = 200 + 800 * (t / DURATION);\n        signal += 0.2 * sin(2 * M_PI * sweep_freq * t);\n        \n        // Add some noise\n        signal += 0.05 * ((double)rand() / RAND_MAX - 0.5);\n        \n        // Convert to 16-bit PCM\n        samples[i] = (int16_t)(signal * 32767);\n    }\n    \n    // Write WAV file\n    FILE *wav = fopen(\""audio.wav\"", \""wb\"");\n    WAVHeader header;\n    \n    strncpy(header.chunkID, \""RIFF\"", 4);\n    header.chunkSize = 36 + num_samples * 2;\n    strncpy(header.format, \""WAVE\"", 4);\n    strncpy(header.subchunk1ID, \""fmt \"", 4);\n    header.subchunk1Size = 16;\n    header.audioFormat = 1;\n    header.numChannels = 1;\n    header.sampleRate = SAMPLE_RATE;\n    header.byteRate = SAMPLE_RATE * 2;\n    header.blockAlign = 2;\n    header.bitsPerSample = 16;\n    strncpy(header.subchunk2ID, \""data\"", 4);\n    header.subchunk2Size = num_samples * 2;\n    \n    fwrite(&header, sizeof(header), 1, wav);\n    fwrite(samples, sizeof(int16_t), num_samples, wav);\n    fclose(wav);\n    \n    free(samples);\n}\n\nvoid generate_visualization() {\n    // Read the WAV file\n    FILE *wav = fopen(\""audio.wav\"", \""rb\"");\n    WAVHeader header;\n    fread(&header, sizeof(header), 1, wav);\n    \n    int num_samples = header.subchunk2Size / 2;\n    int16_t *samples = malloc(num_samples * sizeof(int16_t));\n    fread(samples, sizeof(int16_t), num_samples, wav);\n    fclose(wav);\n    \n    // Calculate spectrogram dimensions\n    int num_frames = (num_samples - WINDOW_SIZE) / HOP_SIZE + 1;\n    int width = num_frames;\n    int height = IMAGE_HEIGHT;\n    \n    // Allocate image buffer\n    uint8_t (*image)[width][3] = malloc(height * width * 3);\n    \n    // FFT setup\n    double *window = fftw_malloc(sizeof(double) * WINDOW_SIZE);\n    fftw_complex *fft_out = fftw_malloc(sizeof(fftw_complex) * (WINDOW_SIZE/2 + 1));\n    fftw_plan plan = fftw_plan_dft_r2c_1d(WINDOW_SIZE, window, fft_out, FFTW_ESTIMATE);\n    \n    // Process each frame\n    for (int frame = 0; frame < num_frames; frame++) {\n        int start = frame * HOP_SIZE;\n        \n        // Apply Hann window\n        for (int i = 0; i < WINDOW_SIZE; i++) {\n            double hann = 0.5 * (1 - cos(2 * M_PI * i / (WINDOW_SIZE - 1)));\n            window[i] = samples[start + i] / 32768.0 * hann;\n        }\n        \n        // Compute FFT\n        fftw_execute(plan);\n        \n        // Convert to magnitude spectrum and map to pixels\n        for (int y = 0; y < height; y++) {\n            int bin = y * (WINDOW_SIZE/2) / height;\n            double magnitude = sqrt(fft_out[bin][0]*fft_out[bin][0] + \n                                  fft_out[bin][1]*fft_out[bin][1]);\n            \n            // Apply log scale and normalize\n            double db = 20 * log10(magnitude + 1e-10);\n            db = (db + 60) / 60;  // Normalize to 0-1 range\n            if (db < 0) db = 0;\n            if (db > 1) db = 1;\n            \n            // Color mapping (viridis-like)\n            uint8_t r, g, b;\n            if (db < 0.25) {\n                r = 68 + (int)(db * 4 * (59 - 68));\n                g = 1 + (int)(db * 4 * (82 - 1));\n                b = 84 + (int)(db * 4 * (139 - 84));\n            } else if (db < 0.5) {\n                r = 59 + (int)((db - 0.25) * 4 * (94 - 59));\n                g = 82 + (int)((db - 0.25) * 4 * (157 - 82));\n                b = 139 + (int)((db - 0.25) * 4 * (142 - 139));\n            } else if (db < 0.75) {\n                r = 94 + (int)((db - 0.5) * 4 * (253 - 94));\n                g = 157 + (int)((db - 0.5) * 4 * (231 - 157));\n                b = 142 + (int)((db - 0.5) * 4 * (37 - 142));\n            } else {\n                r = 253;\n                g = 231;\n                b = 37;\n            }\n            \n            image[height - 1 - y][frame][0] = r;\n            image[height - 1 - y][frame][1] = g;\n            image[height - 1 - y][frame][2] = b;\n        }\n    }\n    \n    // Write PNG\n    FILE *fp = fopen(\""waveform.png\"", \""wb\"");\n    png_structp png = png_create_write_struct(PNG_LIBPNG_VER_STRING, NULL, NULL, NULL);\n    png_infop info = png_create_info_struct(png);\n    \n    png_init_io(png, fp);\n    png_set_IHDR(png, info, width, height, 8, PNG_COLOR_TYPE_RGB,\n                 PNG_INTERLACE_NONE, PNG_COMPRESSION_TYPE_DEFAULT,\n                 PNG_FILTER_TYPE_DEFAULT);\n    png_write_info(png, info);\n    \n    for (int y = 0; y < height; y++) {\n        png_write_row(png, (png_bytep)image[y]);\n    }\n    \n    png_write_end(png, NULL);\n    png_destroy_write_struct(&png, &info);\n    fclose(fp);\n    \n    // Cleanup\n    fftw_destroy_plan(plan);\n    fftw_free(window);\n    fftw_free(fft_out);\n    free(samples);\n    free(image);\n}\n\nint main() {\n    generate_audio();\n    printf(\""Generated audio.wav\\n\"");\n    \n    generate_visualization();\n    printf(\""Generated waveform.png\\n\"");\n    \n    return 0;\n}""}",medium,2025-07-23T09:47:40.310932+00:00,2025-07-23T09:52:54.994642+00:00,,
draft_dp_f16ff429,Need to reverse engineer this `synth` binary and recreate it in C. It generates WAV files with `./synth <frequency> <duration>`. The reconstructed version must produce waveforms that match with >0.99 correlation.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /home/user

# Install Python packages (gcc should already be available in python image)
RUN pip install numpy scipy

# Copy and compile the original synthesizer
COPY original_synth.c /tmp/original_synth.c
RUN gcc -O2 -o /home/user/synth /tmp/original_synth.c -lm && \
    strip /home/user/synth && \
    rm /tmp/original_synth.c

# Set up the working environment
RUN chown -R user:user /home/user

USER user","import os
import subprocess
import struct
import numpy as np
from scipy.stats import pearsonr

def read_wav_data(filename):
    """"""Read raw audio data from WAV file, skipping header""""""
    with open(filename, 'rb') as f:
        # Skip WAV header (44 bytes)
        f.seek(44)
        data = f.read()
        # Convert bytes to 16-bit signed integers
        samples = []
        for i in range(0, len(data), 2):
            if i + 1 < len(data):
                sample = struct.unpack('<h', data[i:i+2])[0]
                samples.append(sample)
        return np.array(samples)

def test_synth_reconstruction_exists():
    """"""Test that the reconstructed synth.c file exists""""""
    assert os.path.exists('/home/user/synth.c'), ""synth.c not found""
    
    # Compile the reconstructed version
    result = subprocess.run(['gcc', '-o', '/home/user/synth_reconstructed', 
                           '/home/user/synth.c', '-lm'], 
                          capture_output=True, text=True)
    assert result.returncode == 0, f""Compilation failed: {result.stderr}""
    assert os.path.exists('/home/user/synth_reconstructed'), ""Compiled binary not found""

def test_waveform_correlation():
    """"""Test that reconstructed synthesizer produces matching waveforms""""""
    test_cases = [
        (440, 1.0),     # A4 note, 1 second
        (880, 0.5),     # A5 note, 0.5 seconds
        (220, 0.3),     # A3 note, 0.3 seconds
    ]
    
    for freq, duration in test_cases:
        # Generate with original
        subprocess.run(['/home/user/synth', str(freq), str(duration)], 
                      check=True)
        os.rename('output.wav', 'original.wav')
        
        # Generate with reconstructed
        subprocess.run(['/home/user/synth_reconstructed', str(freq), str(duration)], 
                      check=True)
        os.rename('output.wav', 'reconstructed.wav')
        
        # Read both WAV files
        original_data = read_wav_data('original.wav')
        reconstructed_data = read_wav_data('reconstructed.wav')
        
        # Calculate correlation
        correlation, _ = pearsonr(original_data, reconstructed_data)
        
        assert correlation >= 0.99, f""Correlation {correlation:.4f} < 0.99 for {freq}Hz, {duration}s""
        
        # Clean up
        os.remove('original.wav')
        os.remove('reconstructed.wav')","{""test_synth_reconstruction_exists"": 0.3, ""test_waveform_correlation"": 0.7}","{""original_synth.c"": ""#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <string.h>\n#include <stdint.h>\n\ntypedef struct {\n    char riff[4];\n    uint32_t file_size;\n    char wave[4];\n    char fmt[4];\n    uint32_t fmt_size;\n    uint16_t audio_format;\n    uint16_t num_channels;\n    uint32_t sample_rate;\n    uint32_t byte_rate;\n    uint16_t block_align;\n    uint16_t bits_per_sample;\n    char data[4];\n    uint32_t data_size;\n} WAVHeader;\n\nvoid write_wav_header(FILE *fp, uint32_t data_size) {\n    WAVHeader header;\n    memcpy(header.riff, \""RIFF\"", 4);\n    header.file_size = 36 + data_size;\n    memcpy(header.wave, \""WAVE\"", 4);\n    memcpy(header.fmt, \""fmt \"", 4);\n    header.fmt_size = 16;\n    header.audio_format = 1;\n    header.num_channels = 1;\n    header.sample_rate = 44100;\n    header.byte_rate = 44100 * 2;\n    header.block_align = 2;\n    header.bits_per_sample = 16;\n    memcpy(header.data, \""data\"", 4);\n    header.data_size = data_size;\n    \n    fwrite(&header, sizeof(header), 1, fp);\n}\n\nint main(int argc, char *argv[]) {\n    if (argc != 3) {\n        fprintf(stderr, \""Usage: %s <frequency> <duration>\\n\"", argv[0]);\n        return 1;\n    }\n    \n    double frequency = atof(argv[1]);\n    double duration = atof(argv[2]);\n    int sample_rate = 44100;\n    int num_samples = (int)(sample_rate * duration);\n    \n    FILE *fp = fopen(\""output.wav\"", \""wb\"");\n    if (!fp) {\n        fprintf(stderr, \""Error opening output file\\n\"");\n        return 1;\n    }\n    \n    uint32_t data_size = num_samples * 2;\n    write_wav_header(fp, data_size);\n    \n    // Generate waveform: combination of fundamental and harmonics\n    for (int i = 0; i < num_samples; i++) {\n        double t = (double)i / sample_rate;\n        double sample = 0;\n        \n        // Fundamental frequency\n        sample += 0.6 * sin(2 * M_PI * frequency * t);\n        \n        // Second harmonic with slight detuning\n        sample += 0.3 * sin(2 * M_PI * frequency * 2.002 * t + 0.1);\n        \n        // Third harmonic\n        sample += 0.15 * sin(2 * M_PI * frequency * 3 * t + 0.2);\n        \n        // Add subtle amplitude envelope\n        double envelope = 1.0 - 0.2 * exp(-5 * t);\n        sample *= envelope;\n        \n        // Convert to 16-bit integer\n        int16_t sample_int = (int16_t)(sample * 32000);\n        fwrite(&sample_int, sizeof(int16_t), 1, fp);\n    }\n    \n    fclose(fp);\n    return 0;\n}""}",hard,2025-07-23T09:51:28.772889+00:00,2025-07-23T09:53:23.527628+00:00,,
draft_dp_8013065c,"Need K-means clustering implemented in three versions: serial, OpenMP parallel, and MPI distributed. Each should load CSV data, use K-means++ init with seed 42, and output cluster assignments, centers, and WCSS. All versions must produce identical results.","FROM ubuntu:22.04

RUN apt-get update && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y \
    build-essential \
    g++ \
    libomp-dev \
    openmpi-bin \
    libopenmpi-dev \
    make \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY Makefile /app/
COPY data_small.csv /app/
COPY data_medium.csv /app/

CMD [""/bin/bash""]","import os
import subprocess
import re

def test_kmeans_executables_exist():
    """"""Test that all three K-means executables were created.""""""
    assert os.path.exists('/app/kmeans_serial'), ""Serial executable not found""
    assert os.path.exists('/app/kmeans_omp'), ""OpenMP executable not found""
    assert os.path.exists('/app/kmeans_mpi'), ""MPI executable not found""

def test_kmeans_outputs_consistent():
    """"""Test that all implementations produce consistent WCSS values.""""""
    # Run serial version
    serial_result = subprocess.run(['/app/kmeans_serial', 'data_small.csv', '3'], 
                                 capture_output=True, text=True, cwd='/app')
    assert serial_result.returncode == 0, ""Serial version failed to run""
    
    # Extract WCSS from serial output
    wcss_match = re.search(r'WCSS:\s*([\d.]+)', serial_result.stdout)
    assert wcss_match, ""Serial version did not output WCSS""
    serial_wcss = float(wcss_match.group(1))
    
    # Run OpenMP version
    omp_result = subprocess.run(['/app/kmeans_omp', 'data_small.csv', '3'], 
                              capture_output=True, text=True, cwd='/app')
    assert omp_result.returncode == 0, ""OpenMP version failed to run""
    
    # Extract WCSS from OpenMP output
    wcss_match = re.search(r'WCSS:\s*([\d.]+)', omp_result.stdout)
    assert wcss_match, ""OpenMP version did not output WCSS""
    omp_wcss = float(wcss_match.group(1))
    
    # Check that WCSS values are within 0.01% tolerance
    tolerance = serial_wcss * 0.0001
    assert abs(serial_wcss - omp_wcss) <= tolerance, \
        f""WCSS values differ too much: serial={serial_wcss}, omp={omp_wcss}""","{""test_kmeans_executables_exist"": 0.3, ""test_kmeans_outputs_consistent"": 0.7}","{""Makefile"": ""CXX = g++\nCXXFLAGS = -std=c++11 -O2 -Wall\nOMPFLAGS = -fopenmp\nMPIXX = mpic++\n\nall: kmeans_serial kmeans_omp kmeans_mpi\n\nkmeans_serial: kmeans_serial.cpp\n\t$(CXX) $(CXXFLAGS) -o $@ $<\n\nkmeans_omp: kmeans_omp.cpp\n\t$(CXX) $(CXXFLAGS) $(OMPFLAGS) -o $@ $<\n\nkmeans_mpi: kmeans_mpi.cpp\n\t$(MPIXX) $(CXXFLAGS) -o $@ $<\n\nclean:\n\trm -f kmeans_serial kmeans_omp kmeans_mpi *.out\n\n.PHONY: all clean"", ""data_medium.csv"": ""2.1,3.2,1.5\n3.2,4.3,2.1\n4.3,5.4,3.2\n5.4,6.5,4.3\n11.0,12.1,10.5\n12.1,13.2,11.6\n13.2,14.3,12.7\n14.3,15.4,13.8\n21.4,22.5,20.9\n22.5,23.6,22.0\n23.6,24.7,23.1\n24.7,25.8,24.2\n6.5,7.6,5.4\n7.6,8.7,6.5\n15.4,16.5,14.9\n16.5,17.6,16.0\n25.8,26.9,25.3\n26.9,28.0,26.4\n8.7,9.8,7.6\n9.8,10.9,8.7\n17.6,18.7,17.1\n18.7,19.8,18.2\n28.0,29.1,27.5\n29.1,30.2,28.6\n1.0,2.1,0.5\n10.9,12.0,10.4\n19.8,20.9,19.3\n30.2,31.3,29.7\n0.5,1.6,0.0\n31.3,32.4,30.8"", ""data_small.csv"": ""1.2,3.4\n2.3,4.5\n3.4,5.6\n4.5,6.7\n10.1,11.2\n11.2,12.3\n12.3,13.4\n13.4,14.5\n20.5,21.6\n21.6,22.7\n22.7,23.8\n23.8,24.9""}",hard,2025-07-23T10:01:07.465256+00:00,2025-07-23T10:02:38.638620+00:00,,
draft_dp_e2bb0e89,The ray tracer is only rendering with the serial version. Need OpenMP and MPI parallel implementations that produce identical output images. Target 2x speedup on 4 cores for the test scene.,"FROM ubuntu:22.04

WORKDIR /app

RUN apt-get update && apt-get install -y \
    g++ \
    make \
    libomp-dev \
    openmpi-bin \
    libopenmpi-dev \
    tmux \
    asciinema \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

COPY vec3.h /app/
COPY scene.h /app/
COPY raytracer.h /app/
COPY raytracer.cpp /app/
COPY main.cpp /app/
COPY main_omp.cpp /app/
COPY raytracer_omp.cpp /app/
COPY main_mpi.cpp /app/
COPY raytracer_mpi.cpp /app/
COPY Makefile /app/

RUN make raytracer","import subprocess
import os
import time

def test_parallel_implementations_produce_identical_output():
    """"""Test that all three implementations produce identical PPM files""""""
    # Run all three versions
    subprocess.run([""./raytracer"", ""100"", ""100""], check=True)
    subprocess.run([""./raytracer_omp"", ""100"", ""100""], check=True)
    subprocess.run([""mpirun"", ""-np"", ""4"", ""./raytracer_mpi"", ""100"", ""100""], check=True)
    
    # Read the output files
    with open(""output_serial.ppm"", ""r"") as f:
        serial_output = f.read()
    
    with open(""output_omp.ppm"", ""r"") as f:
        omp_output = f.read()
    
    with open(""output_mpi.ppm"", ""r"") as f:
        mpi_output = f.read()
    
    # All outputs should be identical
    assert serial_output == omp_output, ""OpenMP output differs from serial""
    assert serial_output == mpi_output, ""MPI output differs from serial""

def test_parallel_versions_achieve_speedup():
    """"""Test that parallel versions are faster than serial on larger image""""""
    # Time serial version
    start = time.time()
    subprocess.run([""./raytracer"", ""400"", ""300""], check=True)
    serial_time = time.time() - start
    
    # Time OpenMP version with 4 threads
    os.environ[""OMP_NUM_THREADS""] = ""4""
    start = time.time()
    subprocess.run([""./raytracer_omp"", ""400"", ""300""], check=True)
    omp_time = time.time() - start
    
    # Time MPI version with 4 processes
    start = time.time()
    subprocess.run([""mpirun"", ""-np"", ""4"", ""./raytracer_mpi"", ""400"", ""300""], check=True)
    mpi_time = time.time() - start
    
    # Parallel versions should achieve at least 2x speedup
    omp_speedup = serial_time / omp_time
    mpi_speedup = serial_time / mpi_time
    
    assert omp_speedup >= 2.0, f""OpenMP speedup {omp_speedup:.2f}x is less than 2x""
    assert mpi_speedup >= 2.0, f""MPI speedup {mpi_speedup:.2f}x is less than 2x""","{""test_parallel_implementations_produce_identical_output"": 0.6, ""test_parallel_versions_achieve_speedup"": 0.4}","{""main_omp.cpp"": ""#include \""raytracer.h\""\n#include <iostream>\n\n// TODO: Implement OpenMP version\n\nint main(int argc, char* argv[]) {\n    std::cerr << \""OpenMP version not implemented yet\\n\"";\n    return 1;\n}"", ""raytracer.cpp"": ""#include \""raytracer.h\""\n#include <fstream>\n#include <algorithm>\n\nVec3 RayTracer::trace(const Ray& ray, int depth) {\n    if (depth > 3) return Vec3(0, 0, 0);\n    \n    double closest_t = 1e9;\n    const Sphere* hit_sphere = nullptr;\n    \n    for (const auto& sphere : scene.spheres) {\n        double t;\n        intersection_tests++;\n        if (sphere.intersect(ray, t) && t < closest_t) {\n            closest_t = t;\n            hit_sphere = &sphere;\n        }\n    }\n    \n    if (!hit_sphere) {\n        // Sky color\n        double t = 0.5 * (ray.direction.y + 1.0);\n        return Vec3(1, 1, 1) * (1 - t) + Vec3(0.5, 0.7, 1.0) * t;\n    }\n    \n    Vec3 hit_point = ray.origin + ray.direction * closest_t;\n    Vec3 normal = (hit_point - hit_sphere->center).normalize();\n    \n    return shade(hit_point, normal, ray.direction * -1, hit_sphere->color);\n}\n\nVec3 RayTracer::shade(const Vec3& hit_point, const Vec3& normal, const Vec3& view_dir, const Vec3& color) {\n    // Ambient\n    Vec3 result = Vec3(color.x * scene.ambient_light.x,\n                      color.y * scene.ambient_light.y,\n                      color.z * scene.ambient_light.z);\n    \n    // Diffuse\n    Vec3 light_dir = (scene.light_pos - hit_point).normalize();\n    double diff = std::max(0.0, normal.dot(light_dir));\n    result = result + color * diff * 0.6;\n    \n    // Specular\n    Vec3 reflect_dir = light_dir - normal * (2 * normal.dot(light_dir));\n    double spec = std::pow(std::max(0.0, view_dir.dot(reflect_dir)), 32);\n    result = result + Vec3(1, 1, 1) * spec * 0.3;\n    \n    // Clamp\n    result.x = std::min(1.0, result.x);\n    result.y = std::min(1.0, result.y);\n    result.z = std::min(1.0, result.z);\n    \n    return result;\n}\n\nvoid RayTracer::save_ppm(const char* filename) {\n    std::ofstream file(filename);\n    file << \""P3\\n\"" << width << \"" \"" << height << \""\\n255\\n\"";\n    \n    for (int i = 0; i < width * height; i++) {\n        int r = static_cast<int>(pixels[i].x * 255);\n        int g = static_cast<int>(pixels[i].y * 255);\n        int b = static_cast<int>(pixels[i].z * 255);\n        file << r << \"" \"" << g << \"" \"" << b << \""\\n\"";\n    }\n}"", ""Makefile"": ""CXX = g++\nCXXFLAGS = -std=c++11 -O2 -Wall\nOMPFLAGS = -fopenmp\nMPIXX = mpic++\n\nall: raytracer raytracer_omp raytracer_mpi\n\nraytracer: main.cpp raytracer.cpp vec3.h raytracer.h scene.h\n\t$(CXX) $(CXXFLAGS) -o raytracer main.cpp raytracer.cpp\n\nraytracer_omp: main_omp.cpp raytracer_omp.cpp vec3.h raytracer.h scene.h\n\t$(CXX) $(CXXFLAGS) $(OMPFLAGS) -o raytracer_omp main_omp.cpp raytracer_omp.cpp\n\nraytracer_mpi: main_mpi.cpp raytracer_mpi.cpp vec3.h raytracer.h scene.h\n\t$(MPIXX) $(CXXFLAGS) -o raytracer_mpi main_mpi.cpp raytracer_mpi.cpp\n\nclean:\n\trm -f raytracer raytracer_omp raytracer_mpi *.ppm"", ""main_mpi.cpp"": ""#include \""raytracer.h\""\n#include <iostream>\n\n// TODO: Implement MPI version\n\nint main(int argc, char* argv[]) {\n    std::cerr << \""MPI version not implemented yet\\n\"";\n    return 1;\n}"", ""raytracer_omp.cpp"": ""// Placeholder for OpenMP implementation"", ""vec3.h"": ""#ifndef VEC3_H\n#define VEC3_H\n\n#include <cmath>\n\nstruct Vec3 {\n    double x, y, z;\n    \n    Vec3() : x(0), y(0), z(0) {}\n    Vec3(double x, double y, double z) : x(x), y(y), z(z) {}\n    \n    Vec3 operator+(const Vec3& v) const { return Vec3(x + v.x, y + v.y, z + v.z); }\n    Vec3 operator-(const Vec3& v) const { return Vec3(x - v.x, y - v.y, z - v.z); }\n    Vec3 operator*(double t) const { return Vec3(x * t, y * t, z * t); }\n    Vec3 operator/(double t) const { return Vec3(x / t, y / t, z / t); }\n    \n    double dot(const Vec3& v) const { return x * v.x + y * v.y + z * v.z; }\n    Vec3 cross(const Vec3& v) const {\n        return Vec3(y * v.z - z * v.y, z * v.x - x * v.z, x * v.y - y * v.x);\n    }\n    \n    double length() const { return sqrt(x * x + y * y + z * z); }\n    Vec3 normalize() const { double len = length(); return Vec3(x / len, y / len, z / len); }\n};\n\n#endif"", ""main.cpp"": ""#include \""raytracer.h\""\n#include <iostream>\n#include <chrono>\n\nclass SerialRayTracer : public RayTracer {\npublic:\n    SerialRayTracer(int w, int h) : RayTracer(w, h) {}\n    \n    void render() override {\n        double aspect = double(width) / height;\n        \n        for (int y = 0; y < height; y++) {\n            for (int x = 0; x < width; x++) {\n                double u = (2.0 * x / width - 1.0) * aspect;\n                double v = 1.0 - 2.0 * y / height;\n                \n                Ray ray(Vec3(0, 0, 0), Vec3(u, v, -1).normalize());\n                pixels[y * width + x] = trace(ray);\n            }\n        }\n    }\n};\n\nint main(int argc, char* argv[]) {\n    int width = 400;\n    int height = 300;\n    \n    if (argc > 1) width = std::atoi(argv[1]);\n    if (argc > 2) height = std::atoi(argv[2]);\n    \n    SerialRayTracer tracer(width, height);\n    \n    auto start = std::chrono::high_resolution_clock::now();\n    tracer.render();\n    auto end = std::chrono::high_resolution_clock::now();\n    \n    double time = std::chrono::duration<double>(end - start).count();\n    \n    tracer.save_ppm(\""output_serial.ppm\"");\n    \n    std::cout << \""Serial version:\\n\"";\n    std::cout << \""Time: \"" << time << \"" seconds\\n\"";\n    std::cout << \""Intersection tests: \"" << tracer.get_intersection_tests() << \""\\n\"";\n    \n    return 0;\n}"", ""raytracer.h"": ""#ifndef RAYTRACER_H\n#define RAYTRACER_H\n\n#include \""vec3.h\""\n#include \""scene.h\""\n#include <vector>\n\nclass RayTracer {\nprotected:\n    int width, height;\n    Scene scene;\n    std::vector<Vec3> pixels;\n    long long intersection_tests;\n    \npublic:\n    RayTracer(int w, int h) : width(w), height(h), pixels(w * h), intersection_tests(0) {}\n    \n    virtual void render() = 0;\n    \n    Vec3 trace(const Ray& ray, int depth = 0);\n    Vec3 shade(const Vec3& hit_point, const Vec3& normal, const Vec3& view_dir, const Vec3& color);\n    \n    void save_ppm(const char* filename);\n    long long get_intersection_tests() const { return intersection_tests; }\n};\n\n#endif"", ""raytracer_mpi.cpp"": ""// Placeholder for MPI implementation"", ""scene.h"": ""#ifndef SCENE_H\n#define SCENE_H\n\n#include \""vec3.h\""\n#include <vector>\n\nstruct Ray {\n    Vec3 origin, direction;\n    Ray(const Vec3& o, const Vec3& d) : origin(o), direction(d.normalize()) {}\n};\n\nstruct Sphere {\n    Vec3 center;\n    double radius;\n    Vec3 color;\n    double reflectivity;\n    \n    Sphere(const Vec3& c, double r, const Vec3& col, double refl = 0.0) \n        : center(c), radius(r), color(col), reflectivity(refl) {}\n    \n    bool intersect(const Ray& ray, double& t) const {\n        Vec3 oc = ray.origin - center;\n        double a = ray.direction.dot(ray.direction);\n        double b = 2.0 * oc.dot(ray.direction);\n        double c = oc.dot(oc) - radius * radius;\n        double discriminant = b * b - 4 * a * c;\n        \n        if (discriminant < 0) return false;\n        \n        double t1 = (-b - sqrt(discriminant)) / (2 * a);\n        double t2 = (-b + sqrt(discriminant)) / (2 * a);\n        \n        if (t1 > 0.001) {\n            t = t1;\n            return true;\n        }\n        if (t2 > 0.001) {\n            t = t2;\n            return true;\n        }\n        return false;\n    }\n};\n\nstruct Scene {\n    std::vector<Sphere> spheres;\n    Vec3 light_pos;\n    Vec3 ambient_light;\n    \n    Scene() : light_pos(2, 4, -3), ambient_light(0.2, 0.2, 0.2) {\n        // Test scene with 3 spheres\n        spheres.push_back(Sphere(Vec3(0, 0, -5), 1.0, Vec3(1, 0, 0)));      // Red\n        spheres.push_back(Sphere(Vec3(-2, 0, -6), 1.0, Vec3(0, 1, 0)));     // Green  \n        spheres.push_back(Sphere(Vec3(2, -1, -4), 0.8, Vec3(0, 0, 1)));     // Blue\n    }\n};\n\n#endif""}",hard,2025-07-23T10:01:16.230557+00:00,2025-07-23T10:02:04.400532+00:00,,
draft_dp_f1db9196,"Found these input/output pairs showing a text pattern transformation algorithm. Analyze input1.txtoutput1.txt, input2.txtoutput2.txt, and input3.txtoutput3.txt to figure out the exact mapping rules. Write transform.py that converts pattern.txt to result.txt using the same algorithm.","FROM ghcr.io/laude-institute/t-bench/ubuntu-24-04:latest

WORKDIR /app

# Create sample input pattern files and their ASCII outputs
COPY pattern1.txt /app/input1.txt
COPY output1.txt /app/
COPY pattern2.txt /app/input2.txt
COPY output2.txt /app/
COPY pattern3.txt /app/input3.txt
COPY output3.txt /app/
COPY test_pattern.txt /app/pattern.txt","import os
import subprocess

def test_transform_program_exists_and_runs():
    """"""Test that the transform program exists and produces output.""""""
    # Check if source file exists
    assert os.path.exists('/app/transform.py'), ""transform.py file not found""
    
    # Run the program
    result = subprocess.run(['python3', 'transform.py'], capture_output=True, text=True, cwd='/app')
    assert result.returncode == 0, f""Program execution failed: {result.stderr}""
    
    # Check output file exists
    assert os.path.exists('/app/result.txt'), ""Output file result.txt not found""

def test_transform_output_correctness():
    """"""Test that the transform output follows the deduced algorithm.""""""
    # This test assumes the program has already been run
    assert os.path.exists('/app/result.txt'), ""result.txt not found""
    
    # Read the output
    with open('/app/result.txt', 'r') as f:
        output = f.read().strip()
    
    # Basic validation - check it's not empty and has reasonable structure
    lines = output.split('\n')
    assert len(lines) == 10, f""Output should have 10 lines, got {len(lines)}""
    assert all(len(line) == 20 for line in lines), ""All output lines should be 20 characters""
    
    # Check that it uses the expected character set based on examples
    expected_chars = set('@%#*+-:.')
    output_chars = set(output.replace('\n', ''))
    assert output_chars.issubset(expected_chars), f""Unexpected characters used: {output_chars - expected_chars}""","{""test_transform_program_exists_and_runs"": 0.3, ""test_transform_output_correctness"": 0.7}","{""output2.txt"": ""....................@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@....................\n..................@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@..................\n................@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@................\n..............@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@..............\n............@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@............\n..........@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@..........\n........@@@@@@@@@@@@@@@@####################@@@@@@@@@@@@@@@@@@@@........\n........@@@@@@@@@@@@######------------------######@@@@@@@@@@@@@@........\n......@@@@@@@@@@@@####--------------------------####@@@@@@@@@@@@@@......\n......@@@@@@@@@@####------...................------####@@@@@@@@@@@@......\n....@@@@@@@@@@@@##------....................--------##@@@@@@@@@@@@@@....\n....@@@@@@@@@@@@##------....................--------##@@@@@@@@@@@@@@....\n....@@@@@@@@@@@@##------....................--------##@@@@@@@@@@@@@@....\n....@@@@@@@@@@@@##------....................--------##@@@@@@@@@@@@@@....\n......@@@@@@@@@@####------...................------####@@@@@@@@@@@@......\n......@@@@@@@@@@@@####--------------------------####@@@@@@@@@@@@@@......\n........@@@@@@@@@@@@######------------------######@@@@@@@@@@@@@@........\n........@@@@@@@@@@@@@@@@####################@@@@@@@@@@@@@@@@@@@@........\n..........@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@..........\n............@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@............\n..............@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@..............\n................@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@................\n..................@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@..................\n....................@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@...................."", ""output3.txt"": ""@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n........@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@\n........@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@\n........@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@\n........@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@\n........@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@\n........@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........\n@@@@@@@@........@@@@@@@@........@@@@@@@@........@@@@@@@@........"", ""output1.txt"": ""@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::..........\n@@@@@@@@@@%%%%%%%%%%%%%%%%########********++++++++--------::::::::.........."", ""test_pattern.txt"": ""00000000999999999999\n00000000999999999999\n00000000999999999999\n00000000999999999999\n55555555444444444444\n55555555444444444444\n55555555444444444444\n99999999000000000000\n99999999000000000000\n99999999000000000000"", ""pattern3.txt"": ""00009999000099990000\n00009999000099990000\n00009999000099990000\n99990000999900009999\n99990000999900009999\n99990000999900009999\n00009999000099990000\n00009999000099990000"", ""pattern2.txt"": ""9999999999999999999999999\n9999999999999999999999999\n9999990000000000009999999\n9999990000000000009999999\n9999990005555555009999999\n9999990005555555009999999\n9999990000000000009999999\n9999990000000000009999999\n9999999999999999999999999\n9999999999999999999999999"", ""pattern1.txt"": ""0000111122223333444455556666777788889999""}",medium,2025-07-23T10:01:26.947467+00:00,2025-07-23T10:03:45.870599+00:00,,
draft_dp_50ee440d,"Our audio processor is too slow. Add SIMD vectorization for the gain and echo effects - need both scalar and SIMD versions that produce identical output. Use SSE/AVX intrinsics, the WAV I/O is already there.","FROM ubuntu:22.04

WORKDIR /app

RUN apt-get update && \
    apt-get install -y \
    build-essential \
    gcc \
    g++ \
    make \
    binutils \
    tmux \
    asciinema \
    && rm -rf /var/lib/apt/lists/*

COPY Makefile /app/
COPY audio_processor.c /app/
COPY audio_processor.h /app/
COPY wav_io.c /app/
COPY wav_io.h /app/
COPY main.c /app/
COPY generate_test_wav.c /app/

RUN gcc -o generate_test_wav generate_test_wav.c -lm && \
    ./generate_test_wav && \
    make","import subprocess
import os
import hashlib

def test_simd_implementation_exists():
    """"""Test that SIMD implementations were added to the processor""""""
    result = subprocess.run(['objdump', '-d', '/app/audio_processor'], 
                          capture_output=True, text=True)
    
    assert 'vpmulld' in result.stdout or 'vmulps' in result.stdout or 'pmulld' in result.stdout or 'mulps' in result.stdout, \
        ""No SIMD multiplication instructions found in binary""
    
    result = subprocess.run(['nm', '/app/audio_processor'], 
                          capture_output=True, text=True)
    assert 'apply_gain_simd' in result.stdout or 'apply_echo_simd' in result.stdout, \
        ""No SIMD function symbols found in binary""

def test_simd_scalar_identical_output():
    """"""Test that scalar and SIMD versions produce identical output""""""
    subprocess.run(['./audio_processor', 'test.wav', 'gain_scalar.wav', 'gain', 'scalar'], 
                   cwd='/app', check=True)
    
    subprocess.run(['./audio_processor', 'test.wav', 'gain_simd.wav', 'gain', 'simd'], 
                   cwd='/app', check=True)
    
    with open('/app/gain_scalar.wav', 'rb') as f1:
        scalar_hash = hashlib.md5(f1.read()).hexdigest()
    
    with open('/app/gain_simd.wav', 'rb') as f2:
        simd_hash = hashlib.md5(f2.read()).hexdigest()
    
    assert scalar_hash == simd_hash, ""SIMD and scalar outputs are not identical""","{""test_simd_implementation_exists"": 0.4, ""test_simd_scalar_identical_output"": 0.6}","{""audio_processor.c"": ""#include \""audio_processor.h\""\n#include <stdlib.h>\n#include <string.h>\n\nvoid apply_gain_scalar(int16_t* data, size_t num_samples, float gain) {\n    for (size_t i = 0; i < num_samples; i++) {\n        float sample = data[i] * gain;\n        if (sample > 32767) sample = 32767;\n        if (sample < -32768) sample = -32768;\n        data[i] = (int16_t)sample;\n    }\n}\n\nvoid apply_echo_scalar(int16_t* data, size_t num_samples, int delay_samples, float decay) {\n    int16_t* buffer = malloc(num_samples * sizeof(int16_t));\n    memcpy(buffer, data, num_samples * sizeof(int16_t));\n    \n    for (size_t i = delay_samples; i < num_samples; i++) {\n        float delayed = buffer[i - delay_samples] * decay;\n        float sample = data[i] + delayed;\n        if (sample > 32767) sample = 32767;\n        if (sample < -32768) sample = -32768;\n        data[i] = (int16_t)sample;\n    }\n    \n    free(buffer);\n}"", ""Makefile"": ""CC = gcc\nCFLAGS = -O2 -march=native -msse -msse2 -mavx -Wall\nTARGET = audio_processor\n\nSRCS = main.c audio_processor.c wav_io.c\nOBJS = $(SRCS:.c=.o)\n\nall: $(TARGET)\n\n$(TARGET): $(OBJS)\n\t$(CC) $(CFLAGS) -o $@ $^\n\n%.o: %.c\n\t$(CC) $(CFLAGS) -c $< -o $@\n\nclean:\n\trm -f $(OBJS) $(TARGET)\n\n.PHONY: all clean"", ""generate_test_wav.c"": ""#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <stdint.h>\n\ntypedef struct {\n    char chunk_id[4];\n    uint32_t chunk_size;\n    char format[4];\n    char subchunk1_id[4];\n    uint32_t subchunk1_size;\n    uint16_t audio_format;\n    uint16_t num_channels;\n    uint32_t sample_rate;\n    uint32_t byte_rate;\n    uint16_t block_align;\n    uint16_t bits_per_sample;\n    char subchunk2_id[4];\n    uint32_t subchunk2_size;\n} wav_header_t;\n\nvoid create_test_wav(const char* filename, int duration_ms, int frequency) {\n    int sample_rate = 44100;\n    int num_samples = (sample_rate * duration_ms) / 1000;\n    int data_size = num_samples * sizeof(int16_t);\n    \n    wav_header_t header = {\n        {'R', 'I', 'F', 'F'},\n        36 + data_size,\n        {'W', 'A', 'V', 'E'},\n        {'f', 'm', 't', ' '},\n        16,\n        1,\n        1,\n        sample_rate,\n        sample_rate * 2,\n        2,\n        16,\n        {'d', 'a', 't', 'a'},\n        data_size\n    };\n    \n    int16_t* data = malloc(data_size);\n    \n    for (int i = 0; i < num_samples; i++) {\n        double t = (double)i / sample_rate;\n        data[i] = (int16_t)(32767 * 0.3 * sin(2 * M_PI * frequency * t));\n    }\n    \n    FILE* file = fopen(filename, \""wb\"");\n    fwrite(&header, sizeof(header), 1, file);\n    fwrite(data, data_size, 1, file);\n    fclose(file);\n    \n    free(data);\n}\n\nint main() {\n    create_test_wav(\""test.wav\"", 1000, 440);\n    return 0;\n}"", ""wav_io.c"": ""#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include \""wav_io.h\""\n\nwav_file_t* read_wav(const char* filename) {\n    FILE* file = fopen(filename, \""rb\"");\n    if (!file) return NULL;\n    \n    wav_file_t* wav = malloc(sizeof(wav_file_t));\n    if (!wav) {\n        fclose(file);\n        return NULL;\n    }\n    \n    fread(&wav->header, sizeof(wav_header_t), 1, file);\n    \n    wav->num_samples = wav->header.subchunk2_size / sizeof(int16_t);\n    wav->data = malloc(wav->header.subchunk2_size);\n    if (!wav->data) {\n        free(wav);\n        fclose(file);\n        return NULL;\n    }\n    \n    fread(wav->data, wav->header.subchunk2_size, 1, file);\n    fclose(file);\n    \n    return wav;\n}\n\nint write_wav(const char* filename, wav_file_t* wav) {\n    FILE* file = fopen(filename, \""wb\"");\n    if (!file) return -1;\n    \n    fwrite(&wav->header, sizeof(wav_header_t), 1, file);\n    fwrite(wav->data, wav->header.subchunk2_size, 1, file);\n    fclose(file);\n    \n    return 0;\n}\n\nvoid free_wav(wav_file_t* wav) {\n    if (wav) {\n        if (wav->data) free(wav->data);\n        free(wav);\n    }\n}"", ""main.c"": ""#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include \""wav_io.h\""\n#include \""audio_processor.h\""\n\nvoid print_usage() {\n    printf(\""Usage: audio_processor <input.wav> <output.wav> <effect> [mode]\\n\"");\n    printf(\""Effects: gain, echo\\n\"");\n    printf(\""Mode: scalar (default), simd\\n\"");\n}\n\nint main(int argc, char* argv[]) {\n    if (argc < 4) {\n        print_usage();\n        return 1;\n    }\n    \n    const char* input_file = argv[1];\n    const char* output_file = argv[2];\n    const char* effect = argv[3];\n    const char* mode = argc > 4 ? argv[4] : \""scalar\"";\n    \n    wav_file_t* wav = read_wav(input_file);\n    if (!wav) {\n        printf(\""Error reading WAV file\\n\"");\n        return 1;\n    }\n    \n    if (strcmp(effect, \""gain\"") == 0) {\n        apply_gain_scalar(wav->data, wav->num_samples, 0.5f);\n    } else if (strcmp(effect, \""echo\"") == 0) {\n        int delay_samples = wav->header.sample_rate * 0.25;\n        apply_echo_scalar(wav->data, wav->num_samples, delay_samples, 0.5f);\n    } else {\n        printf(\""Unknown effect: %s\\n\"", effect);\n        free_wav(wav);\n        return 1;\n    }\n    \n    if (write_wav(output_file, wav) != 0) {\n        printf(\""Error writing WAV file\\n\"");\n        free_wav(wav);\n        return 1;\n    }\n    \n    free_wav(wav);\n    return 0;\n}"", ""wav_io.h"": ""#ifndef WAV_IO_H\n#define WAV_IO_H\n\n#include <stdint.h>\n\ntypedef struct {\n    char chunk_id[4];\n    uint32_t chunk_size;\n    char format[4];\n    char subchunk1_id[4];\n    uint32_t subchunk1_size;\n    uint16_t audio_format;\n    uint16_t num_channels;\n    uint32_t sample_rate;\n    uint32_t byte_rate;\n    uint16_t block_align;\n    uint16_t bits_per_sample;\n    char subchunk2_id[4];\n    uint32_t subchunk2_size;\n} wav_header_t;\n\ntypedef struct {\n    wav_header_t header;\n    int16_t *data;\n    size_t num_samples;\n} wav_file_t;\n\nwav_file_t* read_wav(const char* filename);\nint write_wav(const char* filename, wav_file_t* wav);\nvoid free_wav(wav_file_t* wav);\n\n#endif"", ""audio_processor.h"": ""#ifndef AUDIO_PROCESSOR_H\n#define AUDIO_PROCESSOR_H\n\n#include <stdint.h>\n#include <stddef.h>\n\nvoid apply_gain_scalar(int16_t* data, size_t num_samples, float gain);\nvoid apply_echo_scalar(int16_t* data, size_t num_samples, int delay_samples, float decay);\n\n#endif""}",medium,2025-07-23T10:01:46.743108+00:00,2025-07-23T10:02:45.514234+00:00,,
draft_dp_8f25a462,Need a Chapel implementation of PageRank that handles the social_network.txt graph. The current serial version is too slow - make it parallel using Chapel's distributed arrays and run it with at least 4 tasks.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /app

# Download and install Chapel (pre-built binary)
RUN curl -L -o chapel-2.2.0-linux-x86_64.tar.gz https://github.com/chapel-lang/chapel/releases/download/2.2.0/chapel-2.2.0-linux-x86_64.tar.gz && \
    tar -xzf chapel-2.2.0-linux-x86_64.tar.gz && \
    rm chapel-2.2.0-linux-x86_64.tar.gz && \
    mv chapel-2.2.0-linux-x86_64 /opt/chapel

# Set Chapel environment variables
ENV CHPL_HOME=/opt/chapel
ENV PATH=$CHPL_HOME/bin/linux-x86_64:$PATH
ENV CHPL_TARGET_PLATFORM=linux64
ENV CHPL_HOST_PLATFORM=linux64
ENV CHPL_COMM=none
ENV CHPL_TASKS=qthreads

# Copy project files
COPY Makefile /app/
COPY pagerank_serial.chpl /app/
COPY social_network.txt /app/
COPY small_test.txt /app/

# Create output directory
RUN mkdir -p /app/output

CMD [""/bin/bash""]","import os
import subprocess
import json

def test_parallel_pagerank_exists():
    """"""Test that a parallel PageRank implementation exists and compiles.""""""
    # Check for parallel implementation file
    assert os.path.exists('/app/pagerank_parallel.chpl'), ""Parallel PageRank implementation file not found""
    
    # Try to compile the parallel version
    result = subprocess.run(['chpl', '-o', 'pagerank_parallel', 'pagerank_parallel.chpl'], 
                          cwd='/app', capture_output=True, text=True)
    assert result.returncode == 0, f""Failed to compile parallel PageRank: {result.stderr}""
    assert os.path.exists('/app/pagerank_parallel'), ""Compiled parallel binary not found""

def test_parallel_pagerank_runs_with_tasks():
    """"""Test that parallel PageRank runs with multiple tasks and produces output.""""""
    # First compile if needed
    if not os.path.exists('/app/pagerank_parallel'):
        subprocess.run(['chpl', '-o', 'pagerank_parallel', 'pagerank_parallel.chpl'], 
                      cwd='/app', capture_output=True)
    
    # Run with 4 tasks on the social network graph
    result = subprocess.run(['./pagerank_parallel', '--numTasks=4', 'social_network.txt', 'output/pagerank_results.txt'],
                          cwd='/app', capture_output=True, text=True)
    assert result.returncode == 0, f""Parallel PageRank failed to run: {result.stderr}""
    
    # Check output file exists and has content
    assert os.path.exists('/app/output/pagerank_results.txt'), ""PageRank output file not created""
    
    with open('/app/output/pagerank_results.txt', 'r') as f:
        content = f.read().strip()
    assert len(content) > 0, ""PageRank output file is empty""
    
    # Verify it contains PageRank values (basic format check)
    lines = content.split('\n')
    assert len(lines) > 10, ""PageRank output has too few nodes""
    
    # Check that Chapel parallel constructs are used
    with open('/app/pagerank_parallel.chpl', 'r') as f:
        source = f.read()
    assert any(keyword in source for keyword in ['coforall', 'forall', 'begin', 'cobegin', 'sync']), \
        ""No Chapel parallel constructs found in implementation""","{""test_parallel_pagerank_exists"": 0.4, ""test_parallel_pagerank_runs_with_tasks"": 0.6}","{""small_test.txt"": ""0 1\n1 2\n2 0\n2 3\n3 3"", ""social_network.txt"": ""0 1\n0 2\n0 3\n1 0\n1 4\n1 5\n2 0\n2 6\n2 7\n3 0\n3 8\n3 9\n4 1\n4 10\n4 11\n5 1\n5 12\n5 13\n6 2\n6 14\n6 15\n7 2\n7 16\n7 17\n8 3\n8 18\n8 19\n9 3\n9 20\n9 21\n10 4\n10 22\n11 4\n11 23\n12 5\n12 24\n13 5\n13 25\n14 6\n14 26\n15 6\n15 27\n16 7\n16 28\n17 7\n17 29\n18 8\n18 30\n19 8\n19 31\n20 9\n20 32\n21 9\n21 33\n22 10\n22 34\n23 11\n23 35\n24 12\n24 36\n25 13\n25 37\n26 14\n26 38\n27 15\n27 39\n28 16\n28 40\n29 17\n29 41\n30 18\n30 42\n31 19\n31 43\n32 20\n32 44\n33 21\n33 45\n34 22\n34 46\n35 23\n35 47\n36 24\n36 48\n37 25\n37 49\n38 26\n39 27\n40 28\n41 29\n42 30\n43 31\n44 32\n45 33\n46 34\n47 35\n48 36\n49 37"", ""Makefile"": ""CHPL = chpl\nCHPLFLAGS = -O\n\nall: pagerank_serial\n\npagerank_serial: pagerank_serial.chpl\n\t$(CHPL) $(CHPLFLAGS) -o $@ $<\n\nclean:\n\trm -f pagerank_serial pagerank_parallel\n\trm -rf output/*\n\n.PHONY: all clean"", ""pagerank_serial.chpl"": ""use IO;\nuse Map;\nuse List;\n\nconfig const damping = 0.85;\nconfig const iterations = 20;\nconfig const tolerance = 1e-6;\n\nproc main(args: [] string) {\n    if args.size < 3 {\n        writeln(\""Usage: \"", args[0], \"" <input_graph> <output_file>\"");\n        exit(1);\n    }\n    \n    const inputFile = args[1];\n    const outputFile = args[2];\n    \n    var graph: map(int, list(int));\n    var nodes: set(int);\n    \n    // Read graph\n    var reader = open(inputFile, ioMode.r).reader();\n    var line: string;\n    while reader.readLine(line) {\n        var parts = line.split();\n        if parts.size >= 2 {\n            const src = parts[0]: int;\n            const dst = parts[1]: int;\n            \n            if !graph.contains(src) {\n                graph[src] = new list(int);\n            }\n            graph[src].pushBack(dst);\n            nodes.add(src);\n            nodes.add(dst);\n        }\n    }\n    reader.close();\n    \n    // Initialize PageRank values\n    const N = nodes.size;\n    var pagerank: map(int, real);\n    for node in nodes {\n        pagerank[node] = 1.0 / N;\n    }\n    \n    // Power iteration\n    for iter in 1..iterations {\n        var newRank: map(int, real);\n        \n        for node in nodes {\n            newRank[node] = (1.0 - damping) / N;\n        }\n        \n        for (node, neighbors) in graph {\n            const contribution = damping * pagerank[node] / neighbors.size;\n            for neighbor in neighbors {\n                newRank[neighbor] += contribution;\n            }\n        }\n        \n        // Check convergence\n        var diff = 0.0;\n        for node in nodes {\n            diff += abs(newRank[node] - pagerank[node]);\n        }\n        \n        pagerank = newRank;\n        \n        if diff < tolerance {\n            writeln(\""Converged after \"", iter, \"" iterations\"");\n            break;\n        }\n    }\n    \n    // Write results\n    var writer = open(outputFile, ioMode.cw).writer();\n    for node in nodes {\n        writer.writeln(node, \"" \"", pagerank[node]);\n    }\n    writer.close();\n}""}",hard,2025-07-23T10:03:45.941947+00:00,2025-07-23T10:04:56.008333+00:00,,
draft_dp_3230a8b8,"I need a concurrent hash table with three implementations: serial baseline, lock-based parallel, and lock-free. Should handle insert/lookup/delete with command-line args for capacity and operations. Include a benchmark that measures throughput under different workloads.","FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

WORKDIR /workspace

# Install only essential C++ build tools
RUN apt-get update && apt-get install -y --no-install-recommends \
    g++ \
    make \
    && rm -rf /var/lib/apt/lists/*

COPY hash_table.h /workspace/
COPY serial_hash_table.cpp /workspace/
COPY benchmark.cpp /workspace/
COPY Makefile /workspace/

RUN make clean","import subprocess
import os
import re

def test_implementations_complete():
    """"""Test that all three implementations are present and functional""""""
    # First check if the benchmark executable exists
    assert os.path.exists('/workspace/hash_benchmark'), ""hash_benchmark executable not found""
    
    # Run with minimal operations to check basic functionality
    result = subprocess.run(['/workspace/hash_benchmark', '--operations', '1000', '--threads', '1'], 
                          capture_output=True, text=True, cwd='/workspace')
    
    # Check that all three implementations were tested
    output = result.stdout + result.stderr
    assert 'Serial Hash Table' in output or 'serial' in output.lower(), ""Serial implementation not found in output""
    assert 'Lock-based' in output or 'locked' in output.lower(), ""Lock-based implementation not found in output""
    assert 'Lock-free' in output or 'lock-free' in output.lower(), ""Lock-free implementation not found in output""
    
    # Check that some performance metrics were reported
    assert 'throughput' in output.lower() or 'ops/sec' in output.lower(), ""No throughput metrics found""

def test_concurrent_correctness():
    """"""Test that concurrent operations maintain correctness""""""
    # Run with multiple threads
    result = subprocess.run(['/workspace/hash_benchmark', '--operations', '10000', '--threads', '4', '--seed', '12345'], 
                          capture_output=True, text=True, cwd='/workspace')
    
    assert result.returncode == 0, f""Benchmark failed with return code {result.returncode}""
    
    # Check that operations completed without errors
    output = result.stdout + result.stderr
    assert 'error' not in output.lower() or 'no errors' in output.lower(), ""Errors detected during concurrent execution""
    
    # Verify that operations were counted correctly
    assert re.search(r'(operations|ops).*10000', output, re.IGNORECASE), ""Operations count mismatch""

def test_performance_comparison():
    """"""Test that performance metrics are generated for comparison""""""
    # Run benchmark with different thread counts
    result = subprocess.run(['/workspace/hash_benchmark', '--operations', '5000', '--threads', '2'], 
                          capture_output=True, text=True, cwd='/workspace')
    
    output = result.stdout
    
    # Check for performance numbers (throughput or ops/sec)
    throughput_found = re.search(r'\d+(\.\d+)?\s*(ops/sec|operations/sec|throughput)', output, re.IGNORECASE)
    assert throughput_found, ""No throughput measurements found in output""
    
    # Check that different implementations show different performance characteristics
    perf_numbers = re.findall(r'(\d+(?:\.\d+)?)\s*(?:ops/sec|operations/sec)', output, re.IGNORECASE)
    assert len(perf_numbers) >= 2, ""Need at least 2 performance measurements to compare implementations""","{""test_implementations_complete"": 0.35, ""test_concurrent_correctness"": 0.35, ""test_performance_comparison"": 0.3}","{""serial_hash_table.cpp"": ""#include \""hash_table.h\""\n\ntemplate<typename K, typename V>\nSerialHashTable<K, V>::SerialHashTable(size_t initial_capacity) \n    : bucket_count(initial_capacity), count(0) {\n    buckets = new Node*[bucket_count];\n    for (size_t i = 0; i < bucket_count; ++i) {\n        buckets[i] = nullptr;\n    }\n}\n\ntemplate<typename K, typename V>\nSerialHashTable<K, V>::~SerialHashTable() {\n    // TODO: Clean up buckets\n}\n\ntemplate<typename K, typename V>\nbool SerialHashTable<K, V>::insert(const K& key, const V& value) {\n    size_t index = hasher(key) % bucket_count;\n    // TODO: Implement insert logic\n    return false;\n}\n\ntemplate<typename K, typename V>\nbool SerialHashTable<K, V>::lookup(const K& key, V& value) {\n    // TODO: Implement lookup\n    return false;\n}\n\ntemplate<typename K, typename V>\nbool SerialHashTable<K, V>::remove(const K& key) {\n    // TODO: Implement remove\n    return false;\n}\n\n// Explicit instantiation for common types\ntemplate class SerialHashTable<int, int>;\ntemplate class SerialHashTable<std::string, int>;"", ""Makefile"": ""CXX = g++\nCXXFLAGS = -std=c++11 -O2 -pthread -Wall\nLDFLAGS = -pthread\n\nSRCS = serial_hash_table.cpp benchmark.cpp\nOBJS = $(SRCS:.cpp=.o)\nTARGET = hash_benchmark\n\nall: $(TARGET)\n\n$(TARGET): $(OBJS)\n\t$(CXX) $(LDFLAGS) -o $@ $^\n\n%.o: %.cpp\n\t$(CXX) $(CXXFLAGS) -c $< -o $@\n\nclean:\n\trm -f $(OBJS) $(TARGET)\n\n.PHONY: all clean"", ""benchmark.cpp"": ""#include <iostream>\n#include <chrono>\n#include <vector>\n#include <random>\n#include <thread>\n#include <cstring>\n#include \""hash_table.h\""\n\nstruct BenchmarkConfig {\n    size_t initial_capacity = 1000;\n    size_t num_operations = 100000;\n    int num_threads = 1;\n    int seed = 42;\n    double read_ratio = 0.8;\n    double write_ratio = 0.15;\n    // delete_ratio = 1 - read_ratio - write_ratio\n};\n\nvoid parse_args(int argc, char* argv[], BenchmarkConfig& config) {\n    for (int i = 1; i < argc; i++) {\n        if (strcmp(argv[i], \""--capacity\"") == 0 && i + 1 < argc) {\n            config.initial_capacity = std::atoi(argv[++i]);\n        } else if (strcmp(argv[i], \""--operations\"") == 0 && i + 1 < argc) {\n            config.num_operations = std::atoi(argv[++i]);\n        } else if (strcmp(argv[i], \""--threads\"") == 0 && i + 1 < argc) {\n            config.num_threads = std::atoi(argv[++i]);\n        } else if (strcmp(argv[i], \""--seed\"") == 0 && i + 1 < argc) {\n            config.seed = std::atoi(argv[++i]);\n        }\n    }\n}\n\nint main(int argc, char* argv[]) {\n    BenchmarkConfig config;\n    parse_args(argc, argv, config);\n    \n    std::cout << \""Hash Table Benchmark\"" << std::endl;\n    std::cout << \""Capacity: \"" << config.initial_capacity << std::endl;\n    std::cout << \""Operations: \"" << config.num_operations << std::endl;\n    std::cout << \""Threads: \"" << config.num_threads << std::endl;\n    \n    // TODO: Implement benchmark for serial, locked, and lock-free versions\n    \n    return 0;\n}"", ""hash_table.h"": ""#ifndef HASH_TABLE_H\n#define HASH_TABLE_H\n\n#include <cstddef>\n#include <functional>\n\ntemplate<typename K, typename V>\nclass HashTable {\npublic:\n    virtual ~HashTable() = default;\n    \n    virtual bool insert(const K& key, const V& value) = 0;\n    virtual bool lookup(const K& key, V& value) = 0;\n    virtual bool remove(const K& key) = 0;\n    virtual size_t size() const = 0;\n};\n\ntemplate<typename K, typename V>\nclass SerialHashTable : public HashTable<K, V> {\nprivate:\n    struct Node {\n        K key;\n        V value;\n        Node* next;\n    };\n    \n    Node** buckets;\n    size_t bucket_count;\n    size_t count;\n    std::hash<K> hasher;\n    \npublic:\n    SerialHashTable(size_t initial_capacity);\n    ~SerialHashTable();\n    \n    bool insert(const K& key, const V& value) override;\n    bool lookup(const K& key, V& value) override;\n    bool remove(const K& key) override;\n    size_t size() const override { return count; }\n};\n\n#endif""}",medium,2025-07-23T10:06:58.830069+00:00,2025-07-23T11:06:31.809592+00:00,,
draft_dp_2249e7f7,The sequential log analyzer is too slow for our 5GB+ daily logs. Need a parallel version using goroutines that produces identical stats. Keep the current output format - we have scripts that depend on it.,"FROM ghcr.io/laude-institute/t-bench/python-3-13:20250620

# Install Go from Ubuntu packages
RUN apt-get update && apt-get install -y golang-go && apt-get clean

ENV PATH=""/usr/local/go/bin:$PATH""
ENV GOPATH=""/go""
ENV PATH=""$GOPATH/bin:$PATH""

WORKDIR /app

# Copy project files
COPY go.mod /app/
COPY main.go /app/
COPY analyzer/sequential.go /app/analyzer/
COPY sample.log /app/
COPY generate_logs.go /app/

# Initialize go module
RUN go mod tidy

# Pre-compile to speed things up
RUN go build -o loganalyzer main.go
RUN go build -o generate_logs generate_logs.go

# Generate a larger test log file
RUN ./generate_logs -output large.log -size 50000","import subprocess
import os
import json

def test_versions_produce_identical_stats():
    """"""Test that sequential and parallel versions produce identical statistics.""""""
    # First, ensure we have the parallel version implemented
    result = subprocess.run(
        [""./loganalyzer"", ""-parallel"", ""large.log""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    
    # Check that parallel version actually runs (not just exits with ""not implemented"")
    assert result.returncode == 0, f""Parallel version failed to run: {result.stderr}""
    assert ""not implemented"" not in result.stdout.lower(), ""Parallel version is not implemented""
    
    # Run sequential version
    seq_result = subprocess.run(
        [""./loganalyzer"", ""large.log""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    assert seq_result.returncode == 0
    
    # Run parallel version
    par_result = subprocess.run(
        [""./loganalyzer"", ""-parallel"", ""-workers"", ""4"", ""large.log""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    assert par_result.returncode == 0
    
    # Extract the stats output (everything after ""Processing..."")
    seq_lines = seq_result.stdout.strip().split('\n')
    par_lines = par_result.stdout.strip().split('\n')
    
    # Skip the ""Processing with N workers..."" line in parallel output
    par_stats_start = 0
    for i, line in enumerate(par_lines):
        if line.startswith(""Total Requests:""):
            par_stats_start = i
            break
    
    seq_stats_start = 0
    for i, line in enumerate(seq_lines):
        if line.startswith(""Total Requests:""):
            seq_stats_start = i
            break
    
    # Compare stats output
    seq_stats = '\n'.join(seq_lines[seq_stats_start:])
    par_stats = '\n'.join(par_lines[par_stats_start:])
    
    assert seq_stats == par_stats, f""Stats differ between sequential and parallel versions""

def test_parallel_uses_goroutines():
    """"""Test that the parallel version actually uses goroutines for processing.""""""
    # Build with race detector to ensure concurrent access is handled properly
    build_result = subprocess.run(
        [""go"", ""build"", ""-race"", ""-o"", ""loganalyzer_race"", ""main.go""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    assert build_result.returncode == 0, f""Failed to build with race detector: {build_result.stderr}""
    
    # Run with race detector - if it uses goroutines properly, it should not detect races
    result = subprocess.run(
        [""./loganalyzer_race"", ""-parallel"", ""-workers"", ""8"", ""large.log""],
        cwd=""/app"",
        capture_output=True,
        text=True
    )
    
    assert result.returncode == 0, f""Race condition detected: {result.stderr}""
    assert ""DATA RACE"" not in result.stderr, ""Data race detected in parallel implementation""","{""test_versions_produce_identical_stats"": 0.6, ""test_parallel_uses_goroutines"": 0.4}","{""go.mod"": ""module loganalyzer\n\ngo 1.21"", ""sample.log"": ""192.168.1.1 - - [10/Jan/2024:10:15:32 +0000] \""GET /index.html HTTP/1.1\"" 200 3245 \""-\"" \""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\""\n192.168.1.2 - - [10/Jan/2024:10:15:33 +0000] \""GET /api/users HTTP/1.1\"" 200 1523 \""-\"" \""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\""\n192.168.1.1 - - [10/Jan/2024:10:15:34 +0000] \""POST /api/login HTTP/1.1\"" 401 523 \""-\"" \""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\""\n192.168.1.3 - - [10/Jan/2024:10:15:35 +0000] \""GET /images/logo.png HTTP/1.1\"" 200 8432 \""-\"" \""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36\""\n192.168.1.2 - - [10/Jan/2024:10:15:36 +0000] \""GET /api/products HTTP/1.1\"" 200 4532 \""-\"" \""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\""\n192.168.1.4 - - [10/Jan/2024:11:20:15 +0000] \""GET /index.html HTTP/1.1\"" 200 3245 \""-\"" \""curl/7.68.0\""\n192.168.1.1 - - [10/Jan/2024:11:20:16 +0000] \""GET /api/health HTTP/1.1\"" 200 123 \""-\"" \""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\""\n192.168.1.5 - - [10/Jan/2024:11:20:17 +0000] \""GET /admin HTTP/1.1\"" 403 412 \""-\"" \""Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)\""\n192.168.1.3 - - [10/Jan/2024:11:20:18 +0000] \""POST /api/data HTTP/1.1\"" 201 234 \""-\"" \""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36\""\n192.168.1.2 - - [10/Jan/2024:12:30:45 +0000] \""GET /api/users HTTP/1.1\"" 500 532 \""-\"" \""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\"""", ""generate_logs.go"": ""package main\n\nimport (\n\t\""flag\""\n\t\""fmt\""\n\t\""math/rand\""\n\t\""os\""\n\t\""time\""\n)\n\nvar (\n\tips        = []string{\""192.168.1.1\"", \""192.168.1.2\"", \""192.168.1.3\"", \""192.168.1.4\"", \""192.168.1.5\"", \""10.0.0.1\"", \""10.0.0.2\"", \""172.16.0.1\""}\n\tpaths      = []string{\""/index.html\"", \""/api/users\"", \""/api/login\"", \""/api/products\"", \""/images/logo.png\"", \""/api/health\"", \""/admin\"", \""/api/data\"", \""/static/css/main.css\"", \""/favicon.ico\""}\n\tstatuses   = []string{\""200\"", \""200\"", \""200\"", \""200\"", \""201\"", \""301\"", \""302\"", \""400\"", \""401\"", \""403\"", \""404\"", \""500\""}\n\tuserAgents = []string{\n\t\t\""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"",\n\t\t\""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\"",\n\t\t\""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36\"",\n\t\t\""Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)\"",\n\t\t\""curl/7.68.0\"",\n\t\t\""PostmanRuntime/7.26.8\"",\n\t}\n)\n\nfunc main() {\n\toutput := flag.String(\""output\"", \""generated.log\"", \""Output log file\"")\n\tsize := flag.Int(\""size\"", 10000, \""Number of log entries to generate\"")\n\tflag.Parse()\n\n\tfile, err := os.Create(*output)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \""Error creating file: %v\\n\"", err)\n\t\tos.Exit(1)\n\t}\n\tdefer file.Close()\n\n\trand.Seed(time.Now().UnixNano())\n\tbaseTime := time.Date(2024, 1, 10, 9, 0, 0, 0, time.UTC)\n\n\tfor i := 0; i < *size; i++ {\n\t\tip := ips[rand.Intn(len(ips))]\n\t\tpath := paths[rand.Intn(len(paths))]\n\t\tstatus := statuses[rand.Intn(len(statuses))]\n\t\tua := userAgents[rand.Intn(len(userAgents))]\n\t\t\n\t\t// Random size between 100 and 50000 bytes\n\t\tsize := rand.Intn(49900) + 100\n\t\t\n\t\t// Increment time by 0-5 seconds\n\t\tbaseTime = baseTime.Add(time.Duration(rand.Intn(5)) * time.Second)\n\t\t\n\t\tlogLine := fmt.Sprintf(`%s - - [%s] \""GET %s HTTP/1.1\"" %s %d \""-\"" \""%s\""`+\""\\n\"",\n\t\t\tip,\n\t\t\tbaseTime.Format(\""02/Jan/2006:15:04:05 -0700\""),\n\t\t\tpath,\n\t\t\tstatus,\n\t\t\tsize,\n\t\t\tua,\n\t\t)\n\t\t\n\t\tfile.WriteString(logLine)\n\t}\n\n\tfmt.Printf(\""Generated %d log entries in %s\\n\"", *size, *output)\n}"", ""main.go"": ""package main\n\nimport (\n\t\""flag\""\n\t\""fmt\""\n\t\""loganalyzer/analyzer\""\n\t\""os\""\n)\n\nfunc main() {\n\tparallel := flag.Bool(\""parallel\"", false, \""Use parallel processing\"")\n\tworkers := flag.Int(\""workers\"", 4, \""Number of worker goroutines\"")\n\tflag.Parse()\n\n\tif flag.NArg() < 1 {\n\t\tfmt.Println(\""Usage: loganalyzer [-parallel] [-workers N] <logfile>\"")\n\t\tos.Exit(1)\n\t}\n\n\tlogFile := flag.Arg(0)\n\n\tvar stats *analyzer.Stats\n\tvar err error\n\n\tif *parallel {\n\t\tfmt.Printf(\""Processing with %d workers...\\n\"", *workers)\n\t\t// TODO: Implement parallel analyzer\n\t\tfmt.Println(\""Parallel analyzer not implemented yet\"")\n\t\tos.Exit(1)\n\t} else {\n\t\tstats, err = analyzer.AnalyzeSequential(logFile)\n\t}\n\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \""Error: %v\\n\"", err)\n\t\tos.Exit(1)\n\t}\n\n\tanalyzer.PrintStats(stats)\n}"", ""analyzer/sequential.go"": ""package analyzer\n\nimport (\n\t\""bufio\""\n\t\""fmt\""\n\t\""os\""\n\t\""regexp\""\n\t\""sort\""\n\t\""strconv\""\n\t\""strings\""\n\t\""time\""\n)\n\ntype Stats struct {\n\tTotalRequests   int\n\tStatusCodes     map[string]int\n\tIPAddresses     map[string]int\n\tHourlyBandwidth map[int]int64\n\tURLs            map[string]int\n\tUserAgents      map[string]int\n}\n\nvar logRegex = regexp.MustCompile(`^(\\S+) \\S+ \\S+ \\[([^\\]]+)\\] \""(\\S+) (\\S+) \\S+\"" (\\d+) (\\d+) \""[^\""]*\"" \""([^\""]*)\""`)\n\nfunc AnalyzeSequential(filename string) (*Stats, error) {\n\tfile, err := os.Open(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer file.Close()\n\n\tstats := &Stats{\n\t\tStatusCodes:     make(map[string]int),\n\t\tIPAddresses:     make(map[string]int),\n\t\tHourlyBandwidth: make(map[int]int64),\n\t\tURLs:            make(map[string]int),\n\t\tUserAgents:      make(map[string]int),\n\t}\n\n\tscanner := bufio.NewScanner(file)\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tprocessLine(line, stats)\n\t}\n\n\tif err := scanner.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn stats, nil\n}\n\nfunc processLine(line string, stats *Stats) {\n\tmatches := logRegex.FindStringSubmatch(line)\n\tif len(matches) < 8 {\n\t\treturn\n\t}\n\n\tip := matches[1]\n\ttimestamp := matches[2]\n\turl := matches[4]\n\tstatus := matches[5]\n\tsize := matches[6]\n\tuserAgent := matches[7]\n\n\tstats.TotalRequests++\n\tstats.StatusCodes[status]++\n\tstats.IPAddresses[ip]++\n\tstats.URLs[url]++\n\tstats.UserAgents[userAgent]++\n\n\t// Parse timestamp to get hour\n\tt, err := time.Parse(\""02/Jan/2006:15:04:05 -0700\"", timestamp)\n\tif err == nil {\n\t\thour := t.Hour()\n\t\tbytes, _ := strconv.ParseInt(size, 10, 64)\n\t\tstats.HourlyBandwidth[hour] += bytes\n\t}\n}\n\nfunc PrintStats(stats *Stats) {\n\tfmt.Printf(\""Total Requests: %d\\n\\n\"", stats.TotalRequests)\n\n\tfmt.Println(\""Status Codes:\"")\n\tprintTopN(stats.StatusCodes, 10)\n\n\tfmt.Println(\""\\nTop IP Addresses:\"")\n\tprintTopN(stats.IPAddresses, 10)\n\n\tfmt.Println(\""\\nHourly Bandwidth (bytes):\"")\n\tprintHourlyBandwidth(stats.HourlyBandwidth)\n\n\tfmt.Println(\""\\nTop URLs:\"")\n\tprintTopN(stats.URLs, 10)\n\n\tfmt.Println(\""\\nTop User Agents:\"")\n\tprintTopN(stats.UserAgents, 5)\n}\n\nfunc printTopN(data map[string]int, n int) {\n\ttype kv struct {\n\t\tKey   string\n\t\tValue int\n\t}\n\n\tvar sorted []kv\n\tfor k, v := range data {\n\t\tsorted = append(sorted, kv{k, v})\n\t}\n\n\tsort.Slice(sorted, func(i, j int) bool {\n\t\treturn sorted[i].Value > sorted[j].Value\n\t})\n\n\tfor i := 0; i < n && i < len(sorted); i++ {\n\t\tfmt.Printf(\""  %s: %d\\n\"", sorted[i].Key, sorted[i].Value)\n\t}\n}\n\nfunc printHourlyBandwidth(data map[int]int64) {\n\tfor hour := 0; hour < 24; hour++ {\n\t\tif bytes, ok := data[hour]; ok && bytes > 0 {\n\t\t\tfmt.Printf(\""  Hour %02d: %d\\n\"", hour, bytes)\n\t\t}\n\t}\n}""}",medium,2025-07-23T10:08:32.229503+00:00,2025-07-23T11:35:45.181038+00:00,,
